"""
Market Sentiment Analysis - Core Logic
Aggregates market data and calculates Greed & Fear Index (0-100).
"""

import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any
import sys
import os
import requests
import re

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from modules.fish_basin.fish_basin import fetch_data
from modules.market_ladder.limit_up_ladder import get_limit_up_data
from modules.core_news.core_news_monitor import fetch_eastmoney_data
from modules.market_sentiment.generate_sentiment_prompt import get_raw_image_prompt, generate_image_prompt
from common.image_generator import generate_image_from_text


def get_limit_down_count(date_str: str = None) -> int:
    """
    Get the count of limit down stocks for a given date.

    Args:
        date_str: Date string in YYYYMMDD format. If None, uses today.

    Returns:
        Count of limit down stocks
    """
    try:
        # Get limit down pool from akshare
        df = ak.stock_zt_pool_dtgc_em(date=date_str or datetime.now().strftime("%Y%m%d"))
        return len(df) if df is not None and not df.empty else 0
    except Exception as e:
        print(f"Error fetching limit down data: {e}")
        return 0


def get_volume_from_previous_prompt(date_str: str) -> float:
    """
    Try to get volume from previous day's prompt file.

    Args:
        date_str: Date string in YYYYMMDD format.

    Returns:
        Volume in Yuan (float) or 0.0 if not found
    """
    try:
        if not date_str:
            date_str = datetime.now().strftime("%Y%m%d")

        current_date = datetime.strptime(date_str, "%Y%m%d")
        prev_date = current_date - timedelta(days=1)
        prev_date_str = prev_date.strftime("%Y%m%d")

        file_path = os.path.join("results", prev_date_str, "AIæç¤ºè¯", "å¸‚åœºæƒ…ç»ª_Prompt.txt")

        if not os.path.exists(file_path):
            # Try checking absolute path if relative path fails or debug info
            # print(f"   Previous prompt file not found: {file_path}")
            return 0.0

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Regex search for ä»Šæ—¥æˆäº¤: **(\d+) äº¿**
        match = re.search(r"ä»Šæ—¥æˆäº¤: \*\*(\d+) äº¿\*\*", content)
        if match:
            vol_yi = float(match.group(1))
            print(f"   Recovered volume from file ({prev_date_str}): {vol_yi}äº¿")
            return vol_yi * 1e8

        return 0.0
    except Exception as e:
        print(f"   Error reading previous prompt: {e}")
        return 0.0



def get_market_volume_sina() -> float:
    """
    Fetch real-time market volume (SH + SZ) from Sina Finance.
    Returns total volume in Yuan (float).
    Returns 0.0 if failed.
    """
    url = "http://hq.sinajs.cn/list=s_sh000001,s_sz399001"
    headers = {"Referer": "https://finance.sina.com.cn/"}
    
    print("ğŸ“Š Fetching Real-time Volume from Sina Finance...")
    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.encoding = 'gbk'
        data = response.text
        
        # Parse response
        # var hq_str_s_sh000001="Name,Price,Chg,Pct,Vol,Turnover(Wan)";
        total_volume = 0.0
        parsed_count = 0
        
        lines = data.strip().split('\n')
        for line in lines:
            if 'hq_str_s_' not in line:
                continue
            
            parts = line.split('=')
            if len(parts) < 2:
                continue
                
            content = parts[1].strip('";')
            fields = content.split(',')
            
            if len(fields) >= 6:
                # Index 5 is Turnover in Wan
                try:
                    vol_wan = float(fields[5])
                    vol_yuan = vol_wan * 10000
                    total_volume += vol_yuan
                    parsed_count += 1
                except ValueError:
                    continue
        
        if parsed_count == 2: # Should have both SH and SZ
            print(f"âœ… Sina Volume: {total_volume/1e8:.0f}äº¿")
            return total_volume
        else:
            print(f"âš ï¸ Sina data incomplete (parsed {parsed_count} indices)")
            return 0.0
            
    except Exception as e:
        print(f"âŒ Error fetching Sina volume: {e}")
        return 0.0


def get_market_volume(date_str: str = None) -> Dict[str, float]:
    """
    Get market turnover volume for today and yesterday.
    Primary: Sina (for Today) + AkShare (for Yesterday).
    Fallback: AkShare (for both).

    Returns:
        Dictionary with today_volume, yesterday_volume, change_pct (Volumes in Yuan)
    """
    target_date = date_str or datetime.now().strftime("%Y%m%d")
    is_today = (target_date == datetime.now().strftime("%Y%m%d"))
    
    # 1. Fetch Historical Data (AkShare) to get Yesterday's volume
    # We always need this for comparison
    end_dt = datetime.strptime(target_date, "%Y%m%d")
    start_dt = end_dt - timedelta(days=15) # 15 days back to be safe
    start_date_s = start_dt.strftime("%Y%m%d")
    
    yesterday_vol = 0.0
    ak_today_vol = 0.0
    
    print(f"ğŸ“Š Fetching History for comparison ({start_date_s} - {target_date})...")
    
    try:
        df_sh = ak.index_zh_a_hist(symbol="000001", period="daily", start_date=start_date_s, end_date=target_date)
        df_sz = ak.index_zh_a_hist(symbol="399001", period="daily", start_date=start_date_s, end_date=target_date)
        
        if df_sh is not None and not df_sh.empty and df_sz is not None and not df_sz.empty:
             # Standardize dates
            df_sh['date_str'] = pd.to_datetime(df_sh['æ—¥æœŸ']).dt.strftime("%Y%m%d")
            df_sz['date_str'] = pd.to_datetime(df_sz['æ—¥æœŸ']).dt.strftime("%Y%m%d")

            # Merge
            df = pd.merge(df_sh[['date_str', 'æˆäº¤é¢']], df_sz[['date_str', 'æˆäº¤é¢']], on='date_str', suffixes=('_sh', '_sz'))
            df['total_vol'] = df['æˆäº¤é¢_sh'] + df['æˆäº¤é¢_sz']
            df = df.sort_values('date_str')
            
            # Identify Yesterday
            # If target_date is in df, yesterday is the row before it
            # If target_date is NOT in df (e.g. today during trading), yesterday is the last row
            
            row_target = df[df['date_str'] == target_date]
            
            if not row_target.empty:
                # Target date exists in history (e.g. backtesting or after close)
                ak_today_vol = float(row_target.iloc[0]['total_vol'])
                
                # Get previous row
                idx = df.index[df['date_str'] == target_date].tolist()[0]
                # Since we sorted by date_str, but the index might not be sequential integers if we didn't reset
                # Let's rely on position
                pos = df.index.get_loc(idx)
                if pos > 0:
                    yesterday_vol = float(df.iloc[pos - 1]['total_vol'])
            else:
                # Target date not in history (likely today during trading)
                # Then the last row in df is the most recent trading day (Yesterday)
                if not df.empty:
                    yesterday_vol = float(df.iloc[-1]['total_vol'])
                    print(f"   Using latest history ({df.iloc[-1]['date_str']}) as Yesterday.")
                    
    except Exception as e:
        print(f"âš ï¸ Error fetching history from AkShare: {e}")

    # PRIORITY: Try Prompt File First (More Reliable)
    if yesterday_vol == 0:
        print("   AkShare history failed, trying previous prompt file...")
        yesterday_vol = get_volume_from_previous_prompt(target_date)
        if yesterday_vol > 0:
            print(f"   âœ… Recovered yesterday volume from prompt: {yesterday_vol/1e8:.0f}äº¿")
        else:
            print("   âš ï¸ WARNING: Both AkShare and Prompt file failed for yesterday_vol!")

    # 2. Get Today's Volume
    today_vol = 0.0
    
    if is_today:
        # Try Sina First
        sina_vol = get_market_volume_sina()
        if sina_vol > 0:
            today_vol = sina_vol
        else:
            print("   Sina failed, falling back to AkShare for today...")
            today_vol = ak_today_vol
    else:
        # Not today (Backtesting), must use AkShare
        today_vol = ak_today_vol

    # 3. Calculate Change
    change_pct = 0.0
    if yesterday_vol > 0:
        change_pct = ((today_vol - yesterday_vol) / yesterday_vol) * 100
        
    print(f"âœ… Final Volume: Today={today_vol/1e8:.0f}äº¿, Yesterday={yesterday_vol/1e8:.0f}äº¿, Change={change_pct:+.2f}%")
    
    return {
        "today_volume": today_vol,
        "yesterday_volume": yesterday_vol,
        "change_pct": round(change_pct, 2)
    }


def get_indices_performance() -> Dict[str, float]:
    """
    Get performance (% change) for major indices.
    Corrected codes and added filtering for failed data.

    Returns:
        Dictionary with index names and their % changes
    """
    indices = {
        "ä¸Šè¯50": "sh000016",
        "æ²ªæ·±300": "sh000300",
        "ä¸­è¯500": "sz399905",   # Corrected from sh000905
        "ä¸­è¯2000": "sz399303"   # Changed to CNI 2000 (more reliable data source)
    }

    performance = {}

    for name, code in indices.items():
        try:
            # Use shared fetch_data from fish_basin (proven reliability)
            df = fetch_data(name, code)
            if df is not None and not df.empty and len(df) >= 2:
                latest = float(df.iloc[-1]['close'])
                previous = float(df.iloc[-2]['close'])

                # Check if data is fresh (today)
                last_date = pd.to_datetime(df.iloc[-1]['date']).date()
                today_date = datetime.now().date()

                # Simple validation: if date is not today, try to get spot or accept it might be close price
                # For sentiment, we accept latest available if it's recent

                pct_change = ((latest - previous) / previous) * 100
                performance[name] = round(pct_change, 2)
                print(f"âœ… {name}: {pct_change:+.2f}%")
            else:
                print(f"âš ï¸ Failed to get data for {name}, skipping.")
        except Exception as e:
            print(f"âŒ Error fetching {name} performance: {e}")
            # Do NOT add to performance dict if failed (so it won't show as 0%)

    return performance


def get_market_news_sentiment() -> Dict[str, Any]:
    """
    Analyze news sentiment from core news.
    
    Returns:
        Dictionary with bullish/bearish counts and sample headlines
    """
    try:
        # Fetch news from last 24 hours
        news_data = fetch_eastmoney_data(target_window_hours=24)
        
        if not news_data:
            return {
                "bullish_count": 0,
                "bearish_count": 0,
                "neutral_count": 0,
                "bullish_news": [],
                "bearish_news": []
            }
        
        # Simple sentiment classification based on keywords
        bullish_keywords = ['ä¸Šæ¶¨', 'åˆ©å¥½', 'çªç ´', 'åˆ›æ–°é«˜', 'å¤§æ¶¨', 'æš´æ¶¨', 'æ¶¨åœ', 'ç‰›å¸‚', 'çœ‹å¤š']
        bearish_keywords = ['ä¸‹è·Œ', 'åˆ©ç©º', 'è·Œç ´', 'åˆ›æ–°ä½', 'å¤§è·Œ', 'æš´è·Œ', 'è·Œåœ', 'ç†Šå¸‚', 'çœ‹ç©º']
        
        bullish_news = []
        bearish_news = []
        neutral_count = 0
        
        for item in news_data:
            title = item.get('title', '')
            
            is_bullish = any(kw in title for kw in bullish_keywords)
            is_bearish = any(kw in title for kw in bearish_keywords)
            
            if is_bullish and not is_bearish:
                bullish_news.append(title)
            elif is_bearish and not is_bullish:
                bearish_news.append(title)
            else:
                neutral_count += 1
        
        return {
            "bullish_count": len(bullish_news),
            "bearish_count": len(bearish_news),
            "neutral_count": neutral_count,
            "bullish_news": bullish_news[:5],  # Top 5
            "bearish_news": bearish_news[:5]   # Top 5
        }
    
    except Exception as e:
        print(f"Error analyzing news sentiment: {e}")
        return {
            "bullish_count": 0,
            "bearish_count": 0,
            "neutral_count": 0,
            "bullish_news": [],
            "bearish_news": []
        }


def get_sector_flow() -> Dict[str, Any]:
    """
    Get sector fund flow data.
    Multi-source: ä¸œè´¢ API â†’ åŒèŠ±é¡º â†’ æ–‡ä»¶è§£æ
    
    Returns:
        Dictionary with net inflow and top flowing sectors
    """
    # Source 1: ä¸œè´¢ (Eastmoney) API
    try:
        print("ğŸ’° Trying Source 1: Eastmoney API for money flow...")
        df = ak.stock_sector_fund_flow_rank(indicator="ä»Šæ—¥")
        
        if df is None or df.empty:
            raise Exception("API returned empty data")
        
        # Calculate total net inflow
        net_inflow = df['å‡€é¢'].sum() if 'å‡€é¢' in df.columns else 0
        
        # Get top 3 inflow and outflow sectors
        df_sorted = df.sort_values('å‡€é¢', ascending=False)
        inflow_sectors = df_sorted.head(3)[['åç§°', 'å‡€é¢']].to_dict('records') if len(df_sorted) > 0 else []
        outflow_sectors = df_sorted.tail(3)[['åç§°', 'å‡€é¢']].to_dict('records') if len(df_sorted) > 0 else []
        
        print(f"âœ… Eastmoney money flow: Net {net_inflow/1e8:.0f}äº¿, {len(inflow_sectors)} inflows, {len(outflow_sectors)} outflows")
        return {
            "net_inflow": net_inflow,
            "inflow_sectors": inflow_sectors,
            "outflow_sectors": outflow_sectors
        }
    except Exception as e:
        print(f"âŒ Eastmoney API failed: {e}")
    
    # Source 2: åŒèŠ±é¡º (Tonghuashun) - try alternative approach
    try:
        print("ğŸ’° Trying Source 2: Tonghuashun for money flow...")
        # Use stock_sector_fund_flow_rank with alternative params
        df = ak.stock_fund_flow_individual(symbol="000001")
        if df is not None and not df.empty:
            # This is a fallback, data might not be perfect
            print(f"âš ï¸ Tonghuashun returned limited data, trying file parsing...")
            raise Exception("Tonghuashun data insufficient")
    except Exception as e:
        print(f"âŒ Tonghuashun failed: {e}")
    
    # Source 3: æ–‡ä»¶è§£æ (File parsing from existing prompt)
    try:
        print("ğŸ’° Trying Source 3: File parsing for money flow...")
        import re
        today = datetime.now().strftime("%Y%m%d")
        prompt_file = os.path.join("results", today, "AIæç¤ºè¯", "èµ„é‡‘æµå‘_Prompt.txt")
        
        if not os.path.exists(prompt_file):
            raise FileNotFoundError(f"Prompt file not found: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract inflow sectors and amounts
        # Extract inflow sectors and amounts
        # Improved Regex to capture Clean Names:  **"é“¶è¡Œ"** or "é“¶è¡Œ"
        sector_pattern = r'["\']?([\u4e00-\u9fa5]+)["\']?[^+]*?\+([0-9.]+)äº¿'
        sector_matches = re.findall(sector_pattern, content)
        
        # Extract outflow data
        outflow_pattern = r'([\u4e00-\u9fa5]+)\s*\(-([0-9.]+)äº¿\)'
        outflow_matches = re.findall(outflow_pattern, content)
        
        inflow_sectors = [{'åç§°': name.strip(), 'å‡€é¢': float(val) * 1e8} for name, val in sector_matches if name.strip()][:3]
        outflow_sectors = [{'åç§°': name.strip(), 'å‡€é¢': -float(val) * 1e8} for name, val in outflow_matches if name.strip()][:3]
        
        # Calculate net inflow
        net_inflow = sum(s['å‡€é¢'] for s in inflow_sectors) + sum(s['å‡€é¢'] for s in outflow_sectors)
        
        print(f"âœ… File parsing: Net {net_inflow/1e8:.0f}äº¿, {len(inflow_sectors)} inflows, {len(outflow_sectors)} outflows")
        if inflow_sectors:
            print(f"   Inflows: {[s['åç§°'] for s in inflow_sectors]}")
        if outflow_sectors:
            print(f"   Outflows: {[s['åç§°'] for s in outflow_sectors]}")
        
        return {
            "net_inflow": net_inflow,
            "inflow_sectors": inflow_sectors,
            "outflow_sectors": outflow_sectors
        }
    
    except Exception as e2:
        print(f"âŒ File parsing also failed: {e2}")
    
    print("âŒ All money flow sources failed, returning zeros")
    return {
        "net_inflow": 0,
        "inflow_sectors": [],
        "outflow_sectors": []
    }


def get_market_valuation() -> Dict[str, float]:
    """
    Get market valuation (PE/PB) using AkShare.
    Uses SSE and SZSE summaries.

    Returns:
        Dictionary with avg_pe_sh, avg_pe_sz, and valuation_score (0-100 normalized)
    """
    print("ğŸ“Š Fetching Market Valuation (PE)...")
    try:
        # SSE Summary
        df_sh = ak.stock_sse_summary()
        # df_sh is usually a list of dicts or specific format.
        # For simplicity, if structure varies, we catch error.
        # Assuming standard return: type(df_sh) is usually pd.DataFrame or list
        pe_sh = 0.0
        if isinstance(df_sh, pd.DataFrame):
             # Usually row with type='è‚¡ç¥¨' or similar.
             # Let's try to find 'å¹³å‡å¸‚ç›ˆç‡'
             if 'å¹³å‡å¸‚ç›ˆç‡' in df_sh.columns:
                 pe_sh = df_sh['å¹³å‡å¸‚ç›ˆç‡'].mean() # Simplified
             elif 'item' in df_sh.columns and 'value' in df_sh.columns:
                 # Check for specific row
                 row = df_sh[df_sh['item'] == 'å¹³å‡å¸‚ç›ˆç‡']
                 if not row.empty:
                     pe_sh = float(row.iloc[0]['value'])

        # SZSE Summary
        df_sz = ak.stock_szse_summary()
        pe_sz = 0.0
        if isinstance(df_sz, pd.DataFrame):
             if 'è‚¡ç¥¨å¹³å‡å¸‚ç›ˆç‡' in df_sz.columns:
                  pe_sz = df_sz['è‚¡ç¥¨å¹³å‡å¸‚ç›ˆç‡'].mean()
             elif 'å¹³å‡å¸‚ç›ˆç‡' in df_sz.columns:
                  pe_sz = df_sz['å¹³å‡å¸‚ç›ˆç‡'].mean()

        # Fallback values if API fails or structure changes (Approximate current market)
        if pe_sh == 0: pe_sh = 13.0
        if pe_sz == 0: pe_sz = 22.0

        print(f"âœ… Valuation: SH PE={pe_sh:.2f}, SZ PE={pe_sz:.2f}")

        # Normalize to Score (0-10)
        # SH PE: 10 (Fear) -> 16 (Greed)
        # SZ PE: 20 (Fear) -> 35 (Greed)

        score_sh = (max(10, min(16, pe_sh)) - 10) / 6 * 10
        score_sz = (max(20, min(35, pe_sz)) - 20) / 15 * 10

        valuation_score = (score_sh * 0.6 + score_sz * 0.4) # Weighted

        return {
            "pe_sh": pe_sh,
            "pe_sz": pe_sz,
            "valuation_score": round(valuation_score, 2)
        }

    except Exception as e:
        print(f"âŒ Error fetching valuation: {e}")
        return {"pe_sh": 0, "pe_sz": 0, "valuation_score": 5.0}  # Neutral default


def aggregate_market_data(date_str: str = None) -> Dict[str, Any]:
    """
    Aggregate all market data needed for sentiment analysis.

    Returns:
        Dictionary containing all aggregated market data
    """
    print("Aggregating market data...")

    # Get all data sources
    indices_perf = get_indices_performance()

    # Limit Up
    df_zt, _, _ = get_limit_up_data(date_str or datetime.now().strftime("%Y%m%d"))
    limit_up_count = len(df_zt) if df_zt is not None else 0

    limit_down_count = get_limit_down_count(date_str)
    news_sentiment = get_market_news_sentiment()
    sector_flow = get_sector_flow()
    volume_data = get_market_volume(date_str)
    valuation_data = get_market_valuation() # New Source

    data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "indices": indices_perf,
        "limit_up_count": limit_up_count,
        "limit_down_count": limit_down_count,
        "news_sentiment": news_sentiment,
        "sector_flow": sector_flow,
        "volume": volume_data,
        "valuation": valuation_data
    }

    print("Market data aggregation complete.")
    return data


def get_sentiment_description(score: float) -> str:
    """
    Return a distinct description for the score (0-100), creating 50 levels (every 2 points approx).
    """
    descriptions = [
        (0, "ç»æœ›å´©ç›˜ï¼Œæåº¦ææ…Œ"), (4, "éåœ°ç‹¼è—‰ï¼Œä¿¡å¿ƒå†°ç‚¹"), (8, "é˜´è·Œä¸æ­¢ï¼Œæ·±ä¸è§åº•"), (12, "ææ…Œè”“å»¶ï¼ŒåŠ é€Ÿèµ¶åº•"), (16, "è‡³æš—æ—¶åˆ»ï¼Œè¿™ç§æ—¶åˆ»å¾€å¾€å­•è‚²ç”Ÿæœº"),
        (20, "æåº¦ä½è¿·ï¼Œæ— äººé—®æ´¥"), (24, "æ‚²è§‚å¼¥æ¼«ï¼Œç”šè‡³è¿åå¼¹éƒ½æ— åŠ›"), (28, "æƒ…ç»ªç£¨åº•ï¼Œå¤‡å—ç…ç†¬"), (32, "ä¾ç„¶å¼±åŠ¿ï¼Œç­‰å¾…è½¬æœº"), (36, "è°¨æ…è§‚æœ›ï¼Œå¦‚å±¥è–„å†°"),
        (40, "è™½æœ‰æŠµæŠ—ï¼Œä½†ä¿¡å¿ƒä¸è¶³"), (44, "å¤šç©ºå¹³è¡¡ï¼Œæ–¹å‘æœªæ˜"), (48, "è“„åŠ¿å¾…å‘ï¼Œçª„å¹…éœ‡è¡"), (50, "ä¸­æ€§åå¤šï¼Œé™å¾…èŠ±å¼€"), (52, "æ¸©å’Œå¤è‹ï¼Œåˆç°æ›™å…‰"),
        (56, "å¤šå¤´è¯•æ¢ï¼Œé€æ­¥å›æš–"), (60, "èµšé’±æ•ˆåº”æ˜¾ç°ï¼Œäººæ°”èšæ‹¢"), (64, "äº¤æŠ•æ´»è·ƒï¼Œä¿¡å¿ƒå¢å¼º"), (68, "æƒ…ç»ªé«˜æ¶¨ï¼Œè‰¯æ€§è½®åŠ¨"), (72, "çƒ­ç‚¹é¢‘å‡ºï¼Œè´ªå©ªå‡æ¸©"),
        (76, "åŠ é€Ÿä¸Šè¡Œï¼Œè¸ç©ºç„¦è™‘"), (80, "å…¨é¢æ™®æ¶¨ï¼Œæåº¦äº¢å¥‹"), (84, "ç‹‚çƒ­é€¼ç©ºï¼Œå„ç§åˆ©å¥½æ»¡å¤©é£"), (88, "æƒ…ç»ªè¿‡çƒ­ï¼Œé£é™©ç§¯èš"), (92, "æåº¦è´ªå©ªï¼Œç”šè‡³æœ‰äº›ç–¯ç‹‚"),
        (96, "æ³¡æ²«è§é¡¶ï¼Œæ‘‡æ‘‡æ¬²å "), (100, "éç†æ€§ç¹è£ï¼Œæ­¤æ—¶ä¸è·‘æ›´å¾…ä½•æ—¶")
    ]

    # Find closest
    for threshold, desc in reversed(descriptions):
        if score >= threshold:
            return desc
    return descriptions[0][1]


def detect_divergence(market_data: Dict[str, Any], sentiment_score: float) -> List[str]:
    """
    Detect divergence between Price/Volume and Sentiment.
    """
    divergences = []

    # Extract data
    indices = market_data['indices']
    avg_index_change = sum(indices.values()) / len(indices) if indices else 0
    vol_change = market_data['volume']['change_pct']

    # 1. Price vs Sentiment Divergence
    # Price rising but Sentiment falling (or Low) -> Weak Rally?
    # Usually Sentiment follows Price.
    # Check: Price Rising (>1%) but Sentiment Low (<40) -> Disbelief Rally (Potential Bullish)
    if avg_index_change > 1.0 and sentiment_score < 40:
        divergences.append("é‡ä»·èƒŒç¦»ï¼šæŒ‡æ•°å¤§æ¶¨ä½†æƒ…ç»ªä½è¿·ï¼Œå¾€å¾€æ˜¯è¡Œæƒ…çš„åˆæœŸï¼ˆçŠ¹è±«ä¸­ä¸Šæ¶¨ï¼‰ã€‚")

    # Price Falling (<-1%) but Sentiment High (>60) -> Denial (Potential Bearish)
    if avg_index_change < -1.0 and sentiment_score > 60:
        divergences.append("æƒ…ç»ªèƒŒç¦»ï¼šæŒ‡æ•°ä¸‹è·Œä½†æƒ…ç»ªä¾ç„¶é«˜æ¶¨ï¼Œéœ€è­¦æƒ•è¡¥è·Œé£é™©ã€‚")

    # 2. Volume vs Price Divergence
    # Price Up (>1%) but Volume Down (<-10%) -> é‡ä»·èƒŒç¦» (Bearish)
    if avg_index_change > 1.0 and vol_change < -10:
        divergences.append("ç¼©é‡ä¸Šæ¶¨ï¼šæŒ‡æ•°ä¸Šè¡Œä½†æˆäº¤å¤§å¹…èç¼©ï¼Œä¸Šæ”»åŠ¨èƒ½ä¸è¶³ã€‚")

    # Price Down (<-1%) but Volume Down (<-10%) -> ç¼©é‡ä¸‹è·Œ (Neutral/Bullish if finding bottom)
    if avg_index_change < -1.0 and vol_change < -10:
        divergences.append("ç¼©é‡ä¸‹è·Œï¼šæŠ›å‹é€æ­¥è¡°ç«­ï¼Œå¯èƒ½æ¥è¿‘çŸ­æœŸåº•éƒ¨ã€‚")

    return divergences


def calculate_sentiment_index(market_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Calculate the Greed & Fear Index (0-100) based on market data.

    Algorithm:
    - Base Score: 50
    - Market Breadth (25%): Limit Up/Down
    - Indices Trend (25%): Major Indices
    - News Sentiment (15%): Bullish/Bearish News
    - Money Flow (20%): Sector Inflows
    - Valuation (15%): PE Score (New)

    Args:
        market_data: Aggregated market data dictionary

    Returns:
        Dictionary with index value and breakdown
    """
    base_score = 50
    scores = {}

    # 1. Market Breadth Score (25%) - Range: -12.5 to +12.5
    limit_up = market_data['limit_up_count']
    limit_down = market_data['limit_down_count']
    total_limit = limit_up + limit_down

    if total_limit > 0:
        breadth_ratio = (limit_up - limit_down) / total_limit
        breadth_score = breadth_ratio * 12.5
    else:
        breadth_score = 0
    scores['market_breadth'] = round(breadth_score, 2)

    # 2. Indices Trend Score (25%) - Range: -12.5 to +12.5
    indices = market_data['indices']
    weights = {"ä¸Šè¯50": 0.2, "æ²ªæ·±300": 0.3, "ä¸­è¯500": 0.3, "ä¸­è¯2000": 0.2}
    weighted_change = sum(indices.get(name, 0) * weight for name, weight in weights.items())
    indices_score = max(-12.5, min(12.5, weighted_change * 4)) # Scale
    scores['indices_trend'] = round(indices_score, 2)

    # 3. News Sentiment Score (15%) - Range: -7.5 to +7.5
    news = market_data['news_sentiment']
    bullish = news['bullish_count']
    bearish = news['bearish_count']
    total_news = bullish + bearish

    if total_news > 0:
        news_ratio = (bullish - bearish) / total_news
        news_score = news_ratio * 7.5
    else:
        news_score = 0
    scores['news_sentiment'] = round(news_score, 2)

    # 4. Money Flow Score (20%) - Range: -10 to +10
    net_inflow = market_data['sector_flow']['net_inflow']
    flow_score = max(-10, min(10, net_inflow / 1e9))
    scores['money_flow'] = round(flow_score, 2)

    # 5. Valuation Score (15%) - Range: -7.5 to +7.5
    # Valuation score from get_market_valuation is 0-10.
    # Center at 5. (Score - 5) * 1.5 -> Range approx -7.5 to +7.5
    val_data = market_data['valuation']
    raw_val_score = val_data.get('valuation_score', 5)
    val_score_centered = (raw_val_score - 5) * 1.5
    scores['valuation'] = round(val_score_centered, 2)

    # Calculate final index
    final_index = base_score + sum(scores.values())
    final_index = max(0, min(100, round(final_index, 1)))

    # Determine sentiment level and detailed description
    description = get_sentiment_description(final_index)

    if final_index >= 80:
        sentiment_level = "æåº¦è´ªå©ª"
        color = "red"
    elif final_index >= 60:
        sentiment_level = "è´ªå©ª"
        color = "orange"
    elif final_index >= 40:
        sentiment_level = "ä¸­æ€§"
        color = "yellow"
    elif final_index >= 20:
        sentiment_level = "ææƒ§"
        color = "blue"
    else:
        sentiment_level = "æåº¦ææƒ§"
        color = "dark_blue"

    # Detect Divergences
    divergences = detect_divergence(market_data, final_index)

    return {
        "index": final_index,
        "sentiment_level": sentiment_level,
        "sentiment_description": description,
        "divergences": divergences,
        "color": color,
        "score_breakdown": scores,
        "raw_data": market_data
    }


def generate_prompt_content(result: Dict[str, Any], market_data: Dict[str, Any], date_str: str = None) -> str:
    """Generate AI Prompt content"""
    idx = result['index']
    level = result['sentiment_level']
    desc = result.get('sentiment_description', '')
    divergences = result.get('divergences', [])

    breadth = result['score_breakdown']['market_breadth']
    indices_trend = result['score_breakdown']['indices_trend']
    news_score = result['score_breakdown']['news_sentiment']
    flow_score = result['score_breakdown']['money_flow']
    val_score = result['score_breakdown']['valuation']

    limit_up = market_data['limit_up_count']
    limit_down = market_data['limit_down_count']

    bullish = market_data['news_sentiment']['bullish_count']
    bearish = market_data['news_sentiment']['bearish_count']

    net_inflow = market_data['sector_flow']['net_inflow'] / 1e8
    inflow_sectors = market_data['sector_flow']['inflow_sectors'][:3]
    outflow_sectors = market_data['sector_flow']['outflow_sectors'][:3]

    pe_sh = market_data['valuation']['pe_sh']
    pe_sz = market_data['valuation']['pe_sz']

    # Volume data
    vol_today = market_data['volume']['today_volume'] / 1e8
    vol_yesterday = market_data['volume']['yesterday_volume'] / 1e8
    vol_change = market_data['volume']['change_pct']

    if vol_today == 0:
        vol_desc = "æš‚æ— æ•°æ®"
        vol_change_desc = "æ•°æ®ç¼ºå¤±"
        vol_trend_desc = "æ— æ³•åˆ¤æ–­"
    elif vol_change == 0 and vol_yesterday == 0:
        # Yesterday data unavailable, don't show percentage
        vol_desc = ""
        vol_change_desc = ""
        vol_trend_desc = "æˆäº¤é¢æ­£å¸¸"
    else:
        vol_desc = f"æ”¾é‡{vol_change:.1f}%" if vol_change > 0 else f"ç¼©é‡{abs(vol_change):.1f}%"
        vol_change_desc = "çº¢è‰²" if vol_change > 5 else "ç»¿è‰²" if vol_change < -5 else "é»„è‰²"
        vol_trend_desc = "æˆäº¤é¢æ˜¾è‘—æ”¾å¤§" if vol_change > 10 else "æˆäº¤é¢å°å¹…æ”¾å¤§" if vol_change > 0 else "ç¼©é‡éœ‡è¡" if vol_change > -10 else "æˆäº¤é¢å¤§å¹…èç¼©"

    # Conditional strings
    idx_color = "çº¢è‰²ç²—ä½“" if idx >= 70 else "æ©™è‰²ç²—ä½“" if idx >= 55 else "é»„è‰²ç²—ä½“"
    level_color = "æ©™çº¢è‰²æ ‡ç­¾" if idx >= 70 else "æ©™è‰²æ ‡ç­¾"
    breadth_desc = "æ¶¨åœå®¶æ•°è¿œè¶…è·Œåœ" if limit_up > limit_down * 3 else "æ¶¨è·Œåœç›¸å¯¹å‡è¡¡"
    indices_desc = "ä¸»æµæŒ‡æ•°å…¨çº¿é£˜çº¢" if indices_trend > 2 else "æŒ‡æ•°æ•´ä½“å¹³ç¨³" if indices_trend > -2 else "æŒ‡æ•°é›†ä½“è°ƒæ•´"
    news_desc = "æ­£é¢æ–°é—»å ä¼˜" if news_score > 2 else "æ–°é—»æƒ…ç»ªä¸­æ€§" if news_score > -2 else "è´Ÿé¢æ–°é—»å¢å¤š"

    warning_emoji = "âš ï¸" if flow_score < -5 else ""
    flow_desc = "å‡€æµå‡º" if net_inflow < 0 else "å‡€æµå…¥"
    flow_color = "çº¢è‰²è­¦å‘Š" if net_inflow < -300 else "ç»¿è‰²" if net_inflow > 300 else "ä¸­æ€§"

    # Build prompt
    prompt = f"""# å¸‚åœºæƒ…ç»ªæŒ‡æ•° - AIç»˜å›¾Prompt ({datetime.now().strftime("%mæœˆ%dæ—¥")})
# æ•°æ®æ¥æº: æè´ªæŒ‡æ•°æ¨¡å‹ (5ç»´åº¦ç»¼åˆè¯„åˆ†)

## å›¾ç‰‡è§„æ ¼
- æ¯”ä¾‹: 9:16 ç«–ç‰ˆ
- é£æ ¼: æ‰‹ç»˜/æ‰‹è´¦é£æ ¼ï¼Œæš–è‰²çº¸å¼ è´¨æ„Ÿ
- èƒŒæ™¯è‰²: #F5E6C8 çº¸é»„è‰²
- é…è‰²: è´ªå©ª=çº¢è‰²æ¸å˜, ææƒ§=è“è‰²æ¸å˜

## æ ‡é¢˜
**ğŸ“Š Aè‚¡æè´ªæŒ‡æ•° | Market Greed & Fear** (å±…ä¸­ï¼Œæ‰‹ç»˜å­—ä½“)
**{date_str or datetime.now().strftime("%Y-%m-%d")}**

---

## æ ¸å¿ƒæŒ‡æ ‡ (å¤§å·æ˜¾ç¤º)
**æè´ªæŒ‡æ•°: {idx}/100** ({idx_color})
**æƒ…ç»ªç­‰çº§: {level}** ({level_color})
**å¸‚åœºçŠ¶æ€: {desc}**

---

## äº”ç»´åº¦è¯„åˆ†å¯è§†åŒ– (é›·è¾¾å›¾/è¿›åº¦æ¡)

### 1. å¸‚åœºå®½åº¦ (Breadth) {breadth:+.2f}
- æ¶¨åœ: {limit_up} vs è·Œåœ: {limit_down}
- è¯´æ˜: {breadth_desc}

### 2. æŒ‡æ•°è¶‹åŠ¿ (Trend) {indices_trend:+.2f}
"""

    for idx_name, change in market_data['indices'].items():
        arrow = "â†‘" if change > 0 else "â†“" if change < 0 else "â†’"
        prompt += f"- {idx_name}: {change:+.2f}% {arrow}\n"

    prompt += f"- è¯´æ˜: {indices_desc}\n\n"

    prompt += f"""### 3. æ–°é—»æƒ…ç»ª (News) {news_score:+.2f}
- åˆ©å¤š: {bullish} vs åˆ©ç©º: {bearish}
- è¯´æ˜: {news_desc}

### 4. èµ„é‡‘æµå‘ (Flow) {flow_score:+.2f} {warning_emoji}
- {flow_desc}: **{abs(net_inflow):.2f} äº¿** ({flow_color})
"""
    if inflow_sectors:
        sector_list = "ã€".join([f"{s['åç§°']}" for s in inflow_sectors])
        prompt += f"- æµå…¥: {sector_list}\n"

    prompt += f"""
### 5. å¸‚åœºä¼°å€¼ (Valuation) {val_score:+.2f}
- ä¸Šè¯PE: {pe_sh:.2f} | æ·±è¯PE: {pe_sz:.2f}
- çŠ¶æ€: {"ä¼°å€¼åé«˜" if val_score > 3 else "ä¼°å€¼åä½" if val_score < -3 else "ä¼°å€¼é€‚ä¸­"}

---

### 6. æˆäº¤é¢ (Volume)
- ä»Šæ—¥: **{vol_today:.0f} äº¿**{f' ({vol_desc})' if vol_desc else ''}
- è¯´æ˜: {vol_trend_desc}
"""

    # Divergence section
    if divergences:
        prompt += "\n## âš ï¸ å…³é”®èƒŒç¦»ä¿¡å·\n"
        for div in divergences:
            prompt += f"- **{div}**\n"

    prompt += f"""
---

## æƒ…ç»ªè§£è¯» (æ‰‹å†™ä½“æ–‡å­—æ¡†)
> **å½“å‰å¤„äº"{level}"åŒºé—´**
> **"{desc}"**
"""

    # Interpretation
    if idx >= 80:
        interpretation = "å¸‚åœºæåº¦äº¢å¥‹ï¼Œéšæ—¶å¯èƒ½é¢ä¸´å‰§çƒˆæ³¢åŠ¨ï¼Œåˆ‡å‹¿ç›²ç›®è¿½é«˜ã€‚"
    elif idx >= 60:
        interpretation = f"å¸‚åœºæƒ…ç»ªç§¯æï¼Œ{vol_desc}ï¼Œèµšé’±æ•ˆåº”è¾ƒå¥½ã€‚"
    elif idx <= 20:
        interpretation = "å¸‚åœºæåº¦æ‚²è§‚ï¼Œææ…Œç›˜æ¶Œå‡ºï¼Œæˆ–æ˜¯å·¦ä¾§å¸ƒå±€è‰¯æœºã€‚"
    else:
        interpretation = f"å¸‚åœºæƒ…ç»ªç›¸å¯¹å¹³ç¨³ï¼Œ{vol_desc}ï¼Œç»“æ„æ€§æœºä¼šä¸ºä¸»ã€‚"

    prompt += f"> {interpretation}\n"

    prompt += f"""
---

## æŠ•èµ„å»ºè®®
âœ… **æ“ä½œ**: {"è§‚æœ›ä¸ºä¸» | ä¸¥æ§ä»“ä½" if net_inflow < -300 else "æŒè‚¡å¾…æ¶¨ | é€¢ä½å¸çº³" if idx < 40 else "å»å¼±ç•™å¼º | é¡ºåŠ¿è€Œä¸º"}
âš ï¸ **é£é™©**: {"èµ„é‡‘å¤§å¹…æµå‡ºï¼Œå°å¿ƒå›è°ƒ" if net_inflow < -300 else "é«˜ä½è‚¡åˆ†åŒ–é£é™©" if idx > 70 else "åº•éƒ¨éœ‡è¡ï¼Œè€å¿ƒç­‰å¾…"}

---

## Footer
"æ¯æ—¥æè´ªæŒ‡æ•° | AIé‡åŒ–æƒ…ç»ªæ¨¡å‹"

---

## AIç»˜å›¾Prompt (Midjourney/SD)

(masterpiece, best quality), (vertical:1.2), (aspect ratio: 9:16), (sketch style), (hand drawn), (infographic)

Create a TALL VERTICAL PORTRAIT IMAGE (Aspect Ratio 9:16) HAND-DRAWN SKETCH style stock market sentiment infographic poster.

**Layout Structure**:
1. **Top Section**: A large vintage MAIN GAUGE (Speedometer style) pointing to {idx} ({level}).
2. **Middle Section**: A PROMINENT HEXAGONAL RADAR CHART (å…­è¾¹å½¢é›·è¾¾å›¾) showing 5 dimensions:
   - Dimension 1 (Market Breadth): Score {breadth:+.1f} - {'Strong' if breadth > 5 else 'Weak' if breadth < -5 else 'Neutral'}
   - Dimension 2 (Index Trend): Score {indices_trend:+.1f} - {'Bullish' if indices_trend > 2 else 'Bearish' if indices_trend < -2 else 'Flat'}
   - Dimension 3 (Money Flow): Score {flow_score:+.1f} - {'Inflow' if flow_score > 0 else 'Outflow'}
   - Dimension 4 (News Sentiment): Score {news_score:+.1f} - {'Positive' if news_score > 2 else 'Negative' if news_score < -2 else 'Neutral'}
   - Dimension 5 (Valuation): Score {val_score:+.1f} - {'Expensive' if val_score > 3 else 'Cheap' if val_score < -3 else 'Fair'}
   - **Chart Style**: Hand-drawn hexagon with 5 axes radiating from center, filled area shows current scores
   - **Color**: Use {'fiery red' if idx >= 80 else 'warm orange' if idx >= 60 else 'calm yellow' if idx >= 40 else 'cool blue' if idx >= 20 else 'deep cold blue'} tones, with filled area showing intensity
3. **Background**: {'fiery red tones, burning background' if idx >= 80 else 'warm orange tones, bright background' if idx >= 60 else 'neutral yellow tones, balanced composition' if idx >= 40 else 'cool blue tones, calm background' if idx >= 20 else 'deep cold blue tones, icy background'}, aged paper texture, ink sketch lines.

**Visual Details**:
- Style: Da Vinci engineering sketch, complex mechanical details, infographic layout.
- **IMPORTANT**: The hexagonal radar chart MUST be the dominant visual element in the middle section.
- Color Palette: {'excitement, frenzy' if idx >= 80 else 'optimistic, positive' if idx >= 60 else 'calm, waiting' if idx >= 40 else 'cautious, worried' if idx >= 20 else 'panic, extreme pessimism'} tones on parchment paper.
- Textures: Crosshatching, ink splatters, rough paper grain.
- No digital text, just visual representations of data.

--ar 9:16 --style raw --v 6
"""
    return prompt


def run_analysis(date_str: str = None) -> Dict[str, Any]:
    """
    Main entry point for market sentiment analysis.

    Args:
        date_str: Date string in YYYYMMDD format. If None, uses today.

    Returns:
        Sentiment analysis result dictionary
    """
    print(f"Running market sentiment analysis for {date_str or 'today'}...")

    # Aggregate market data
    market_data = aggregate_market_data(date_str)

    # Calculate sentiment index
    result = calculate_sentiment_index(market_data)

    # Generate and save prompt
    date_s = date_str or datetime.now().strftime("%Y%m%d")
    output_dir = os.path.join("results", date_s, "AIæç¤ºè¯")
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "å¸‚åœºæƒ…ç»ª_Prompt.txt")

    prompt_content = generate_prompt_content(result, market_data, date_s)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(prompt_content)

    print(f"\nâœ… Analysis complete: {result['index']}/100 ({result['sentiment_level']})")
    print(f"ğŸ“„ Prompt saved to: {output_path}")

    # DISABLED: No longer generate intermediate files
    # The final å¸‚åœºæƒ…ç»ª_Prompt.txt now contains the complete Midjourney/SD prompt with hexagonal radar chart

    # Generate Image using API (Use Raw English Prompt)
    raw_image_prompt = get_raw_image_prompt(result)
    image_output_dir = os.path.join("results", date_s, "images")
    os.makedirs(image_output_dir, exist_ok=True)
    image_output_path = os.path.join(image_output_dir, "market_sentiment_cover.png")

    print("\nğŸ¨ Generating Market Sentiment Cover Image...")
    generate_image_from_text(raw_image_prompt, image_output_path)

    return result


if __name__ == "__main__":
    # Run analysis and save results
    run_analysis()
