"""
Market Sentiment Analysis - Core Logic
Aggregates market data and calculates Greed & Fear Index (0-100).
"""

import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any
import sys
import os
import requests
import re

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from modules.fish_basin.fish_basin import fetch_data
from modules.market_ladder.limit_up_ladder import get_limit_up_data
from modules.core_news.core_news_monitor import fetch_eastmoney_data


def get_limit_down_count(date_str: str = None) -> int:
    """
    Get the count of limit down stocks for a given date.

    Args:
        date_str: Date string in YYYYMMDD format. If None, uses today.

    Returns:
        Count of limit down stocks
    """
    try:
        # Get limit down pool from akshare
        df = ak.stock_zt_pool_dtgc_em(date=date_str or datetime.now().strftime("%Y%m%d"))
        return len(df) if df is not None and not df.empty else 0
    except Exception as e:
        print(f"Error fetching limit down data: {e}")
        return 0


def get_volume_from_previous_prompt(date_str: str) -> float:
    """
    Try to get volume from previous day's prompt file.

    Args:
        date_str: Date string in YYYYMMDD format.

    Returns:
        Volume in Yuan (float) or 0.0 if not found
    """
    try:
        if not date_str:
            date_str = datetime.now().strftime("%Y%m%d")

        current_date = datetime.strptime(date_str, "%Y%m%d")
        prev_date = current_date - timedelta(days=1)
        prev_date_str = prev_date.strftime("%Y%m%d")

        file_path = os.path.join("results", prev_date_str, "AIæç¤ºè¯", "å¸‚åœºæƒ…ç»ª_Prompt.txt")

        if not os.path.exists(file_path):
            # Try checking absolute path if relative path fails or debug info
            # print(f"   Previous prompt file not found: {file_path}")
            return 0.0

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Regex search for ä»Šæ—¥æˆäº¤: **(\d+) äº¿**
        match = re.search(r"ä»Šæ—¥æˆäº¤: \*\*(\d+) äº¿\*\*", content)
        if match:
            vol_yi = float(match.group(1))
            print(f"   Recovered volume from file ({prev_date_str}): {vol_yi}äº¿")
            return vol_yi * 1e8

        return 0.0
    except Exception as e:
        print(f"   Error reading previous prompt: {e}")
        return 0.0



def get_market_volume_sina() -> float:
    """
    Fetch real-time market volume (SH + SZ) from Sina Finance.
    Returns total volume in Yuan (float).
    Returns 0.0 if failed.
    """
    url = "http://hq.sinajs.cn/list=s_sh000001,s_sz399001"
    headers = {"Referer": "https://finance.sina.com.cn/"}
    
    print("ğŸ“Š Fetching Real-time Volume from Sina Finance...")
    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.encoding = 'gbk'
        data = response.text
        
        # Parse response
        # var hq_str_s_sh000001="Name,Price,Chg,Pct,Vol,Turnover(Wan)";
        total_volume = 0.0
        parsed_count = 0
        
        lines = data.strip().split('\n')
        for line in lines:
            if 'hq_str_s_' not in line:
                continue
            
            parts = line.split('=')
            if len(parts) < 2:
                continue
                
            content = parts[1].strip('";')
            fields = content.split(',')
            
            if len(fields) >= 6:
                # Index 5 is Turnover in Wan
                try:
                    vol_wan = float(fields[5])
                    vol_yuan = vol_wan * 10000
                    total_volume += vol_yuan
                    parsed_count += 1
                except ValueError:
                    continue
        
        if parsed_count == 2: # Should have both SH and SZ
            print(f"âœ… Sina Volume: {total_volume/1e8:.0f}äº¿")
            return total_volume
        else:
            print(f"âš ï¸ Sina data incomplete (parsed {parsed_count} indices)")
            return 0.0
            
    except Exception as e:
        print(f"âŒ Error fetching Sina volume: {e}")
        return 0.0


def get_market_volume(date_str: str = None) -> Dict[str, float]:
    """
    Get market turnover volume for today and yesterday.
    Primary: Sina (for Today) + AkShare (for Yesterday).
    Fallback: AkShare (for both).

    Returns:
        Dictionary with today_volume, yesterday_volume, change_pct (Volumes in Yuan)
    """
    target_date = date_str or datetime.now().strftime("%Y%m%d")
    is_today = (target_date == datetime.now().strftime("%Y%m%d"))
    
    # 1. Fetch Historical Data (AkShare) to get Yesterday's volume
    # We always need this for comparison
    end_dt = datetime.strptime(target_date, "%Y%m%d")
    start_dt = end_dt - timedelta(days=15) # 15 days back to be safe
    start_date_s = start_dt.strftime("%Y%m%d")
    
    yesterday_vol = 0.0
    ak_today_vol = 0.0
    
    print(f"ğŸ“Š Fetching History for comparison ({start_date_s} - {target_date})...")
    
    try:
        df_sh = ak.index_zh_a_hist(symbol="000001", period="daily", start_date=start_date_s, end_date=target_date)
        df_sz = ak.index_zh_a_hist(symbol="399001", period="daily", start_date=start_date_s, end_date=target_date)
        
        if df_sh is not None and not df_sh.empty and df_sz is not None and not df_sz.empty:
             # Standardize dates
            df_sh['date_str'] = pd.to_datetime(df_sh['æ—¥æœŸ']).dt.strftime("%Y%m%d")
            df_sz['date_str'] = pd.to_datetime(df_sz['æ—¥æœŸ']).dt.strftime("%Y%m%d")

            # Merge
            df = pd.merge(df_sh[['date_str', 'æˆäº¤é¢']], df_sz[['date_str', 'æˆäº¤é¢']], on='date_str', suffixes=('_sh', '_sz'))
            df['total_vol'] = df['æˆäº¤é¢_sh'] + df['æˆäº¤é¢_sz']
            df = df.sort_values('date_str')
            
            # Identify Yesterday
            # If target_date is in df, yesterday is the row before it
            # If target_date is NOT in df (e.g. today during trading), yesterday is the last row
            
            row_target = df[df['date_str'] == target_date]
            
            if not row_target.empty:
                # Target date exists in history (e.g. backtesting or after close)
                ak_today_vol = float(row_target.iloc[0]['total_vol'])
                
                # Get previous row
                idx = df.index[df['date_str'] == target_date].tolist()[0]
                # Since we sorted by date_str, but the index might not be sequential integers if we didn't reset
                # Let's rely on position
                pos = df.index.get_loc(idx)
                if pos > 0:
                    yesterday_vol = float(df.iloc[pos - 1]['total_vol'])
            else:
                # Target date not in history (likely today during trading)
                # Then the last row in df is the most recent trading day (Yesterday)
                if not df.empty:
                    yesterday_vol = float(df.iloc[-1]['total_vol'])
                    print(f"   Using latest history ({df.iloc[-1]['date_str']}) as Yesterday.")
                    
    except Exception as e:
        print(f"âš ï¸ Error fetching history from AkShare: {e}")

    # Fallback if yesterday_vol is still 0
    if yesterday_vol == 0:
        print("   Trying to fetch yesterday's volume from previous prompt...")
        yesterday_vol = get_volume_from_previous_prompt(target_date)

    # 2. Get Today's Volume
    today_vol = 0.0
    
    if is_today:
        # Try Sina First
        sina_vol = get_market_volume_sina()
        if sina_vol > 0:
            today_vol = sina_vol
        else:
            print("   Sina failed, falling back to AkShare for today...")
            today_vol = ak_today_vol
    else:
        # Not today (Backtesting), must use AkShare
        today_vol = ak_today_vol

    # 3. Calculate Change
    change_pct = 0.0
    if yesterday_vol > 0:
        change_pct = ((today_vol - yesterday_vol) / yesterday_vol) * 100
        
    print(f"âœ… Final Volume: Today={today_vol/1e8:.0f}äº¿, Yesterday={yesterday_vol/1e8:.0f}äº¿, Change={change_pct:+.2f}%")
    
    return {
        "today_volume": today_vol,
        "yesterday_volume": yesterday_vol,
        "change_pct": round(change_pct, 2)
    }


def get_indices_performance() -> Dict[str, float]:
    """
    Get performance (% change) for major indices.
    
    Returns:
        Dictionary with index names and their % changes
    """
    indices = {
        "ä¸Šè¯50": "sh000016",
        "æ²ªæ·±300": "sh000300",
        "ä¸­è¯500": "sh000905",
        "ä¸­è¯2000": "sh932000"
    }
    
    performance = {}
    
    for name, code in indices.items():
        try:
            df = fetch_data(name, code)
            if df is not None and not df.empty and len(df) >= 2:
                latest = df.iloc[-1]['close']
                previous = df.iloc[-2]['close']
                pct_change = ((latest - previous) / previous) * 100
                performance[name] = round(pct_change, 2)
            else:
                performance[name] = 0.0
        except Exception as e:
            print(f"Error fetching {name} performance: {e}")
            performance[name] = 0.0
    
    return performance


def get_market_news_sentiment() -> Dict[str, Any]:
    """
    Analyze news sentiment from core news.
    
    Returns:
        Dictionary with bullish/bearish counts and sample headlines
    """
    try:
        # Fetch news from last 24 hours
        news_data = fetch_eastmoney_data(target_window_hours=24)
        
        if not news_data:
            return {
                "bullish_count": 0,
                "bearish_count": 0,
                "neutral_count": 0,
                "bullish_news": [],
                "bearish_news": []
            }
        
        # Simple sentiment classification based on keywords
        bullish_keywords = ['ä¸Šæ¶¨', 'åˆ©å¥½', 'çªç ´', 'åˆ›æ–°é«˜', 'å¤§æ¶¨', 'æš´æ¶¨', 'æ¶¨åœ', 'ç‰›å¸‚', 'çœ‹å¤š']
        bearish_keywords = ['ä¸‹è·Œ', 'åˆ©ç©º', 'è·Œç ´', 'åˆ›æ–°ä½', 'å¤§è·Œ', 'æš´è·Œ', 'è·Œåœ', 'ç†Šå¸‚', 'çœ‹ç©º']
        
        bullish_news = []
        bearish_news = []
        neutral_count = 0
        
        for item in news_data:
            title = item.get('title', '')
            
            is_bullish = any(kw in title for kw in bullish_keywords)
            is_bearish = any(kw in title for kw in bearish_keywords)
            
            if is_bullish and not is_bearish:
                bullish_news.append(title)
            elif is_bearish and not is_bullish:
                bearish_news.append(title)
            else:
                neutral_count += 1
        
        return {
            "bullish_count": len(bullish_news),
            "bearish_count": len(bearish_news),
            "neutral_count": neutral_count,
            "bullish_news": bullish_news[:5],  # Top 5
            "bearish_news": bearish_news[:5]   # Top 5
        }
    
    except Exception as e:
        print(f"Error analyzing news sentiment: {e}")
        return {
            "bullish_count": 0,
            "bearish_count": 0,
            "neutral_count": 0,
            "bullish_news": [],
            "bearish_news": []
        }


def get_sector_flow() -> Dict[str, Any]:
    """
    Get sector fund flow data.
    Multi-source: ä¸œè´¢ API â†’ åŒèŠ±é¡º â†’ æ–‡ä»¶è§£æ
    
    Returns:
        Dictionary with net inflow and top flowing sectors
    """
    # Source 1: ä¸œè´¢ (Eastmoney) API
    try:
        print("ğŸ’° Trying Source 1: Eastmoney API for money flow...")
        df = ak.stock_sector_fund_flow_rank(indicator="ä»Šæ—¥")
        
        if df is None or df.empty:
            raise Exception("API returned empty data")
        
        # Calculate total net inflow
        net_inflow = df['å‡€é¢'].sum() if 'å‡€é¢' in df.columns else 0
        
        # Get top 3 inflow and outflow sectors
        df_sorted = df.sort_values('å‡€é¢', ascending=False)
        inflow_sectors = df_sorted.head(3)[['åç§°', 'å‡€é¢']].to_dict('records') if len(df_sorted) > 0 else []
        outflow_sectors = df_sorted.tail(3)[['åç§°', 'å‡€é¢']].to_dict('records') if len(df_sorted) > 0 else []
        
        print(f"âœ… Eastmoney money flow: Net {net_inflow/1e8:.0f}äº¿, {len(inflow_sectors)} inflows, {len(outflow_sectors)} outflows")
        return {
            "net_inflow": net_inflow,
            "inflow_sectors": inflow_sectors,
            "outflow_sectors": outflow_sectors
        }
    except Exception as e:
        print(f"âŒ Eastmoney API failed: {e}")
    
    # Source 2: åŒèŠ±é¡º (Tonghuashun) - try alternative approach
    try:
        print("ğŸ’° Trying Source 2: Tonghuashun for money flow...")
        # Use stock_sector_fund_flow_rank with alternative params
        df = ak.stock_fund_flow_individual(symbol="000001")
        if df is not None and not df.empty:
            # This is a fallback, data might not be perfect
            print(f"âš ï¸ Tonghuashun returned limited data, trying file parsing...")
            raise Exception("Tonghuashun data insufficient")
    except Exception as e:
        print(f"âŒ Tonghuashun failed: {e}")
    
    # Source 3: æ–‡ä»¶è§£æ (File parsing from existing prompt)
    try:
        print("ğŸ’° Trying Source 3: File parsing for money flow...")
        import re
        today = datetime.now().strftime("%Y%m%d")
        prompt_file = os.path.join("results", today, "AIæç¤ºè¯", "èµ„é‡‘æµå‘_Prompt.txt")
        
        if not os.path.exists(prompt_file):
            raise FileNotFoundError(f"Prompt file not found: {prompt_file}")
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract inflow sectors and amounts
        # Extract inflow sectors and amounts
        # Improved Regex to capture Clean Names:  **"é“¶è¡Œ"** or "é“¶è¡Œ"
        sector_pattern = r'["\']?([\u4e00-\u9fa5]+)["\']?[^+]*?\+([0-9.]+)äº¿'
        sector_matches = re.findall(sector_pattern, content)
        
        # Extract outflow data
        outflow_pattern = r'([\u4e00-\u9fa5]+)\s*\(-([0-9.]+)äº¿\)'
        outflow_matches = re.findall(outflow_pattern, content)
        
        inflow_sectors = [{'åç§°': name.strip(), 'å‡€é¢': float(val) * 1e8} for name, val in sector_matches if name.strip()][:3]
        outflow_sectors = [{'åç§°': name.strip(), 'å‡€é¢': -float(val) * 1e8} for name, val in outflow_matches if name.strip()][:3]
        
        # Calculate net inflow
        net_inflow = sum(s['å‡€é¢'] for s in inflow_sectors) + sum(s['å‡€é¢'] for s in outflow_sectors)
        
        print(f"âœ… File parsing: Net {net_inflow/1e8:.0f}äº¿, {len(inflow_sectors)} inflows, {len(outflow_sectors)} outflows")
        if inflow_sectors:
            print(f"   Inflows: {[s['åç§°'] for s in inflow_sectors]}")
        if outflow_sectors:
            print(f"   Outflows: {[s['åç§°'] for s in outflow_sectors]}")
        
        return {
            "net_inflow": net_inflow,
            "inflow_sectors": inflow_sectors,
            "outflow_sectors": outflow_sectors
        }
    
    except Exception as e2:
        print(f"âŒ File parsing also failed: {e2}")
    
    print("âŒ All money flow sources failed, returning zeros")
    return {
        "net_inflow": 0,
        "inflow_sectors": [],
        "outflow_sectors": []
    }


def aggregate_market_data(date_str: str = None) -> Dict[str, Any]:
    """
    Aggregate all market data needed for sentiment analysis.
    
    Returns:
        Dictionary containing all aggregated market data
    """
    print("Aggregating market data...")
    
    # Get all data sources
    indices_perf = get_indices_performance()
    
    # Limit Up
    df_zt, _, _ = get_limit_up_data(date_str or datetime.now().strftime("%Y%m%d"))
    limit_up_count = len(df_zt) if df_zt is not None else 0
    
    limit_down_count = get_limit_down_count(date_str)
    news_sentiment = get_market_news_sentiment()
    sector_flow = get_sector_flow()
    volume_data = get_market_volume(date_str)
    
    data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "indices": indices_perf,
        "limit_up_count": limit_up_count,
        "limit_down_count": limit_down_count,
        "news_sentiment": news_sentiment,
        "sector_flow": sector_flow,
        "volume": volume_data
    }
    
    print("Market data aggregation complete.")
    return data


def calculate_sentiment_index(market_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Calculate the Greed & Fear Index (0-100) based on market data.
    
    Algorithm:
    - Base Score: 50
    - Market Breadth (30%): Based on limit up/down ratio
    - Indices Trend (30%): Weighted average of major indices
    - News Sentiment (20%): Balance of bullish/bearish news
    - Money Flow (20%): Net sector inflows
    
    Args:
        market_data: Aggregated market data dictionary
    
    Returns:
        Dictionary with index value and breakdown
    """
    base_score = 50
    scores = {}
    
    # 1. Market Breadth Score (30%) - Range: -15 to +15
    limit_up = market_data['limit_up_count']
    limit_down = market_data['limit_down_count']
    total_limit = limit_up + limit_down
    
    if total_limit > 0:
        breadth_ratio = (limit_up - limit_down) / total_limit
        breadth_score = breadth_ratio * 15  # Scale to -15 to +15
    else:
        breadth_score = 0
    
    scores['market_breadth'] = round(breadth_score, 2)
    
    # 2. Indices Trend Score (30%) - Range: -15 to +15
    indices = market_data['indices']
    weights = {
        "ä¸Šè¯50": 0.2,
        "æ²ªæ·±300": 0.3,
        "ä¸­è¯500": 0.3,
        "ä¸­è¯2000": 0.2
    }
    
    weighted_change = sum(indices.get(name, 0) * weight for name, weight in weights.items())
    # Normalize: assume -3% to +3% maps to -15 to +15
    indices_score = max(-15, min(15, weighted_change * 5))
    scores['indices_trend'] = round(indices_score, 2)
    
    # 3. News Sentiment Score (20%) - Range: -10 to +10
    news = market_data['news_sentiment']
    bullish = news['bullish_count']
    bearish = news['bearish_count']
    total_news = bullish + bearish
    
    if total_news > 0:
        news_ratio = (bullish - bearish) / total_news
        news_score = news_ratio * 10
    else:
        news_score = 0
    
    scores['news_sentiment'] = round(news_score, 2)
    
    # 4. Money Flow Score (20%) - Range: -10 to +10
    net_inflow = market_data['sector_flow']['net_inflow']
    # Normalize: assume -100äº¿ to +100äº¿ maps to -10 to +10
    flow_score = max(-10, min(10, net_inflow / 1e9))
    scores['money_flow'] = round(flow_score, 2)
    
    # Calculate final index
    final_index = base_score + sum(scores.values())
    final_index = max(0, min(100, round(final_index, 1)))  # Clamp to 0-100
    
    # Determine sentiment level
    if final_index >= 70:
        sentiment_level = "æåº¦è´ªå©ª"
        color = "red"
    elif final_index >= 55:
        sentiment_level = "è´ªå©ª"
        color = "orange"
    elif final_index >= 45:
        sentiment_level = "ä¸­æ€§"
        color = "yellow"
    elif final_index >= 30:
        sentiment_level = "ææƒ§"
        color = "blue"
    else:
        sentiment_level = "æåº¦ææƒ§"
        color = "dark_blue"
    
    return {
        "index": final_index,
        "sentiment_level": sentiment_level,
        "color": color,
        "score_breakdown": scores,
        "raw_data": market_data
    }


def generate_prompt_content(result: Dict[str, Any], market_data: Dict[str, Any], date_str: str = None) -> str:
    """Generate AI Prompt content"""
    idx = result['index']
    level = result['sentiment_level']
    breadth = result['score_breakdown']['market_breadth']
    indices_trend = result['score_breakdown']['indices_trend']
    news_score = result['score_breakdown']['news_sentiment']
    flow_score = result['score_breakdown']['money_flow']
    
    limit_up = market_data['limit_up_count']
    limit_down = market_data['limit_down_count']
    
    bullish = market_data['news_sentiment']['bullish_count']
    bearish = market_data['news_sentiment']['bearish_count']
    
    net_inflow = market_data['sector_flow']['net_inflow'] / 1e8
    inflow_sectors = market_data['sector_flow']['inflow_sectors'][:3]
    outflow_sectors = market_data['sector_flow']['outflow_sectors'][:3]
    
    # Volume data
    vol_today = market_data['volume']['today_volume'] / 1e8
    vol_yesterday = market_data['volume']['yesterday_volume'] / 1e8
    vol_change = market_data['volume']['change_pct']
    
    if vol_today == 0:
        vol_desc = "æš‚æ— æ•°æ® (æ¥å£å¼‚å¸¸)"
        vol_change_desc = "æ•°æ®ç¼ºå¤±"
        vol_trend_desc = "æ— æ³•åˆ¤æ–­"
    else:
        vol_desc = f"æ”¾é‡{vol_change:.1f}%" if vol_change > 0 else f"ç¼©é‡{abs(vol_change):.1f}%"
        vol_change_desc = "çº¢è‰²" if vol_change > 5 else "ç»¿è‰²" if vol_change < -5 else "é»„è‰²"
        vol_trend_desc = "æˆäº¤é¢æ˜¾è‘—æ”¾å¤§ï¼Œå¸‚åœºæ´»è·ƒåº¦æå‡" if vol_change > 10 else "æˆäº¤é¢å°å¹…æ”¾å¤§" if vol_change > 0 else "ç¼©é‡éœ‡è¡ï¼Œè§‚æœ›æƒ…ç»ªæµ“åš" if vol_change > -10 else "æˆäº¤é¢å¤§å¹…èç¼©ï¼Œå¸‚åœºè°¨æ…"
    
    # Conditional strings (é¿å…f-stringåµŒå¥—)
    idx_color = "çº¢è‰²ç²—ä½“" if idx >= 70 else "æ©™è‰²ç²—ä½“" if idx >= 55 else "é»„è‰²ç²—ä½“"
    level_color = "æ©™çº¢è‰²æ ‡ç­¾" if idx >= 70 else "æ©™è‰²æ ‡ç­¾"
    breadth_desc = "æ¶¨åœå®¶æ•°è¿œè¶…è·Œåœ,å¸‚åœºèµšé’±æ•ˆåº”å¼º" if limit_up > limit_down * 3 else "å¸‚åœºåˆ†åŒ–ï¼Œæ¶¨è·Œåœç›¸å¯¹å‡è¡¡"
    indices_desc = "ä¸»æµæŒ‡æ•°å…¨çº¿é£˜çº¢" if indices_trend > 2 else "æŒ‡æ•°æ•´ä½“å¹³ç¨³" if indices_trend > -2 else "æŒ‡æ•°é›†ä½“è°ƒæ•´"
    news_desc = "æ­£é¢æ–°é—»å ä¼˜,å¸‚åœºæƒ…ç»ªæ´»è·ƒ" if news_score > 2 else "æ–°é—»æƒ…ç»ªä¸­æ€§" if news_score > -2 else "è´Ÿé¢æ–°é—»å¢å¤š"
    
    warning_emoji = "âš ï¸" if flow_score < -5 else ""
    flow_desc = "å‡€æµå‡º" if net_inflow < 0 else "å‡€æµå…¥"
    flow_color = "çº¢è‰²è­¦å‘Š" if net_inflow < -300 else "ç»¿è‰²" if net_inflow > 300 else "ä¸­æ€§"
    
    # Build prompt
    prompt = f"""# å¸‚åœºæƒ…ç»ªæŒ‡æ•° - AIç»˜å›¾Prompt ({datetime.now().strftime("%mæœˆ%dæ—¥")})
# æ•°æ®æ¥æº: æè´ªæŒ‡æ•°æ¨¡å‹ (4ç»´åº¦ç»¼åˆè¯„åˆ†)

## å›¾ç‰‡è§„æ ¼
- æ¯”ä¾‹: 9:16 ç«–ç‰ˆ
- é£æ ¼: æ‰‹ç»˜/æ‰‹è´¦é£æ ¼ï¼Œæš–è‰²çº¸å¼ è´¨æ„Ÿ
- èƒŒæ™¯è‰²: #F5E6C8 çº¸é»„è‰²
- é…è‰²: è´ªå©ª=çº¢è‰²æ¸å˜, ææƒ§=è“è‰²æ¸å˜

## æ ‡é¢˜
**ğŸ“Š Aè‚¡æè´ªæŒ‡æ•° | Market Greed & Fear** (å±…ä¸­ï¼Œæ‰‹ç»˜å­—ä½“)
**{datetime.now().strftime("%Y-%m-%d")}**

---

## æ ¸å¿ƒæŒ‡æ ‡ (å¤§å·æ˜¾ç¤º)
**æè´ªæŒ‡æ•°: {idx}/100** ({idx_color})
**æƒ…ç»ªç­‰çº§: {level}** ({level_color})

---

## å››ç»´åº¦è¯„åˆ†å¯è§†åŒ– (è¿›åº¦æ¡/é›·è¾¾å›¾)

### 1. å¸‚åœºå®½åº¦ (Market Breadth) {breadth:+.2f}
- æ¶¨åœ: {limit_up} åª (çº¢è‰²)
- è·Œåœ: {limit_down} åª (ç»¿è‰²)
- è¯´æ˜: {breadth_desc}

### 2. æŒ‡æ•°è¶‹åŠ¿ (Indices Trend) {indices_trend:+.2f}
"""
    
    for idx_name, change in market_data['indices'].items():
        arrow = "â†‘" if change > 0 else "â†“" if change < 0 else "â†’"
        prompt += f"- {idx_name}: {change:+.2f}% {arrow}\n"
    
    prompt += f"- è¯´æ˜: {indices_desc}\n\n"
    
    prompt += f"""### 3. æ–°é—»æƒ…ç»ª (News Sentiment) {news_score:+.2f}
- åˆ©å¤šæ¶ˆæ¯: {bullish} æ¡ (çº¢è‰²)
- åˆ©ç©ºæ¶ˆæ¯: {bearish} æ¡ (ç»¿è‰²)
- è¯´æ˜: {news_desc}

### 4. èµ„é‡‘æµå‘ (Money Flow) {flow_score:+.2f} {warning_emoji}
- {flow_desc}: **{abs(net_inflow):.2f} äº¿** ({flow_color})
"""
    
    if inflow_sectors:
        sector_list = "ã€".join([f"{s['åç§°']} +{s['å‡€é¢']/1e8:.0f}äº¿" for s in inflow_sectors])
        prompt += f"- æµå…¥æ¿å—: {sector_list}\n"
    
    if outflow_sectors:
        sector_list = "ã€".join([f"{s['åç§°']} {s['å‡€é¢']/1e8:.0f}äº¿" for s in outflow_sectors])
        prompt += f"- æµå‡ºæ¿å—: {sector_list}\n"
    
    if net_inflow < -300:
        prompt += "- è¯´æ˜: **å¤§é‡èµ„é‡‘æ’¤ç¦»ï¼Œå¸‚åœºé¿é™©æƒ…ç»ªå‡æ¸©**\n"
    elif net_inflow > 300:
        prompt += "- è¯´æ˜: **èµ„é‡‘å¤§å¹…æµå…¥ï¼Œå¸‚åœºåšå¤šæ„æ„¿å¼ºçƒˆ**\n"
    else:
        prompt += "- è¯´æ˜: èµ„é‡‘è§‚æœ›ï¼Œæ¿å—è½®åŠ¨\n"
    
    # Volume section
    prompt += f"""
### 5. æˆäº¤é¢ (Market Volume)
- ä»Šæ—¥æˆäº¤: **{vol_today:.0f} äº¿**
- æ˜¨æ—¥æˆäº¤: **{vol_yesterday:.0f} äº¿**
- å¯¹æ¯”æ˜¨æ—¥: **{vol_desc}** ({vol_change_desc})
- è¯´æ˜: {vol_trend_desc}

---
"""
    
    # AI Trend Content
    ai_trend_content = ""
    if date_str:
        try:
            trend_path = os.path.join("results", date_str, "agent_outputs", "result_trend_summary.txt")
            if os.path.exists(trend_path):
                with open(trend_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                if content:
                    ai_trend_content = f"\n> \n> {content}"
        except Exception:
            pass

    # Interpretation
    if idx >= 70 and net_inflow < -300:
        interpretation = f"è™½ç„¶æ¶¨åœå®¶æ•°é¢†å…ˆï¼Œä½†èµ„é‡‘å‡€æµå‡ºè¶…{abs(net_inflow):.0f}äº¿ä¸”{vol_desc}ï¼Œæ˜¾ç¤ºæœºæ„åœ¨é«˜ä½å‡ä»“ã€‚çŸ­æœŸè°¨é˜²è¿½é«˜é£é™©ï¼"
    elif idx >= 55:
        interpretation = f"å¸‚åœºæƒ…ç»ªåä¹è§‚ï¼Œ{vol_desc}ã€‚ä½†éœ€å…³æ³¨èµ„é‡‘æµå‘å˜åŒ–ã€‚"
    else:
        interpretation = f"å¸‚åœºæƒ…ç»ªè°¨æ…ï¼Œ{vol_desc}ï¼Œå»ºè®®æ§åˆ¶ä»“ä½ã€‚"

    advice = "è§‚æœ›ä¸ºä¸» | ä¸¥æ§ä»“ä½" if net_inflow < -300 else "é€¢ä½å¸ƒå±€ | æ§åˆ¶ä»“ä½"
    risk = f"èµ„é‡‘å¤§å¹…æµå‡º{abs(net_inflow):.0f}äº¿ä¸”{vol_desc}" if net_inflow < -300 else f"æŒ‡æ•°{idx:.1f}ï¼Œæ³¨æ„å›è°ƒé£é™©"

    prompt += f"""
## æƒ…ç»ªè§£è¯» (æ‰‹å†™ä½“æ–‡å­—æ¡†)
> **å½“å‰å¤„äº"{level}"åŒºé—´{"ï¼Œä½†éœ€è­¦æƒ•ï¼" if idx >= 70 and net_inflow < -300 else ""}**
> {interpretation}{ai_trend_content}

---

## æŠ•èµ„å»ºè®® (çº¢è‰²æ ‡ç­¾æç¤ºæ¡†)
âœ… **æ“ä½œå»ºè®®**: {advice}  
âš ï¸ **é£é™©æç¤º**: {risk}

---

## Footer
"æ¯æ—¥æè´ªæŒ‡æ•° | AIé‡åŒ–æƒ…ç»ªæ¨¡å‹ | ç‚¹èµå…³æ³¨ä¸è¿·è·¯"

---

## AIç»˜å›¾Prompt (English)

Hand-drawn financial infographic poster, China A-share Market Greed & Fear Index.

**Style**: Warm cream paper texture (#F5E6C8), vintage notebook aesthetic, hand-drawn Chinese fonts.

**Color Coding**: 
- Greed Level ({idx}) = {"RED gradient" if idx >= 70 else "ORANGE gradient"}
- Progress bars: Bullish = RED fill, Bearish = GREEN fill

**Layout (Vertical 9:16)**:
1. Title: "æè´ªæŒ‡æ•° {idx}" (large {"red" if idx >= 70 else "orange"} number, hand-drawn style)
2. Sentiment Level Badge: "{level}" ({"orange-red" if idx >= 70 else "orange"} tag)
3. Five Dimensions Section:
   - Market Breadth: {limit_up}æ¶¨åœ vs {limit_down}è·Œåœ (red vs green comparison bar)
   - Indices Trend: Mini arrow chart
   - News Sentiment: {bullish} bullish vs {bearish} bearish
   - Money Flow: {"**CRITICAL**" if net_inflow < -300 else ""} {net_inflow:.2f}äº¿ ({"RED WARNING with downward arrow" if net_inflow < -300 else "GREEN upward arrow" if net_inflow > 300 else "gray neutral bar"})
   - Volume: {vol_desc}, Today {vol_today:.0f}äº¿ vs Yesterday {vol_yesterday:.0f}äº¿
4. Interpretation Box: Hand-written style text
5. Footer: "æ¯æ—¥æè´ªæŒ‡æ•° | AIé‡åŒ–æƒ…ç»ªæ¨¡å‹"

**Visual Emphasis**:
- Large "{idx}" with {"red" if idx >= 70 else "orange"} glow
- Progress bars with paper texture
- Hand-drawn icons: ğŸ“ŠğŸ“ˆâš ï¸
"""
    
    if net_inflow < -300:
        prompt += "- **Money Flow section**: Red warning badge with downward arrows\n"
    
    if abs(vol_change) > 10:
        prompt += f"- **Volume section**: Highlight {vol_desc} with {'red' if vol_change > 10 else 'green'} emphasis\n"
    
    return prompt


def run_analysis(date_str: str = None) -> Dict[str, Any]:
    """
    Main entry point for market sentiment analysis.

    Args:
        date_str: Date string in YYYYMMDD format. If None, uses today.

    Returns:
        Sentiment analysis result dictionary
    """
    print(f"Running market sentiment analysis for {date_str or 'today'}...")

    # Aggregate market data
    market_data = aggregate_market_data(date_str)

    # Calculate sentiment index
    result = calculate_sentiment_index(market_data)

    # Generate and save prompt
    date_s = date_str or datetime.now().strftime("%Y%m%d")
    output_dir = os.path.join("results", date_s, "AIæç¤ºè¯")
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "å¸‚åœºæƒ…ç»ª_Prompt.txt")
    
    prompt_content = generate_prompt_content(result, market_data, date_s)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(prompt_content)
    
    print(f"\nâœ… Analysis complete: {result['index']}/100 ({result['sentiment_level']})")
    print(f"ğŸ“„ Prompt saved to: {output_path}")

    return result


if __name__ == "__main__":
    # Run analysis and save results
    run_analysis()
