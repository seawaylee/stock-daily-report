"""
[Module 7] Economic Monitor (Source: Cailianpress 24h)
Generates:
1. Economic Brief Prompt (Major Events & Market Movers)
Source: Cailianpress (CLS) 24h Rolling Telegraphs
"""
import requests
import pandas as pd
from datetime import datetime, timedelta
import os
import re
import time

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def fetch_cls_telegraphs(limit=100):
    """Fetch latest telegraphs from Cailianpress"""
    url = "https://www.cls.cn/nodeapi/telegraphList"
    params = {
        'rn': limit,
        'sv': '7.7.5',
    }
    print(f"Fetching CLS Telegraphs (Top {limit})...")
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            data = r.json().get('data', {}).get('roll_data', [])
            return data
    except Exception as e:
        print(f"Error fetching CLS: {e}")
    return []

def filter_last_24h_highlights(data):
    """Filter news from last 24h and select highlights"""
    now = datetime.now()
    cutoff = now - timedelta(hours=24) # 24h window
    
    highlights = {
        'global': [], # US/EU/Global Macro
        'china': [],  # China/Policy
        'market': []  # Assets/Stocks
    }
    
    # Keywords for simple categorization
    kw_global = ['ç¾è”å‚¨', 'ç¾å…ƒ', 'æ¬§å¤®è¡Œ', 'é™æ¯', 'CPI', 'GDP', 'æ‹œç™»', 'ç‰¹æœ—æ™®', 'ç¾å›½', 'æ¬§ç›Ÿ']
    kw_market = ['é»„é‡‘', 'åŸæ²¹', 'æ¯”ç‰¹å¸', 'çº³æŒ‡', 'æ ‡æ™®', 'è‚¡ä»·', 'è´¢æŠ¥', 'ä¸šç»©', 'æ¶¨åœ', 'å¤§è·Œ', 'æ–°é«˜']
    kw_china = ['å¤®è¡Œ', 'è¯ç›‘ä¼š', 'Aè‚¡', 'å›½åŠ¡é™¢', 'å‘æ”¹å§”', 'ç»Ÿè®¡å±€', 'LPR', 'ç¤¾è', 'M2']

    unique_titles = set()

    for item in data:
        timestamp = item.get('ctime', 0)
        item_time = datetime.fromtimestamp(timestamp)
        
        # 1. Check Time Window (24h)
        if item_time < cutoff:
            continue
            
        time_str = item_time.strftime('%H:%M')
        title = item.get('title', '') or item.get('content', '')[:50]
        # Clean title
        title = re.sub(r'ã€.*?ã€‘', '', title).strip()
        # Remove brief or empty
        if len(title) < 8: 
            continue
        
        # Deduplicate
        if title in unique_titles:
            continue
        unique_titles.add(title)
        
        full_content = item.get('content', '')
        
        # 2. Categorize
        if 'è´¢è”ç¤¾' in title and 'ç”µ' in title: # Clean up standard prefix
            title = re.sub(r'^è´¢è”ç¤¾\d+æœˆ\d+æ—¥ç”µï¼Œ?', '', title)

        # Skip boring items
        if "æ—¥å…ƒ" in title and "æ±‡ç‡" in title: pass # Keep?
        
        # Score importance (heuristic)
        is_important = False
        
        # Create display string with time
        display_str = f"[{time_str}] {title}"
        
        if any(k in title or k in full_content for k in kw_global):
            highlights['global'].append(display_str)
        elif any(k in title or k in full_content for k in kw_china):
            highlights['china'].append(display_str)
        elif any(k in title or k in full_content for k in kw_market):
            highlights['market'].append(display_str) # For market table, we might process differently, but string layout is flexible
        else:
            # Fallback for generic high impact?
            pass
            
    # Limit counts
    return {k: v[:8] for k, v in highlights.items()}

def generate_prompt(date_str, output_dir):
    """Generate Prompt with CLS 24h Data"""
    date_disp = datetime.strptime(date_str, '%Y%m%d').strftime('%mæœˆ%dæ—¥')
    
    # 1. Fetch & Process
    raw_data = fetch_cls_telegraphs(limit=150) # Fetch more to ensure coverage
    data = filter_last_24h_highlights(raw_data)
    
    # 2. Format
    # Global
    global_txt = ""
    for t in data['global'][:6]:
        global_txt += f"- {t}\n"
    if not global_txt: global_txt = "- [æš‚æ— é‡å¤§å…¨çƒæ¶ˆæ¯]"
        
    # China
    china_txt = ""
    for t in data['china'][:6]:
        china_txt += f"- {t}\n"
    if not china_txt: china_txt = "- [æš‚æ— é‡å¤§å›½å†…æ”¿ç­–]"
        
    # Market
    market_txt = ""
    for t in data['market'][:5]:
        # t is "[HH:MM] Title..."
        # We want to extract time and title for table
        # Simple split, assuming format hasn't changed
        try:
            time_part = t[1:6] # HH:MM
            content_part = t[8:]
            market_txt += f"| {time_part} | {content_part[:10]}.. | å…³æ³¨ |\n"
        except:
             market_txt += f"| --:-- | {t[:10]}.. | å…³æ³¨ |\n"
             
    if not market_txt: market_txt = "| --:-- | æš‚æ— å¼‚åŠ¨ | -- |\n"

    content = f"""# å…¨çƒè´¢ç»æ—¥å† 24h - AIç»˜å›¾Prompt ({date_disp})
# æ•°æ®æ¥æº: è´¢è”ç¤¾ (è¿‘24å°æ—¶æ»šåŠ¨èšåˆ)

## å›¾ç‰‡è§„æ ¼
- æ¯”ä¾‹: 9:16 ç«–ç‰ˆ
- é£æ ¼: æ‰‹ç»˜/æ‰‹è´¦é£æ ¼ï¼Œæš–è‰²çº¸å¼ è´¨æ„Ÿ
- èƒŒæ™¯è‰²: #F5E6C8 çº¸é»„è‰²

## æ ‡é¢˜
**ğŸ“… è´¢è”ç¤¾ 24h æ ¸å¿ƒç²¾é€‰** (çº¢è‰²)
**CLS Telegraph | {date_disp}**

---

## ğŸŒ å…¨çƒå®è§‚ (Global & Macro)

### ğŸ‡ºğŸ‡¸ å›½é™…/ç¾å…ƒ
{global_txt}

### ğŸ‡¨ğŸ‡³ ä¸­å›½/æ”¿ç­–
{china_txt}

---

## ğŸ“Š å¸‚åœºçƒ­ç‚¹ (Market Movers)

| æ—¶é—´ | çƒ­ç‚¹äº‹ä»¶ | çŠ¶æ€ |
|------|----------|------|
{market_txt}

---

## ğŸ’¡ äº¤æ˜“æé†’
- è¿™é‡Œæ±‡æ€»äº†è¿‡å»24å°æ—¶æœ€é‡è¦çš„è´¢ç»æ–°é—»
- âš ï¸ é‡ç‚¹å…³æ³¨ä¸Šè¿°æ”¿ç­–å¯¹Aè‚¡çš„å½±å“

## AIç»˜å›¾Prompt (English)

Hand-drawn financial infographic poster, Cailianpress news, Global market summary {date_disp}.

**Style**: Warm cream paper texture (#F5E6C8), vintage notebook aesthetic, handwritten Chinese fonts.

**Layout**:
- Title: "CLS News" hand-drawn style.
- Section 1: Global/China News List (Hand-drawn flags).
- Section 2: Market Events Table.
- Footer: "CLS.cn".

(Optimized for hand-drawn financial briefing)
"""
    path = os.path.join(output_dir, "AIæç¤ºè¯", "é‡‘åæ•°æ®_Prompt.txt")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"Saved: {path}")

def run(date_str, output_dir):
    generate_prompt(date_str, output_dir)
