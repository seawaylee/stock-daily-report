"""
å…¨å¸‚åœºé€‰è‚¡ + AIæ™ºèƒ½åˆ†æç”ŸæˆæŠ¥å‘Š
1. 300å¹¶å‘å…¨å¸‚åœºé€‰è‚¡ï¼ˆå¸‚å€¼100äº¿+ï¼Œæ’é™¤STï¼‰
2. æ¥å…¥Geminiåˆ†æTop10å€¼åšç‡

"""
import sys
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import requests
import base64
import time
import random
import numpy as np
from tqdm import tqdm

# å¯¼å…¥é…ç½®å’ŒPromptæ¨¡å—
from common.config import MAX_WORKERS, MIN_MARKET_CAP
from common.prompts import (
    NumpyEncoder, 
    get_analysis_prompt, 
    get_image_prompt
)

# å¯¼å…¥æ•°æ®è·å–å’Œä¿¡å·æ£€æµ‹æ¨¡å—

# å¯¼å…¥æ•°æ®è·å–å’Œä¿¡å·æ£€æµ‹æ¨¡å—
from common.data_fetcher import get_all_stock_list, get_stock_data
from common.signals import check_stock_signal
# from modules.daily_report.sector_flow import run_daily_analysis (Refactored)
# from modules.daily_report.generate_ladder_prompt import generate_ladder_prompt (Refactored)

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


# ============ çƒ­é—¨é¢˜æè¿‡æ»¤åŠŸèƒ½ ============

def get_hot_sectors_from_fish_basin(date_dir: str, top_n: int = 5):
    """
    ä»è¶‹åŠ¿æ¨¡å‹Promptæ–‡ä»¶ä¸­æå–Top Nçƒ­é—¨é¢˜æ
    
    Args:
        date_dir: æ—¥æœŸç›®å½•ï¼ˆä¾‹å¦‚ï¼šresults/20260204ï¼‰
        top_n: è·å–å‰Nä¸ªé¢˜æï¼Œé»˜è®¤5
    
    Returns:
        é¢˜æåˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š['è´µé‡‘å±', 'æœ‰è‰²é‡‘å±', 'å…‰ä¼è®¾å¤‡', 'çŸ³æ²¹åŠ å·¥è´¸æ˜“', 'åŠå¯¼ä½“']
        å¦‚æœæå–å¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    """
    import re
    from datetime import datetime, timedelta
    
    # å°è¯•è¯»å–ä»Šå¤©çš„è¶‹åŠ¿æ¨¡å‹Promptæ–‡ä»¶
    prompt_file = os.path.join(date_dir, "AIæç¤ºè¯", "è¶‹åŠ¿æ¨¡å‹_åˆå¹¶_Prompt.txt")
    
    # Fallback: å¦‚æœä»Šå¤©çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æ˜¨å¤©çš„
    if not os.path.exists(prompt_file):
        print(f"âš ï¸ ä»Šæ—¥è¶‹åŠ¿æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        # å°è¯•æ˜¨å¤©
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
        prompt_file = os.path.join("results", yesterday, "AIæç¤ºè¯", "è¶‹åŠ¿æ¨¡å‹_åˆå¹¶_Prompt.txt")
        if not os.path.exists(prompt_file):
            print(f"âŒ æ˜¨æ—¥è¶‹åŠ¿æ¨¡å‹æ–‡ä»¶ä¹Ÿä¸å­˜åœ¨: {prompt_file}")
            return []
        else:
            print(f"âœ… ä½¿ç”¨æ˜¨æ—¥è¶‹åŠ¿æ¨¡å‹æ–‡ä»¶: {prompt_file}")
    
    try:
        with open(prompt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾ "SECTION 2: çƒ­é—¨é¢˜æè¶‹åŠ¿" éƒ¨åˆ†
        section_match = re.search(r'SECTION 2:.*?çƒ­é—¨é¢˜æ.*?\*\*Data\*\*:(.*?)---', content, re.DOTALL)
        if not section_match:
            print("âŒ æœªæ‰¾åˆ°çƒ­é—¨é¢˜ææ•°æ®æ®µ")
            return []
        
        data_section = section_match.group(1)
        
        # æå–é¢˜æåç§°ï¼šæ ¼å¼ä¸º "1. â— è´µé‡‘å± | æ¶¨è·Œ:..."
        # æ­£åˆ™åŒ¹é…ï¼šæ•°å­—. â—‹/â— é¢˜æåç§° |
        pattern = r'\d+\.\s*[â—â—‹]\s*([^\s|]+)\s*\|'
        matches = re.findall(pattern, data_section)
        
        if not matches:
            print("âŒ æœªèƒ½æå–é¢˜æåç§°")
            return []
        
        # å–å‰top_nä¸ª
        hot_sectors = matches[:top_n]
        print(f"ğŸ“Š æå–åˆ°Top{top_n}çƒ­é—¨é¢˜æ: {hot_sectors}")
        return hot_sectors
        
    except Exception as e:
        print(f"âŒ æå–çƒ­é—¨é¢˜æå¤±è´¥: {e}")
        return []


def match_stock_sector(stock_info: dict, hot_sectors: list) -> bool:
    """
    åˆ¤æ–­è‚¡ç¥¨æ˜¯å¦å±äºçƒ­é—¨é¢˜æ
    
    Args:
        stock_info: è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼ˆéœ€åŒ…å«'industry'æˆ–'sector'å­—æ®µï¼‰
        hot_sectors: çƒ­é—¨é¢˜æåˆ—è¡¨
    
    Returns:
        æ˜¯å¦åŒ¹é…ä»»ä¸€çƒ­é—¨é¢˜æ
    """
    if not hot_sectors:
        return False
    
    # è·å–è‚¡ç¥¨çš„è¡Œä¸š/é¢˜æä¿¡æ¯
    industry = stock_info.get('industry', '')
    sector = stock_info.get('sector', '')
    combined = f"{industry} {sector}".lower()
    
    # é¢˜ææ˜ å°„è¡¨ï¼šFish Basiné¢˜æå -> å¯èƒ½çš„è¡Œä¸šå…³é”®è¯
    sector_mapping = {
        'è´µé‡‘å±': ['é»„é‡‘', 'ç™½é“¶', 'è´µé‡‘å±'],
        'æœ‰è‰²é‡‘å±': ['æœ‰è‰²', 'é“', 'é“œ', 'é”Œ', 'é•', 'é’´', 'é”‚'],
        'å…‰ä¼è®¾å¤‡': ['å…‰ä¼', 'å¤ªé˜³èƒ½', 'é€†å˜å™¨', 'ç¡…ç‰‡'],
        'çŸ³æ²¹åŠ å·¥è´¸æ˜“': ['çŸ³æ²¹', 'çŸ³åŒ–', 'åŒ–å·¥', 'ç‚¼åŒ–'],
        'åŠå¯¼ä½“': ['åŠå¯¼ä½“', 'èŠ¯ç‰‡', 'é›†æˆç”µè·¯', 'IC', 'æ™¶åœ†'],
        'å•†ä¸šèˆªå¤©': ['èˆªå¤©', 'å«æ˜Ÿ', 'ç«ç®­', 'èˆªç©ºèˆªå¤©'],
        'ä¿é™©': ['ä¿é™©', 'å¯¿é™©', 'è´¢é™©'],
        'ç¨€åœŸ': ['ç¨€åœŸ', 'é’•é“ç¡¼', 'æ°¸ç£'],
        'é€šä¿¡è®¾å¤‡': ['é€šä¿¡', '5G', 'å…‰é€šä¿¡', 'ç½‘ç»œè®¾å¤‡'],
        'ç»†åˆ†åŒ–å·¥': ['åŒ–å·¥', 'åŒ–å­¦', 'ç²¾ç»†åŒ–å·¥'],
        'ç”µç½‘è®¾å¤‡': ['ç”µç½‘', 'ç”µåŠ›è®¾å¤‡', 'ç‰¹é«˜å‹', 'å˜å‹å™¨'],
        'ç…¤ç‚­': ['ç…¤ç‚­', 'ç…¤çŸ¿', 'ç„¦ç…¤'],
        'æˆ¿åœ°äº§': ['æˆ¿åœ°äº§', 'åœ°äº§', 'ç‰©ä¸š'],
        'é£ç”µè®¾å¤‡': ['é£ç”µ', 'é£èƒ½', 'é£æœº'],
        'ç”µåŠ›': ['ç”µåŠ›', 'å‘ç”µ', 'ç«ç”µ', 'æ°´ç”µ'],
        'å…»æ®–': ['å…»æ®–', 'çŒª', 'é¸¡', 'ç¦½'],
        'åŒ»ç–—æœåŠ¡': ['åŒ»ç–—', 'åŒ»é™¢', 'è¯Šæ–­'],
        'æ–°èƒ½æº': ['æ–°èƒ½æº', 'ç”µæ± ', 'å‚¨èƒ½', 'é”‚ç”µ'],
        'äººå·¥æ™ºèƒ½': ['äººå·¥æ™ºèƒ½', 'AI', 'ç®—åŠ›', 'èŠ¯ç‰‡', 'äº‘è®¡ç®—'],
        'æ—…æ¸¸': ['æ—…æ¸¸', 'é…’åº—', 'æ™¯åŒº'],
    }
    
    # åŒ¹é…é€»è¾‘
    for hot_sector in hot_sectors:
        # ç›´æ¥åŒ¹é…
        if hot_sector.lower() in combined:
            return True
        
        # é€šè¿‡æ˜ å°„è¡¨åŒ¹é…
        if hot_sector in sector_mapping:
            keywords = sector_mapping[hot_sector]
            for keyword in keywords:
                if keyword.lower() in combined:
                    return True
    
    return False


def process_single_stock(args):
    """å¤„ç†å•åªè‚¡ç¥¨"""
    code, name, market_cap, industry = args
    # Add random delay to prevent request bursts (Anti-Scraping / Flow Control)
    time.sleep(random.uniform(0.1, 0.2))
    try:
        df = get_stock_data(code, 300)
        if df is None or len(df) < 120:
            return None
        
        result = check_stock_signal(df, code)
        
        # è·å–æœ€åä¸€è¡ŒåŸå§‹æ•°æ®
        last_row = df.iloc[-1].to_dict()
        last_row['date'] = str(last_row['date'])[:10]
        
        return {
            'code': code,
            'name': name,
            'market_cap': float(market_cap),
            'industry': industry if str(industry).lower() != 'nan' else None,  # é¢˜æ/è¡Œä¸š
            'signal': bool(result.get('signal', False)),
            'signals': result.get('signals', []),
            'K': float(result.get('K', 0)),
            'D': float(result.get('D', 0)),
            'J': float(result.get('J', 0)),
            'RSI': float(result.get('RSI', 0)),
            'near_amplitude': float(result.get('è¿‘æœŸæŒ¯å¹…', 0)),
            'far_amplitude': float(result.get('è¿œæœŸæŒ¯å¹…', 0)),
            'raw_data_mock': last_row
        }
    except Exception as e:
        return None


def run_full_selection(force=False):
    """å…¨å¸‚åœºé€‰è‚¡
    
    Args:
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°é€‰è‚¡ï¼Œå¿½ç•¥ä»Šæ—¥å·²æœ‰ç»“æœ
    """
    today_date = datetime.now().strftime('%Y%m%d')
    date_dir = os.path.join("results", today_date)
    os.makedirs(date_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šæ—¥ç»“æœ
    if not force:
        import glob
        existing_files = glob.glob(os.path.join(date_dir, f"selected_{today_date}_*.json")) 
        if existing_files:
            latest_file = max(existing_files, key=os.path.getctime)
            print(f"âš¡ å‘ç°ä»Šæ—¥å·²æœ‰é€‰è‚¡ç»“æœ: {latest_file}")
            with open(latest_file, 'r', encoding='utf-8') as f:
                selected = json.load(f)
            # ä»æ–‡ä»¶åæå–å®Œæ•´æ—¶é—´æˆ³ (selected_YYYYMMDD_HHMMSS.json)
            filename = os.path.basename(latest_file)
            # filenameæ ¼å¼: selected_20260118_004725.json
            # å»æ‰å‰ç¼€ selected_ (9 chars) å’Œåç¼€ .json (5 chars)
            timestamp = filename[9:-5] 
            return selected, timestamp
    else:
        print("ğŸ”„ --force æ¨¡å¼ï¼šå¿½ç•¥ä»Šæ—¥ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°é€‰è‚¡")

    print("=" * 70)
    print("  ä¸œæ–¹è´¢å¯Œ - çŸ¥è¡ŒB1é€‰è‚¡ç­–ç•¥ (AIæ™ºèƒ½åˆ†æç‰ˆ)")
    print(f"  å¸‚å€¼ >= {MIN_MARKET_CAP}äº¿ | æ’é™¤ST | å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")
    print(f"  æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    print("\n[1/4] è·å–è‚¡ç¥¨åˆ—è¡¨...")
    stock_list = get_all_stock_list(min_market_cap=MIN_MARKET_CAP, exclude_st=True)
    
    # æ³¨é‡Šï¼šç§»é™¤500åªè‚¡ç¥¨é™åˆ¶ï¼Œåˆ†æå…¨éƒ¨è‚¡ç¥¨
    # stock_list = stock_list.head(500)
    print(f"âš ï¸ å°†åˆ†æå…¨éƒ¨ {len(stock_list)} åªè‚¡ç¥¨")
    
    if len(stock_list) == 0:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return [], ""
    
    args_list = [
        (row['code'], row['name'], row['market_cap'], row.get('industry', '')) 
        for _, row in stock_list.iterrows()
    ]
    
    print(f"\n[2/4] å¹¶å‘åˆ†æ {len(args_list)} åªè‚¡ç¥¨çš„ä¿¡å·...")
    
    selected = []
    all_results = []
    
    # ä¿å­˜ç»“æœ
    today_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜æ‰€æœ‰åŸå§‹æ•°æ® (Incremental)
    raw_file = os.path.join(date_dir, f"all_stocks_{today_timestamp}.jsonl")
    print(f"ğŸ“ å®æ—¶æ•°æ®å°†å†™å…¥: {raw_file}")

    # Initial Parallel Fetch
    processed_codes = set()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_stock, args): args[0] for args in args_list}
        
        # Open file in append mode for incremental writing
        with open(raw_file, 'w', encoding='utf-8') as f_out:
            for future in tqdm(as_completed(futures), total=len(futures), desc="é€‰è‚¡è¿›åº¦"):
                result = future.result()
                if result is not None:
                    # Incremental Write
                    f_out.write(json.dumps(result, cls=NumpyEncoder, ensure_ascii=False) + '\n')
                    f_out.flush() # Ensure it flows to disk
                    
                    all_results.append(result)
                    processed_codes.add(result['code'])
                    if result['signal']:
                        selected.append(result)

    # Retry Logic
    missing_args = [arg for arg in args_list if arg[0] not in processed_codes]
    if missing_args:
        print(f"\nğŸ”„ B1 Retry: {len(missing_args)} stocks failed. Retrying sequentially...")
        import time
        
        with open(raw_file, 'a', encoding='utf-8') as f_out:
            for i, args in enumerate(missing_args):
                code = args[0]
                try:
                    # Sequential Retry with delay
                    time.sleep(0.5) 
                    result = process_single_stock(args)
                    
                    if result is not None:
                        f_out.write(json.dumps(result, cls=NumpyEncoder, ensure_ascii=False) + '\n')
                        f_out.flush()
                        all_results.append(result)
                        processed_codes.add(code)
                        if result['signal']:
                            selected.append(result)
                        print(f"   âœ… Retry success: {code}")
                    else:
                        pass # still failed
                except:
                    pass
                
                if (i+1) % 10 == 0:
                    print(f"   Retry progress: {i+1}/{len(missing_args)}")

    # Summary
    success_count = len(processed_codes)
    total_count = len(args_list)
    fail_count = total_count - success_count
    
    print("\n" + "="*40)
    print(f"ğŸ“Š B1é€‰è‚¡ æ‰§è¡Œæ±‡æ€»")
    print(f"âœ… æˆåŠŸ: {success_count}/{total_count}")
    print(f"âŒ å¤±è´¥: {fail_count}/{total_count}")
    print("="*40)
    
    # raw_file is already written incrementally
    
    
    print(f"\nğŸ“ åŸå§‹æ•°æ®: {raw_file} ({len(all_results)} æ¡)")
    
    # ä¿å­˜é€‰è‚¡ç»“æœ
    selected_file = os.path.join(date_dir, f"selected_{today_timestamp}.json")
    with open(selected_file, 'w', encoding='utf-8') as f:
        json.dump(selected, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
            
    print(f"ğŸ“ é€‰è‚¡ç»“æœ: {selected_file} ({len(selected)} åª)")
    
    return selected, today_timestamp


def save_stock_summary(selected_stocks, date_dir, timestamp):
    """ä¿å­˜ä¾¿äºç§ä¿¡å‘é€çš„æ–‡æœ¬æ±‡æ€»"""
    summary_file = os.path.join(date_dir, f"stock_list_summary_{timestamp}.txt")
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"ğŸ“… é€‰è‚¡æ±‡æ€» {datetime.now().strftime('%Y-%m-%d')}\n")
        f.write(f"ç­–ç•¥: AIå¤§æ¨¡å‹é‡åŒ–\n")
        f.write("-" * 30 + "\n\n")
        
        for idx, stock in enumerate(selected_stocks, 1):
            code = stock['code']
            name = stock['name']
            industry = stock.get('industry', 'æœªçŸ¥è¡Œä¸š')
            
            f.write(f"{idx}. {name} ({code})\n")
            if industry and str(industry).lower() != 'nan':
                f.write(f"   è¡Œä¸š: {industry}\n")
            # è·å–ä¿¡å·åˆ—è¡¨
            stock_signals = stock.get('signals', [])
            
            if stock_signals:
                # ç»Ÿä¸€æœ¯è¯­
                sanitized_signals = [
                    s.replace('B1', 'ä¹°ç‚¹')
                     .replace('B', 'ä¹°ç‚¹')
                     .replace('åŸå§‹', 'æ ‡å‡†')
                    for s in stock_signals
                ]
                f.write(f"   å‘½ä¸­è§„åˆ™: {'+'.join(sanitized_signals)}\n")
            
            f.write("\n")
            
        f.write("-" * 30 + "\n")
        f.write("æ³¨ï¼šæ¬¡æ—¥å…³æ³¨è¿›åœºï¼ŒéæŠ•èµ„å»ºè®®ã€‚\n")
        f.write("æ›´å¤šè¯¦æƒ…è¯·çœ‹æ–‡æ¡ˆåˆ†æã€‚\n")

    print(f"ğŸ“ ç§ä¿¡æ±‡æ€»åˆ—è¡¨: {summary_file}")
    return summary_file

# æ³¨é‡Šï¼šsave_stock_summary åŠŸèƒ½å·²ç§»è‡³ agent_outputs/result_analysis.txt
# æ­¤å‡½æ•°ä¿ç•™ä½†ä¸å†è°ƒç”¨

# ================ è„±æ•å·¥å…·å‡½æ•° ================

def desensitize_stock_name(name):
    """è‚¡ç¥¨åç§°è„±æ•ï¼šä¿ç•™å‰2å­—ï¼Œåé¢æ”¹ä¸ºæ‹¼éŸ³é¦–å­—æ¯å¤§å†™"""
    if len(name) <= 2:
        return name
    
    try:
        from pypinyin import lazy_pinyin, Style
        # è·å–åç¼€çš„æ‹¼éŸ³é¦–å­—æ¯
        suffix = name[2:]
        pinyin_initials = lazy_pinyin(suffix, style=Style.FIRST_LETTER)
        # è½¬å¤§å†™å¹¶æ‹¼æ¥
        initials = ''.join([p.upper() for p in pinyin_initials])
        return name[:2] + initials
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… pypinyinï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘
        print("Warning: pypinyin not installed. Using simplified desensitization.")
        suffix = name[2:]
        # å–åç¼€å‰ä¸¤ä¸ªå­—ç¬¦ä½œä¸ºæ ‡è¯†
        return name[:2] + (suffix[:2].upper() if len(suffix) >= 2 else suffix.upper())

def desensitize_stock_code(code):
    """è‚¡ç¥¨ä»£ç è„±æ•ï¼šå‰4ä½ä¿ç•™ï¼Œå2ä½æ”¹ä¸º**"""
    if len(code) < 6:
        return code
    return code[:4] + '**'



def call_gemini_analysis(selected_stocks, date_dir):
    """ä½¿ç”¨Agentåˆ†æTop10å€¼åšç‡"""
    # å‡†å¤‡åˆ†ææ•°æ®
    stocks_info = []
    for s in selected_stocks:
        raw = s['raw_data_mock']
        stocks_info.append({
            'ä»£ç ': s['code'],
            'åç§°': s['name'],
            'æ€»å¸‚å€¼(äº¿å…ƒ)': round(s['market_cap'], 0),
            'ä¿¡å·ç±»å‹': ', '.join(s['signals']),
            'K': round(s['K'], 1),
            'D': round(s['D'], 1),
            'J': round(s['J'], 1),
            'RSI': round(s['RSI'], 1),
            'è¿‘æœŸæŒ¯å¹…%': round(s['near_amplitude'], 1),
            'è¿œæœŸæŒ¯å¹…%': round(s['far_amplitude'], 1),
            'æ”¶ç›˜ä»·': raw['close'],
            'æˆäº¤é‡': raw['volume']
        })
    
    prompt = get_analysis_prompt(stocks_info)

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_analysis.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"\n[4/4] ä»»åŠ¡å·²ä¿å­˜ï¼Œç­‰å¾…Agentåˆ†æTop10...")
    print(f"ğŸ“ ä»»åŠ¡æ–‡ä»¶: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_analysis.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            result = f.read()
        print("âœ… Agentåˆ†æå®Œæˆ")
        
        # --- æå–å¹¶ä¿å­˜ Top 10 ---
        import re
        top_codes = re.findall(r'\((\d{6})\)', result)
        seen = set()
        unique_codes = []
        for c in top_codes:
            if c not in seen:
                unique_codes.append(c)
                seen.add(c)
        unique_codes = unique_codes[:20] # Top 20
        
        stock_map = {s['code']: s for s in selected_stocks}
        top_stocks = []
        for c in unique_codes:
            if c in stock_map:
                top_stocks.append(stock_map[c])
        
        top10_file = os.path.join(date_dir, "selected_top10.json") # Keep filenamesame for compat or change? Let's keep it.
        with open(top10_file, 'w', encoding='utf-8') as f:
            json.dump(top_stocks, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
        print(f"ğŸ“ å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶: {top10_file} ({len(top_stocks)}åª)")
        
        return result, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        print("æç¤ºï¼šè¯·è¿è¡Œ Agent å·¥ä½œæµæ¥å¤„ç†åˆ†æä»»åŠ¡")
        return None, prompt





def generate_image_prompt(gemini_analysis, selected_stocks, date_dir):
    """ç›´æ¥ç”Ÿæˆä¿¡æ¯å›¾æç¤ºè¯ (æ— éœ€AgentäºŒæ¬¡å¤„ç†)"""
    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    if len(selected_stocks) > 5:
        print(f"âš ï¸ è­¦å‘Š: ä¼ å…¥å›¾ç‰‡ç”Ÿæˆçš„è‚¡ç¥¨æ•°é‡ä¸º {len(selected_stocks)}ï¼Œæˆªå–Top 5ã€‚")
        selected_stocks = selected_stocks[:5]

    # ä»åˆ†æç»“æœæå– "æ•´ä½“å¸‚åœºå¤ç›˜" å’Œ "æ¬¡æ—¥äº¤æ˜“ç­–ç•¥"
    import re
    
    # --- æå–å¤ç›˜ä¸ç­–ç•¥ ---
    market_review = "æ— å¤ç›˜å†…å®¹"
    tomorrow_strategy = ""
    
    # å°è¯•æå– "Step 4: å›¾ç‰‡ç”Ÿæˆä¸“ç”¨æ‘˜è¦"
    summary_section_match = re.search(r'å›¾ç‰‡ç”Ÿæˆä¸“ç”¨æ‘˜è¦\s*(.+)', gemini_analysis, re.DOTALL)
    
    SUMMARY_FOUND = False
    if summary_section_match:
        summary_content = summary_section_match.group(1)
        
        # æå–å¤ç›˜
        match_rev = re.search(r'ğŸ“\s*(.+?)(?=\n\s*ğŸ’¡|$)', summary_content, re.DOTALL)
        if match_rev:
            extracted_rev = match_rev.group(1).strip().replace('**', '').replace('æ•´ä½“å¤ç›˜', '').strip()
            if extracted_rev:
                market_review = extracted_rev
                SUMMARY_FOUND = True
        
        # æå–ç­–ç•¥
        match_str = re.search(r'ğŸ’¡\s*(.+)', summary_content, re.DOTALL)
        if match_str:
            extracted_str = match_str.group(1).strip().replace('**', '').replace('æ¬¡æ—¥ç­–ç•¥', '').strip()
            if extracted_str:
                tomorrow_strategy = extracted_str
                SUMMARY_FOUND = True
                
    if not SUMMARY_FOUND:
        print("âš ï¸ æœªæ‰¾åˆ°ä¸“ç”¨æ‘˜è¦ï¼Œä½¿ç”¨æ™ºèƒ½æå–å›é€€æ¨¡å¼...")
        # å›é€€æ¨¡å¼ï¼šä»æ­£æ–‡æå–ç¬¬ä¸€æ®µ
        match_review = re.search(r'æ•´ä½“å¸‚åœºå¤ç›˜\s+(.+?)(?=\n\s*æ¬¡æ—¥äº¤æ˜“ç­–ç•¥|$)', gemini_analysis, re.DOTALL)
        if match_review:
            full_review = match_review.group(1).strip()
            market_review = full_review.split('\n')[0].strip().replace('**', '')

        match_strategy = re.search(r'æ¬¡æ—¥äº¤æ˜“ç­–ç•¥\s+(.+?)(?=\n\s*é£é™©æç¤º|$)', gemini_analysis, re.DOTALL)
        if match_strategy:
            full_strategy = match_strategy.group(1).strip()
            # æå– **æ ¸å¿ƒç‚¹**
            strategy_points = re.findall(r'\*\*(.*?)\*\*', full_strategy)
            if strategy_points:
                tomorrow_strategy = "ã€".join(strategy_points[:3])
            else:
                tomorrow_strategy = full_strategy.split('\n')[0].strip().replace('**', '')

    
    # æ„å»ºåŠ¨æ€ Footer å†…å®¹
    footer_content = ""
    # if market_review and market_review != "æ— å¤ç›˜å†…å®¹":
    #    footer_content += f"ğŸ“ æ•´ä½“å¤ç›˜\n{market_review}\n\n"
    
    # if tomorrow_strategy:
    #    footer_content += f"ğŸ’¡ æ¬¡æ—¥ç­–ç•¥\n{tomorrow_strategy}"
    # 
    # USER REQUEST: Specific Footer with Disclaimer
    footer_content = """
**FOOTER:**
"Daily AI Algo Strategy | High Value Ratio Stocks | Follow for Updates"
(Render in Chinese: "æ¯æ—¥ç›˜ååˆ†äº«AIé‡åŒ–ç­–ç•¥çš„é«˜å€¼åšç‡è‚¡ç¥¨ï¼Œç‚¹èµå…³æ³¨ä¸è¿·è·¯")

**å…è´£å£°æ˜ (Disclaimer):**
æœ¬å†…å®¹ä»…ä¾›å­¦ä¹ äº¤æµï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚
è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚è¯·ç‹¬ç«‹æ€è€ƒï¼Œç†æ€§å†³ç­–ã€‚
"""

    # --- Generate Card Text with Trading Strategy (Python Logic) ---
    cards_text = ""
    for idx, s in enumerate(selected_stocks, 1):
        # ä¸å†è„±æ•ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åç§°å’Œä»£ç 
        name = s['name']
        code = s['code']
        industry = s.get('industry', 'æœªçŸ¥')
        if not industry: industry = "æœªçŸ¥"
        
        signals = ','.join(s.get('signals', [])).replace('B1','æ ‡å‡†ä¹°ç‚¹').replace('B','æ ‡å‡†ä¹°ç‚¹').replace('åŸå§‹ä¹°ç‚¹','æ ‡å‡†ä¹°ç‚¹')
        signals = signals.split(',')[0] # First signal
        signals = signals.replace('æ ‡å‡†ä¹°ç‚¹', 'Buy').replace('å›è¸©', 'Retrace')
        
        J_val = round(s.get('J', 0), 2)
        RSI_val = round(s.get('RSI', 0), 2)
        
        # è·å–ä»·æ ¼ï¼šä¼˜å…ˆä»priceå­—æ®µï¼Œå¦åˆ™ä»raw_data_mockä¸­è·å–
        price = s.get('price', 0)
        if price == 0 and 'raw_data_mock' in s:
            price = s['raw_data_mock'].get('close', 0)
        
        # è®¡ç®—æ“ä½œç­–ç•¥
        # ä¹°å…¥æ—¶æœºï¼šæ ¹æ®Jå€¼å’ŒRSIå€¼åˆ¤æ–­
        if J_val < 20 and RSI_val < 40:
            buy_timing = "è¶…å–åŒºï¼Œå¯åˆ†æ‰¹å»ºä»“"
            entry_zone = f"{price * 0.98:.2f}-{price * 1.02:.2f}"
        elif J_val < 50:
            buy_timing = "å›è°ƒä¼ç¨³åä¹°å…¥"
            entry_zone = f"{price * 0.97:.2f}-{price:.2f}"
        else:
            buy_timing = "çªç ´ç¡®è®¤åè¿½æ¶¨"
            entry_zone = f"{price:.2f}-{price * 1.03:.2f}"
        
        # æ­¢æŸä½ï¼šé€šå¸¸è®¾ç½®åœ¨5-8%
        stop_loss = f"{price * 0.92:.2f}"
        stop_loss_pct = "8%"
        
        # é£é™©è¯„ä¼°ï¼šæ ¹æ®RSIå’ŒæŒ¯å¹…åˆ¤æ–­
        near_amp = s.get('near_amplitude', 0)
        if RSI_val < 30 or near_amp > 15:
            risk_level = "âš ï¸ é«˜é£é™©"
            risk_note = "æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®è½»ä»“"
        elif RSI_val < 50:
            risk_level = "âš¡ ä¸­ç­‰é£é™©"
            risk_note = "é€‚åº¦å‚ä¸"
        else:
            risk_level = "ğŸ“Š ç›¸å¯¹ç¨³å¥"
            risk_note = "å¯é€‚å½“å¢ä»“"
        
        line1 = f"#{idx} {name} | {code} | ğŸ­ {industry}"
        line2 = f"ğŸš€ **{signals}** (Red Ink) | **J={J_val}** (Blue) **RSI={RSI_val}** (Purple)"
        line3 = f"ğŸ’° **ä¹°å…¥åŒºé—´**: {entry_zone}å…ƒ | **æ­¢æŸ**: {stop_loss}å…ƒ(-{stop_loss_pct})"
        line4 = f"ğŸ“ **æ“ä½œ**: {buy_timing} | **é£é™©**: {risk_level} ({risk_note})"
        
        cards_text += f"{line1}\n{line2}\n{line3}\n{line4}\n\n"

    # --- Final Prompt Construction ---
    final_prompt = f"""(masterpiece, best quality), (vertical:1.2), (aspect ratio: 10:16), (sketch style), (hand drawn), (infographic)

Create a TALL VERTICAL PORTRAIT IMAGE (Aspect Ratio 10:16) HAND-DRAWN SKETCH style stock market infographic poster.

**CRITICAL: VERTICAL PORTRAIT FORMAT (10:16)**
- The image MUST be significantly taller than it is wide (Phone wallpaper style).
- Aspect Ratio: 10:16.
- Canvas Size: 1600x2560.

**CRITICAL: HAND-DRAWN AESTHETIC**
- Use ONLY pencil sketch lines, charcoal shading, ink pen strokes
- Visible paper grain texture throughout
- Line wobbles and imperfections (authentic hand-drawn feel)
- NO digital smoothness, NO vector graphics
- Shading: crosshatching, stippling, charcoal smudges only
- Background: Hand-drawn red-gold gradient with visible pencil strokes


Center: "AIå¤§æ¨¡å‹é‡åŒ–ç­–ç•¥" + "{datetime.now().strftime('%Y-%m-%d')}"
**Visual Highlight**: Add a realistic "Red Ink Stamp" (Seal) near the title with text: "æ¬¡æ—¥æ‹©æœºä¹°å…¥"

20 stock cards (10 per column) in a 2-Column Grid:
Left column: Pale blue background with paper texture
Right column: Pale yellow background with paper texture

**VISUAL CONTENT:**
Refined Hand-Drawn Table/Cards:

{cards_text}

{footer_content}

(Note: This prompt is optimized for the 'Nano Banana Pro3' model. Please ensure all details are consistent with high-quality hand-drawn vector art.)
"""

    return final_prompt, final_prompt


def save_reports(gemini_analysis, today):
    """ä¿å­˜æŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆ - ä»…ä¿å­˜åˆ°agent_outputsï¼‰"""
    # æ³¨é‡Šï¼šå¤–å±‚é‡å¤æ–‡ä»¶å·²ç§»é™¤ï¼Œæ‰€æœ‰ç»“æœé›†ä¸­åœ¨ agent_outputs/
    # æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œactual saving done in agent workflow
    date_str = today.split('_')[0]
    date_dir = os.path.join("results", date_str)
    
    print(f"ï¿½ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {date_dir}/agent_outputs/")
    print(f"   - result_analysis.txt")

    print(f"   - result_image_prompt.txt")
    
    return None


def save_prompts(prompts_dict, today):
    """ä¿å­˜æç¤ºè¯è®°å½•ï¼ˆå¯é€‰ - ç”¨äºè°ƒè¯•ï¼‰"""
    # æ³¨é‡Šï¼šæ­¤åŠŸèƒ½å¯é€‰ï¼Œæç¤ºè¯å·²åœ¨ agent_tasks/ ä¸­ä¿å­˜
    # ä¿ç•™æ­¤å‡½æ•°ç”¨äºè°ƒè¯•ç›®çš„
def enrich_stocks_from_analysis(selected_stocks, date_dir):
    """ä»åˆ†ææŠ¥å‘Šå›å¡«è¡Œä¸š/é¢˜æ"""
    try:
        print("ğŸ”„ æ­£åœ¨ä»åˆ†ææŠ¥å‘Šå›å¡« [è¡Œä¸š] å’Œ [è„±æ•ä¿¡æ¯]...")
        analysis_file = os.path.join(date_dir, "agent_outputs", "result_analysis.txt")
        if os.path.exists(analysis_file):
            import re
            with open(analysis_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£ææ¨¡å¼: 1. **ä¸­èˆªå…‰ç”µ (002179)** | å†›å·¥ç”µå­/é«˜ç«¯è¿æ¥å™¨ |
            # å…¼å®¹å¸¦æœ‰ ** çš„ markdown æ ¼å¼
            pattern = re.compile(r'\d+\.\s*(?:\*\*)?(.+?)\s*(?:\*\*)?\s*\((?:\*\*)?(\d{6})(?:\*\*)?\)\s*(?:\*\*)?\s*\|\s*(.+?)\s*\|')
            
            # æ„å»ºæ˜ å°„è¡¨ code -> industry
            industry_map = {}
            matches = pattern.findall(content)
            for name, code, ind in matches:
                # æ¸…ç†æ•°æ®
                clean_name = name.replace('*', '').strip()
                clean_code = code.replace('*', '').strip()
                clean_ind = ind.replace('*', '').strip()
                industry_map[clean_code] = clean_ind
                # print(f"  - è¯†åˆ«åˆ°: {clean_code} -> {clean_ind}")

            # å›å¡«åˆ° selected_stocks
            count = 0
            for stock in selected_stocks:
                code = stock['code']
                if code in industry_map:
                    stock['industry'] = industry_map[code]
                    count += 1
            
            print(f"âœ… æˆåŠŸä»åˆ†ææŠ¥å‘Šå›å¡« {count} æ¡è¡Œä¸šæ•°æ®")
            
            # ä¿å­˜å›å¡«åçš„ç»“æœåˆ° selected_top10.json
            top10_file = os.path.join(date_dir, "selected_top10.json")
            with open(top10_file, 'w', encoding='utf-8') as f:
                json.dump(selected_stocks, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å·²æ›´æ–° selected_top10.json")
            
            return True
        else:
            print("âš ï¸ æœªæ‰¾åˆ° result_analysis.txtï¼Œæ— æ³•å›å¡«ä¿¡æ¯")
            return False
    except Exception as e:
        print(f"âš ï¸ å›å¡«ä¿¡æ¯å‡ºé”™: {e}") 
        return False





def run(date_dir=None, force=False):
    """
    Main entry point for Daily Stock Selection & AI Analysis.
    
    Args:
        date_dir: è¾“å‡ºç›®å½•
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼Œå¿½ç•¥ä»Šæ—¥ç¼“å­˜
    """
    # 1. å…¨å¸‚åœºé€‰è‚¡
    # DEBUG: Mock selection to test downstream
    # print("âš ï¸ DEBUG MODE: Using mocked stock list to skip slow selection")
    # today = datetime.now().strftime('%Y%m%d')
    # selected = [
    #     {
    #         'code': 'sz002931', 'name': 'é”‹é¾™è‚¡ä»½', 'price': 10.5, 'reason': 'Debug', 
    #         'market_cap': 20.0, 'signals': ['B1'], 'K': 50, 'D': 50, 'J': 50, 'RSI': 50, 'near_amplitude': 5.0, 'far_amplitude': 10.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 10.5, 'æ¢æ‰‹%': 5.0, 'close': 10.5, 'volume': 100000}
    #     },
    #     {
    #         'code': 'sh603078', 'name': 'æ±ŸåŒ–å¾®', 'price': 20.0, 'reason': 'Debug', 
    #         'market_cap': 30.0, 'signals': ['B1'], 'K': 60, 'D': 60, 'J': 60, 'RSI': 60, 'near_amplitude': 6.0, 'far_amplitude': 12.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 20.0, 'æ¢æ‰‹%': 3.2, 'close': 20.0, 'volume': 200000}
    #     },
    #     {
    #         'code': 'sz000063', 'name': 'ä¸­å…´é€šè®¯', 'price': 30.0, 'reason': 'Debug',
    #         'market_cap': 1000.0, 'signals': ['B1'], 'K': 70, 'D': 70, 'J': 70, 'RSI': 70, 'near_amplitude': 3.0, 'far_amplitude': 8.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 30.0, 'æ¢æ‰‹%': 2.1, 'close': 30.0, 'volume': 500000}
    #     }
    # ]
    selected, today = run_full_selection(force=force)
    
    # ç¡®ä¿æ—¥æœŸæ–‡ä»¶å¤¹å­˜åœ¨
    date_str = today.split('_')[0]
    
    # Use passed in date_dir if provided, otherwise default
    if not date_dir:
        date_dir = os.path.join("results", date_str)
        
    os.makedirs(date_dir, exist_ok=True)
    
    gemini_analysis = None
    
    # 2. **NEW** è·å–çƒ­é—¨é¢˜æå¹¶è¿‡æ»¤è‚¡ç¥¨
    print("\n" + "="*70)
    print("  Step 2: çƒ­é—¨é¢˜æè¿‡æ»¤")
    print("="*70)
    
    if not selected:
        print("âŒ æ²¡æœ‰é€‰å‡ºè‚¡ç¥¨ï¼Œè·³è¿‡ B1 AI åˆ†æï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æ¨¡å—...")
        return False
    
    print(f"ğŸ“Š B1æŠ€æœ¯ç­›é€‰ç»“æœ: {len(selected)} åªè‚¡ç¥¨")
    
    # è·å–Top5çƒ­é—¨é¢˜æ
    hot_sectors = get_hot_sectors_from_fish_basin(date_dir, top_n=5)
    
    if not hot_sectors:
        print("âš ï¸ æœªèƒ½è·å–çƒ­é—¨é¢˜æï¼Œè·³è¿‡é¢˜æè¿‡æ»¤ï¼Œä½¿ç”¨å…¨éƒ¨B1è‚¡ç¥¨")
        filtered_stocks = selected
    else:
        # æŒ‰é¢˜æè¿‡æ»¤
        filtered_stocks = [s for s in selected if match_stock_sector(s, hot_sectors)]
        print(f"\nâœ… é¢˜æè¿‡æ»¤å®Œæˆ:")
        print(f"   - çƒ­é—¨é¢˜æTop5: {', '.join(hot_sectors)}")
        print(f"   - åŸå§‹B1è‚¡ç¥¨æ•°: {len(selected)}")
        print(f"   - è¿‡æ»¤åè‚¡ç¥¨æ•°: {len(filtered_stocks)}")
        
        if not filtered_stocks:
            print("\nâŒ æ²¡æœ‰ç¬¦åˆçƒ­é—¨é¢˜æçš„B1è‚¡ç¥¨ï¼Œæ”¾å®½æ¡ä»¶ä½¿ç”¨å…¨éƒ¨B1è‚¡ç¥¨")
            filtered_stocks = selected
        else:
            # æ˜¾ç¤ºè¿‡æ»¤å‡ºçš„è‚¡ç¥¨æ ·ä¾‹
            sample = min(5, len(filtered_stocks))
            print(f"\n   è¿‡æ»¤åè‚¡ç¥¨ç¤ºä¾‹ï¼ˆå‰{sample}åªï¼‰:")
            for i, stock in enumerate(filtered_stocks[:sample], 1):
                print(f"      {i}. {stock['name']} ({stock['code']}) - {stock.get('industry', 'N/A')}")
    
    # 3. è°ƒç”¨AIåˆ†æ (ä½¿ç”¨filtered_stocksè€Œä¸æ˜¯selected)
    print("\n" + "="*70)
    print("  Step 3: AIæ™ºèƒ½åˆ†æ")
    print("="*70)
    
    try:
        # ä¼ å…¥è¿‡æ»¤åçš„è‚¡ç¥¨ä¾›Agentåˆ†æ
        # Agentä¼šä»ä¸­é€‰å‡ºTopè¿›è¡Œæ·±åº¦åˆ†æ
        all_stocks = filtered_stocks
        
        # è°ƒç”¨Agentåˆ†æï¼ˆä¼ å…¥é¢˜æè¿‡æ»¤åçš„å€™é€‰ï¼‰
        gemini_analysis, analysis_prompt = call_gemini_analysis(all_stocks, date_dir)
        
        # å¦‚æœAgentè¿˜æœªç”Ÿæˆç»“æœï¼Œç­‰å¾…ç”¨æˆ·è¿è¡Œå·¥ä½œæµ
        if gemini_analysis is None:
            print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†ä»»åŠ¡")
            print("è¯·è¿è¡Œ Agent å·¥ä½œæµå®Œæˆåˆ†æï¼Œç„¶åå†æ¬¡æ‰§è¡Œæ­¤è„šæœ¬")
            return True # Not a failure, just a pause
        
        print("\nâœ… Agentåˆ†æå®Œæˆ")
        
        # åŠ è½½ Top 10 ä¸­é—´æ–‡ä»¶
        top10_file = os.path.join(date_dir, "selected_top10.json")
        top_stocks_list = all_stocks # é»˜è®¤
        
        if os.path.exists(top10_file):
             with open(top10_file, 'r', encoding='utf-8') as f:
                top_stocks_list = json.load(f)
             print(f"âš¡ åŠ è½½ Topè‚¡ç¥¨æ± : {len(top_stocks_list)} åª")
        else:
             print("âš ï¸ æœªæ‰¾åˆ° selected_top10.jsonï¼Œå°†ä½¿ç”¨å…¨éƒ¨è¿‡æ»¤åçš„è‚¡ç¥¨")

        # --- æ–°å¢æ­¥éª¤ï¼šä» AIåˆ†ææŠ¥å‘Š (result_analysis.txt) å›å¡« è¡Œä¸š/é¢˜æ ---
        # ç›®çš„ï¼šç›´æ¥ä»åˆ†æç»“æœå›å¡«ä¿¡æ¯
        enrich_stocks_from_analysis(top_stocks_list, date_dir)
        # -------------------------------------------------------------------
    except Exception as e_ai:
         print(f"âš ï¸ AIåˆ†ææ¨¡å—å‡ºé”™: {e_ai}")
         return False

    # (Skip Image Prompt generation if no analysis, logically)
    if gemini_analysis:
        try:
            # ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
            image_prompt, img_gen_prompt = generate_image_prompt(gemini_analysis, top_stocks_list, date_dir)
            if image_prompt is not None:
                print("âœ… å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ")
                
                # ä¿å­˜ç‹¬ç«‹å›¾ç‰‡æç¤ºè¯æ–‡ä»¶
                prompt_dir = os.path.join(date_dir, "AIæç¤ºè¯")
                os.makedirs(prompt_dir, exist_ok=True)
                img_prompt_file = os.path.join(prompt_dir, "è¶‹åŠ¿B1é€‰è‚¡_Prompt.txt")
                with open(img_prompt_file, 'w', encoding='utf-8') as f:
                    f.write(image_prompt)
                print(f"ğŸ“ å›¾ç‰‡æç¤ºè¯å·²ä¿å­˜: {img_prompt_file}")
        except Exception as e_img:
            print(f"âš ï¸ å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå¤±è´¥: {e_img}")

    # 4. ä¿å­˜æŠ¥å‘Š
    save_reports(gemini_analysis, today)
    return True


if __name__ == "__main__":
    run()
