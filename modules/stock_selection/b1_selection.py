"""
å…¨å¸‚åœºé€‰è‚¡ + AIæ™ºèƒ½åˆ†æç”ŸæˆæŠ¥å‘Š
1. 300å¹¶å‘å…¨å¸‚åœºé€‰è‚¡ï¼ˆå¸‚å€¼100äº¿+ï¼Œæ’é™¤STï¼‰
2. æ¥å…¥Geminiåˆ†æTop10å€¼åšç‡
3. ç”Ÿæˆæ¨èåŸå› MDæ–‡æ¡£
4. ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼ˆè„±æ•å¤„ç†ï¼‰
"""
import sys
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import requests
import base64
import time
import numpy as np
from tqdm import tqdm

# å¯¼å…¥é…ç½®å’ŒPromptæ¨¡å—
from common.config import MAX_WORKERS, MIN_MARKET_CAP
from common.prompts import (
    NumpyEncoder, 
    get_analysis_prompt, 
    get_xiaohongshu_prompt, 
    get_image_prompt
)

# å¯¼å…¥æ•°æ®è·å–å’Œä¿¡å·æ£€æµ‹æ¨¡å—

# å¯¼å…¥æ•°æ®è·å–å’Œä¿¡å·æ£€æµ‹æ¨¡å—
from common.data_fetcher import get_all_stock_list, get_stock_data
from common.signals import check_stock_signal
# from modules.daily_report.sector_flow import run_daily_analysis (Refactored)
# from modules.daily_report.generate_ladder_prompt import generate_ladder_prompt (Refactored)

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def process_single_stock(args):
    """å¤„ç†å•åªè‚¡ç¥¨"""
    code, name, market_cap, industry = args
    try:
        df = get_stock_data(code, 300)
        if df is None or len(df) < 120:
            return None
        
        result = check_stock_signal(df, code)
        
        # è·å–æœ€åä¸€è¡ŒåŸå§‹æ•°æ®
        last_row = df.iloc[-1].to_dict()
        last_row['date'] = str(last_row['date'])[:10]
        
        return {
            'code': code,
            'name': name,
            'market_cap': float(market_cap),
            'industry': industry if str(industry).lower() != 'nan' else None,  # é¢˜æ/è¡Œä¸š
            'signal': bool(result.get('signal', False)),
            'signals': result.get('signals', []),
            'K': float(result.get('K', 0)),
            'D': float(result.get('D', 0)),
            'J': float(result.get('J', 0)),
            'RSI': float(result.get('RSI', 0)),
            'near_amplitude': float(result.get('è¿‘æœŸæŒ¯å¹…', 0)),
            'far_amplitude': float(result.get('è¿œæœŸæŒ¯å¹…', 0)),
            'raw_data_mock': last_row
        }
    except Exception as e:
        return None


def run_full_selection(force=False):
    """å…¨å¸‚åœºé€‰è‚¡
    
    Args:
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°é€‰è‚¡ï¼Œå¿½ç•¥ä»Šæ—¥å·²æœ‰ç»“æœ
    """
    today_date = datetime.now().strftime('%Y%m%d')
    date_dir = os.path.join("results", today_date)
    os.makedirs(date_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šæ—¥ç»“æœ
    if not force:
        import glob
        existing_files = glob.glob(os.path.join(date_dir, f"selected_{today_date}_*.json")) 
        if existing_files:
            latest_file = max(existing_files, key=os.path.getctime)
            print(f"âš¡ å‘ç°ä»Šæ—¥å·²æœ‰é€‰è‚¡ç»“æœ: {latest_file}")
            with open(latest_file, 'r', encoding='utf-8') as f:
                selected = json.load(f)
            # ä»æ–‡ä»¶åæå–å®Œæ•´æ—¶é—´æˆ³ (selected_YYYYMMDD_HHMMSS.json)
            filename = os.path.basename(latest_file)
            # filenameæ ¼å¼: selected_20260118_004725.json
            # å»æ‰å‰ç¼€ selected_ (9 chars) å’Œåç¼€ .json (5 chars)
            timestamp = filename[9:-5] 
            return selected, timestamp
    else:
        print("ğŸ”„ --force æ¨¡å¼ï¼šå¿½ç•¥ä»Šæ—¥ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°é€‰è‚¡")

    print("=" * 70)
    print("  ä¸œæ–¹è´¢å¯Œ - çŸ¥è¡ŒB1é€‰è‚¡ç­–ç•¥ (AIæ™ºèƒ½åˆ†æç‰ˆ)")
    print(f"  å¸‚å€¼ >= {MIN_MARKET_CAP}äº¿ | æ’é™¤ST | å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")
    print(f"  æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    print("\n[1/4] è·å–è‚¡ç¥¨åˆ—è¡¨...")
    stock_list = get_all_stock_list(min_market_cap=MIN_MARKET_CAP, exclude_st=True)
    
    # æ³¨é‡Šï¼šç§»é™¤500åªè‚¡ç¥¨é™åˆ¶ï¼Œåˆ†æå…¨éƒ¨è‚¡ç¥¨
    # stock_list = stock_list.head(500)
    print(f"âš ï¸ å°†åˆ†æå…¨éƒ¨ {len(stock_list)} åªè‚¡ç¥¨")
    
    if len(stock_list) == 0:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return [], ""
    
    args_list = [
        (row['code'], row['name'], row['market_cap'], row.get('industry', '')) 
        for _, row in stock_list.iterrows()
    ]
    
    print(f"\n[2/4] å¹¶å‘åˆ†æ {len(args_list)} åªè‚¡ç¥¨çš„ä¿¡å·...")
    
    selected = []
    all_results = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_stock, args): args[0] for args in args_list}
        
        for future in tqdm(as_completed(futures), total=len(futures), desc="é€‰è‚¡è¿›åº¦"):
            result = future.result()
            if result is not None:
                all_results.append(result)
                if result['signal']:
                    selected.append(result)
    
    # ä¿å­˜ç»“æœ
    today_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜æ‰€æœ‰åŸå§‹æ•°æ®
    raw_file = os.path.join(date_dir, f"all_stocks_{today_timestamp}.jsonl")
    with open(raw_file, 'w', encoding='utf-8') as f:
        for item in all_results:
            f.write(json.dumps(item, cls=NumpyEncoder, ensure_ascii=False) + '\n')
    
    print(f"\nğŸ“ åŸå§‹æ•°æ®: {raw_file} ({len(all_results)} æ¡)")
    
    # ä¿å­˜é€‰è‚¡ç»“æœ
    selected_file = os.path.join(date_dir, f"selected_{today_timestamp}.json")
    with open(selected_file, 'w', encoding='utf-8') as f:
        json.dump(selected, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
            
    print(f"ğŸ“ é€‰è‚¡ç»“æœ: {selected_file} ({len(selected)} åª)")
    
    return selected, today_timestamp


def save_stock_summary(selected_stocks, date_dir, timestamp):
    """ä¿å­˜ä¾¿äºç§ä¿¡å‘é€çš„æ–‡æœ¬æ±‡æ€»"""
    summary_file = os.path.join(date_dir, f"stock_list_summary_{timestamp}.txt")
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"ğŸ“… é€‰è‚¡æ±‡æ€» {datetime.now().strftime('%Y-%m-%d')}\n")
        f.write(f"ç­–ç•¥: AIå¤§æ¨¡å‹é‡åŒ–\n")
        f.write("-" * 30 + "\n\n")
        
        for idx, stock in enumerate(selected_stocks, 1):
            code = stock['code']
            name = stock['name']
            industry = stock.get('industry', 'æœªçŸ¥è¡Œä¸š')
            
            f.write(f"{idx}. {name} ({code})\n")
            if industry and str(industry).lower() != 'nan':
                f.write(f"   è¡Œä¸š: {industry}\n")
            # è·å–ä¿¡å·åˆ—è¡¨
            stock_signals = stock.get('signals', [])
            
            if stock_signals:
                # ç»Ÿä¸€æœ¯è¯­
                sanitized_signals = [
                    s.replace('B1', 'ä¹°ç‚¹')
                     .replace('B', 'ä¹°ç‚¹')
                     .replace('åŸå§‹', 'æ ‡å‡†')
                    for s in stock_signals
                ]
                f.write(f"   å‘½ä¸­è§„åˆ™: {'+'.join(sanitized_signals)}\n")
            
            f.write("\n")
            
        f.write("-" * 30 + "\n")
        f.write("æ³¨ï¼šæ¬¡æ—¥å…³æ³¨è¿›åœºï¼ŒéæŠ•èµ„å»ºè®®ã€‚\n")
        f.write("æ›´å¤šè¯¦æƒ…è¯·çœ‹æ–‡æ¡ˆåˆ†æã€‚\n")

    print(f"ğŸ“ ç§ä¿¡æ±‡æ€»åˆ—è¡¨: {summary_file}")
    return summary_file

# æ³¨é‡Šï¼šsave_stock_summary åŠŸèƒ½å·²ç§»è‡³ agent_outputs/result_analysis.txt
# æ­¤å‡½æ•°ä¿ç•™ä½†ä¸å†è°ƒç”¨

# ================ è„±æ•å·¥å…·å‡½æ•° ================

def desensitize_stock_name(name):
    """è‚¡ç¥¨åç§°è„±æ•ï¼šä¿ç•™å‰2å­—ï¼Œåé¢æ”¹ä¸ºæ‹¼éŸ³é¦–å­—æ¯å¤§å†™"""
    if len(name) <= 2:
        return name
    
    try:
        from pypinyin import lazy_pinyin, Style
        # è·å–åç¼€çš„æ‹¼éŸ³é¦–å­—æ¯
        suffix = name[2:]
        pinyin_initials = lazy_pinyin(suffix, style=Style.FIRST_LETTER)
        # è½¬å¤§å†™å¹¶æ‹¼æ¥
        initials = ''.join([p.upper() for p in pinyin_initials])
        return name[:2] + initials
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… pypinyinï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘
        print("Warning: pypinyin not installed. Using simplified desensitization.")
        suffix = name[2:]
        # å–åç¼€å‰ä¸¤ä¸ªå­—ç¬¦ä½œä¸ºæ ‡è¯†
        return name[:2] + (suffix[:2].upper() if len(suffix) >= 2 else suffix.upper())

def desensitize_stock_code(code):
    """è‚¡ç¥¨ä»£ç è„±æ•ï¼šå‰4ä½ä¿ç•™ï¼Œå2ä½æ”¹ä¸º**"""
    if len(code) < 6:
        return code
    return code[:4] + '**'



def call_gemini_analysis(selected_stocks, date_dir):
    """ä½¿ç”¨Agentåˆ†æTop10å€¼åšç‡"""
    # å‡†å¤‡åˆ†ææ•°æ®
    stocks_info = []
    for s in selected_stocks:
        raw = s['raw_data_mock']
        stocks_info.append({
            'ä»£ç ': s['code'],
            'åç§°': s['name'],
            'æ€»å¸‚å€¼(äº¿å…ƒ)': round(s['market_cap'], 0),
            'ä¿¡å·ç±»å‹': ', '.join(s['signals']),
            'K': round(s['K'], 1),
            'D': round(s['D'], 1),
            'J': round(s['J'], 1),
            'RSI': round(s['RSI'], 1),
            'è¿‘æœŸæŒ¯å¹…%': round(s['near_amplitude'], 1),
            'è¿œæœŸæŒ¯å¹…%': round(s['far_amplitude'], 1),
            'æ”¶ç›˜ä»·': raw['close'],
            'æˆäº¤é‡': raw['volume']
        })
    
    prompt = get_analysis_prompt(stocks_info)

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_analysis.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"\n[4/4] ä»»åŠ¡å·²ä¿å­˜ï¼Œç­‰å¾…Agentåˆ†æTop10...")
    print(f"ğŸ“ ä»»åŠ¡æ–‡ä»¶: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_analysis.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            result = f.read()
        print("âœ… Agentåˆ†æå®Œæˆ")
        
        # --- æå–å¹¶ä¿å­˜ Top 10 ---
        import re
        top_codes = re.findall(r'\((\d{6})\)', result)
        seen = set()
        unique_codes = []
        for c in top_codes:
            if c not in seen:
                unique_codes.append(c)
                seen.add(c)
        unique_codes = unique_codes[:10]
        
        stock_map = {s['code']: s for s in selected_stocks}
        top_stocks = []
        for c in unique_codes:
            if c in stock_map:
                top_stocks.append(stock_map[c])
        
        top10_file = os.path.join(date_dir, "selected_top10.json")
        with open(top10_file, 'w', encoding='utf-8') as f:
            json.dump(top_stocks, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
        print(f"ğŸ“ å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶: {top10_file} ({len(top_stocks)}åª)")
        
        return result, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        print("æç¤ºï¼šè¯·è¿è¡Œ Agent å·¥ä½œæµæ¥å¤„ç†åˆ†æä»»åŠ¡")
        return None, prompt


def generate_xiaohongshu_post(gemini_analysis, selected_stocks, date_dir):
    """ä½¿ç”¨Agentç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼ˆè„±æ•å¤„ç†ï¼‰"""
    # å‡†å¤‡è„±æ•åçš„è‚¡ç¥¨åˆ—è¡¨
    masked_stocks = []
    for s in selected_stocks:
        masked_stocks.append({
            'name': s['name'],
            'name_masked': desensitize_stock_name(s['name']),
            'code': s['code'],
            'code_masked': desensitize_stock_code(s['code']),
            'industry': s.get('industry', ''),
        })
    
    # å‡†å¤‡è„±æ•è¯´æ˜
    prompt = get_xiaohongshu_prompt(
        gemini_analysis, 
        json.dumps(masked_stocks, ensure_ascii=False, indent=2), 
        datetime.now().strftime('%Y-%m-%d')
    )

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_xiaohongshu.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"ğŸ“ å°çº¢ä¹¦ä»»åŠ¡å·²ä¿å­˜: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_xiaohongshu.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            result = f.read()
        print("âœ… å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
        return result, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        return None, prompt


def generate_image_prompt(gemini_analysis, selected_stocks, date_dir):
    """ä½¿ç”¨Agentç”Ÿæˆä¿¡æ¯å›¾æç¤ºè¯"""
    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    if len(selected_stocks) > 10:
        print(f"âš ï¸ è­¦å‘Š: ä¼ å…¥å›¾ç‰‡ç”Ÿæˆçš„è‚¡ç¥¨æ•°é‡ä¸º {len(selected_stocks)}ï¼Œé¢„æœŸä¸º10ã€‚")
        # å°è¯•ä½¿ç”¨å‰10ä¸ª
        selected_stocks = selected_stocks[:10]

    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    stock_summary = []
    for s in selected_stocks:
        stock_summary.append({
            'name': s['name'],
            'name_masked': s.get('name_masked', desensitize_stock_name(s['name'])),  # ä¼˜å…ˆä½¿ç”¨å·²æœ‰è„±æ•å
            'code': s['code'],
            'code_masked': s.get('code_masked', desensitize_stock_code(s['code'])),  # ä¼˜å…ˆä½¿ç”¨å·²æœ‰è„±æ•ä»£ç 
            'industry': s.get('industry', 'æœªçŸ¥'),
            'signals': ','.join(s.get('signals', [])).replace('B1','æ ‡å‡†ä¹°ç‚¹').replace('B','æ ‡å‡†ä¹°ç‚¹').replace('åŸå§‹ä¹°ç‚¹','æ ‡å‡†ä¹°ç‚¹'),
            'J': round(s.get('J', 0), 2),
            'RSI': round(s.get('RSI', 0), 2),
        })
    
    # ä»å°çº¢ä¹¦æ–‡æ¡ˆæå–æ¬¡æ—¥ç­–ç•¥
    # ä»åˆ†æç»“æœæå– "æ•´ä½“å¸‚åœºå¤ç›˜" å’Œ "æ¬¡æ—¥äº¤æ˜“ç­–ç•¥"
    import re
    
    # --- æå–å¤ç›˜ä¸ç­–ç•¥ (ä¼˜å…ˆä½¿ç”¨ Step 4 ä¸“ç”¨æ‘˜è¦) ---
    market_review = "æ— å¤ç›˜å†…å®¹"
    tomorrow_strategy = ""
    
    # å°è¯•æå– "Step 4: å›¾ç‰‡ç”Ÿæˆä¸“ç”¨æ‘˜è¦"
    summary_section_match = re.search(r'å›¾ç‰‡ç”Ÿæˆä¸“ç”¨æ‘˜è¦\s*(.+)', gemini_analysis, re.DOTALL)
    
    SUMMARY_FOUND = False
    if summary_section_match:
        summary_content = summary_section_match.group(1)
        
        # æå–å¤ç›˜
        match_rev = re.search(r'ğŸ“\s*(.+?)(?=\n\s*ğŸ’¡|$)', summary_content, re.DOTALL)
        if match_rev:
            extracted_rev = match_rev.group(1).strip().replace('**', '').replace('æ•´ä½“å¤ç›˜', '').strip()
            if extracted_rev:
                market_review = extracted_rev
                SUMMARY_FOUND = True
        
        # æå–ç­–ç•¥
        match_str = re.search(r'ğŸ’¡\s*(.+)', summary_content, re.DOTALL)
        if match_str:
            extracted_str = match_str.group(1).strip().replace('**', '').replace('æ¬¡æ—¥ç­–ç•¥', '').strip()
            if extracted_str:
                tomorrow_strategy = extracted_str
                SUMMARY_FOUND = True
                
    if not SUMMARY_FOUND:
        print("âš ï¸ æœªæ‰¾åˆ°ä¸“ç”¨æ‘˜è¦ï¼Œä½¿ç”¨æ™ºèƒ½æå–å›é€€æ¨¡å¼...")
        # å›é€€æ¨¡å¼ï¼šä»æ­£æ–‡æå–ç¬¬ä¸€æ®µ
        match_review = re.search(r'æ•´ä½“å¸‚åœºå¤ç›˜\s+(.+?)(?=\n\s*æ¬¡æ—¥äº¤æ˜“ç­–ç•¥|$)', gemini_analysis, re.DOTALL)
        if match_review:
            full_review = match_review.group(1).strip()
            market_review = full_review.split('\n')[0].strip().replace('**', '')

        match_strategy = re.search(r'æ¬¡æ—¥äº¤æ˜“ç­–ç•¥\s+(.+?)(?=\n\s*é£é™©æç¤º|$)', gemini_analysis, re.DOTALL)
        if match_strategy:
            full_strategy = match_strategy.group(1).strip()
            # æå– **æ ¸å¿ƒç‚¹**
            strategy_points = re.findall(r'\*\*(.*?)\*\*', full_strategy)
            if strategy_points:
                tomorrow_strategy = "ã€".join(strategy_points[:3])
            else:
                tomorrow_strategy = full_strategy.split('\n')[0].strip().replace('**', '')

    # --- å¯¹å¤ç›˜å’Œç­–ç•¥æ–‡æ¡ˆè¿›è¡Œè„±æ•æ›¿æ¢ ---
    # éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œå°†æ–‡æ¡ˆä¸­çš„"å…¨å"æ›¿æ¢ä¸º"è„±æ•å"
    # æŒ‰åç§°é•¿åº¦é™åºæ’åˆ—ï¼Œé¿å…çŸ­åè¯¯ä¼¤é•¿å (e.g. "ä¸­èˆª" vs "ä¸­èˆªå…‰ç”µ")
    sorted_stocks = sorted(selected_stocks, key=lambda x: len(x['name']), reverse=True)
    
    for s in sorted_stocks:
        name = s['name']
        name_masked = s.get('name_masked', desensitize_stock_name(name))
        code = s['code']
        code_masked = s.get('code_masked', desensitize_stock_code(code))
        
        # æ›¿æ¢åç§°
        if name in market_review:
            market_review = market_review.replace(name, name_masked)
        if name in tomorrow_strategy:
            tomorrow_strategy = tomorrow_strategy.replace(name, name_masked)
        
        # æ›¿æ¢ä»£ç  (å¦‚æœæœ‰çš„è¯)
        if code in market_review:
            market_review = market_review.replace(code, code_masked)
        if code in tomorrow_strategy:
            tomorrow_strategy = tomorrow_strategy.replace(code, code_masked)

    
    # æ„å»ºåŠ¨æ€ Footer å†…å®¹
    footer_content = ""
    if market_review and market_review != "æ— å¤ç›˜å†…å®¹":
        footer_content += f"ğŸ“ æ•´ä½“å¤ç›˜\n{market_review}\n\n"
    
    if tomorrow_strategy:
        footer_content += f"ğŸ’¡ æ¬¡æ—¥ç­–ç•¥\n{tomorrow_strategy}"

    prompt = get_image_prompt(stock_summary, footer_content, datetime.now().strftime('%Y-%m-%d'))

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_image_prompt.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"ğŸ“ å›¾ç‰‡ç”Ÿæˆä»»åŠ¡å·²ä¿å­˜: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_image_prompt.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            final_prompt = f.read()
        final_prompt += "\n\n(Note: This prompt is optimized for the 'Nano Banana Pro3' model. Please ensure all details are consistent with high-quality hand-drawn vector art.)"
        print("âœ… å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ")
        return final_prompt, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        return None, prompt


def save_reports(gemini_analysis, xiaohongshu_post, today):
    """ä¿å­˜æŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆ - ä»…ä¿å­˜åˆ°agent_outputsï¼‰"""
    # æ³¨é‡Šï¼šå¤–å±‚é‡å¤æ–‡ä»¶å·²ç§»é™¤ï¼Œæ‰€æœ‰ç»“æœé›†ä¸­åœ¨ agent_outputs/
    # æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œactual saving done in agent workflow
    date_str = today.split('_')[0]
    date_dir = os.path.join("results", date_str)
    
    print(f"ï¿½ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {date_dir}/agent_outputs/")
    print(f"   - result_analysis.txt")
    print(f"   - result_xiaohongshu.txt")
    print(f"   - result_image_prompt.txt")
    
    return None, None


def save_prompts(prompts_dict, today):
    """ä¿å­˜æç¤ºè¯è®°å½•ï¼ˆå¯é€‰ - ç”¨äºè°ƒè¯•ï¼‰"""
    # æ³¨é‡Šï¼šæ­¤åŠŸèƒ½å¯é€‰ï¼Œæç¤ºè¯å·²åœ¨ agent_tasks/ ä¸­ä¿å­˜
    # ä¿ç•™æ­¤å‡½æ•°ç”¨äºè°ƒè¯•ç›®çš„
def enrich_stocks_from_analysis(selected_stocks, date_dir):
    """ä»åˆ†ææŠ¥å‘Šå›å¡«è¡Œä¸š/é¢˜æ"""
    try:
        print("ğŸ”„ æ­£åœ¨ä»åˆ†ææŠ¥å‘Šå›å¡« [è¡Œä¸š] å’Œ [è„±æ•ä¿¡æ¯]...")
        analysis_file = os.path.join(date_dir, "agent_outputs", "result_analysis.txt")
        if os.path.exists(analysis_file):
            import re
            with open(analysis_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£ææ¨¡å¼: 1. **ä¸­èˆªå…‰ç”µ (002179)** | å†›å·¥ç”µå­/é«˜ç«¯è¿æ¥å™¨ |
            # å…¼å®¹å¸¦æœ‰ ** çš„ markdown æ ¼å¼
            pattern = re.compile(r'\d+\.\s*(?:\*\*)?(.+?)\s*(?:\*\*)?\s*\((?:\*\*)?(\d{6})(?:\*\*)?\)\s*(?:\*\*)?\s*\|\s*(.+?)\s*\|')
            
            # æ„å»ºæ˜ å°„è¡¨ code -> industry
            industry_map = {}
            matches = pattern.findall(content)
            for name, code, ind in matches:
                # æ¸…ç†æ•°æ®
                clean_name = name.replace('*', '').strip()
                clean_code = code.replace('*', '').strip()
                clean_ind = ind.replace('*', '').strip()
                industry_map[clean_code] = clean_ind
                # print(f"  - è¯†åˆ«åˆ°: {clean_code} -> {clean_ind}")

            # å›å¡«åˆ° selected_stocks
            count = 0
            for stock in selected_stocks:
                code = stock['code']
                if code in industry_map:
                    stock['industry'] = industry_map[code]
                    count += 1
            
            print(f"âœ… æˆåŠŸä»åˆ†ææŠ¥å‘Šå›å¡« {count} æ¡è¡Œä¸šæ•°æ®")
            
            # ä¿å­˜å›å¡«åçš„ç»“æœåˆ° selected_top10.json
            top10_file = os.path.join(date_dir, "selected_top10.json")
            with open(top10_file, 'w', encoding='utf-8') as f:
                json.dump(selected_stocks, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å·²æ›´æ–° selected_top10.json")
            
            return True
        else:
            print("âš ï¸ æœªæ‰¾åˆ° result_analysis.txtï¼Œæ— æ³•å›å¡«ä¿¡æ¯")
            return False
    except Exception as e:
        print(f"âš ï¸ å›å¡«ä¿¡æ¯å‡ºé”™: {e}") 
        return False





def run(date_dir=None, force=False):
    """
    Main entry point for Daily Stock Selection & AI Analysis.
    
    Args:
        date_dir: è¾“å‡ºç›®å½•
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼Œå¿½ç•¥ä»Šæ—¥ç¼“å­˜
    """
    # 1. å…¨å¸‚åœºé€‰è‚¡
    # DEBUG: Mock selection to test downstream
    # print("âš ï¸ DEBUG MODE: Using mocked stock list to skip slow selection")
    # today = datetime.now().strftime('%Y%m%d')
    # selected = [
    #     {
    #         'code': 'sz002931', 'name': 'é”‹é¾™è‚¡ä»½', 'price': 10.5, 'reason': 'Debug', 
    #         'market_cap': 20.0, 'signals': ['B1'], 'K': 50, 'D': 50, 'J': 50, 'RSI': 50, 'near_amplitude': 5.0, 'far_amplitude': 10.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 10.5, 'æ¢æ‰‹%': 5.0, 'close': 10.5, 'volume': 100000}
    #     },
    #     {
    #         'code': 'sh603078', 'name': 'æ±ŸåŒ–å¾®', 'price': 20.0, 'reason': 'Debug', 
    #         'market_cap': 30.0, 'signals': ['B1'], 'K': 60, 'D': 60, 'J': 60, 'RSI': 60, 'near_amplitude': 6.0, 'far_amplitude': 12.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 20.0, 'æ¢æ‰‹%': 3.2, 'close': 20.0, 'volume': 200000}
    #     },
    #     {
    #         'code': 'sz000063', 'name': 'ä¸­å…´é€šè®¯', 'price': 30.0, 'reason': 'Debug',
    #         'market_cap': 1000.0, 'signals': ['B1'], 'K': 70, 'D': 70, 'J': 70, 'RSI': 70, 'near_amplitude': 3.0, 'far_amplitude': 8.0,
    #         'raw_data_mock': {'æ”¶ç›˜': 30.0, 'æ¢æ‰‹%': 2.1, 'close': 30.0, 'volume': 500000}
    #     }
    # ]
    selected, today = run_full_selection(force=force)
    
    # ç¡®ä¿æ—¥æœŸæ–‡ä»¶å¤¹å­˜åœ¨
    date_str = today.split('_')[0]
    
    # Use passed in date_dir if provided, otherwise default
    if not date_dir:
        date_dir = os.path.join("results", date_str)
        
    os.makedirs(date_dir, exist_ok=True)
    
    gemini_analysis = None
    xiaohongshu_post = None
    
    # 4. è°ƒç”¨AIåˆ†æ (ä»…å½“æœ‰é€‰è‚¡æ—¶)
    if not selected:
        print("âŒ æ²¡æœ‰é€‰å‡ºè‚¡ç¥¨ï¼Œè·³è¿‡ B1 AI åˆ†æï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æ¨¡å—...")
        return False
    else:
        try:
            # ä¼ å…¥æ‰€æœ‰é€‰ä¸­çš„è‚¡ç¥¨ä¾›Agentåˆ†æ
            # Agentä¼šä»ä¸­é€‰å‡ºTop10è¿›è¡Œæ·±åº¦åˆ†æ
            all_stocks = selected
            
            # è°ƒç”¨Agentåˆ†æï¼ˆä¼ å…¥å…¨éƒ¨å€™é€‰ï¼‰
            gemini_analysis, analysis_prompt = call_gemini_analysis(all_stocks, date_dir)
            
            # å¦‚æœAgentè¿˜æœªç”Ÿæˆç»“æœï¼Œç­‰å¾…ç”¨æˆ·è¿è¡Œå·¥ä½œæµ
            if gemini_analysis is None:
                print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†ä»»åŠ¡")
                print("è¯·è¿è¡Œ Agent å·¥ä½œæµå®Œæˆåˆ†æï¼Œç„¶åå†æ¬¡æ‰§è¡Œæ­¤è„šæœ¬")
                return True # Not a failure, just a pause
            
            print("\nâœ… Agentåˆ†æå®Œæˆ")
            
            # åŠ è½½ Top 10 ä¸­é—´æ–‡ä»¶
            top10_file = os.path.join(date_dir, "selected_top10.json")
            top_stocks_list = all_stocks # é»˜è®¤
            
            if os.path.exists(top10_file):
                 with open(top10_file, 'r', encoding='utf-8') as f:
                    top_stocks_list = json.load(f)
                 print(f"âš¡ åŠ è½½ Top 10 è‚¡ç¥¨æ± : {len(top_stocks_list)} åª")
            else:
                 print("âš ï¸ æœªæ‰¾åˆ° selected_top10.jsonï¼Œå°†ä½¿ç”¨å…¨éƒ¨è‚¡ç¥¨")

            # ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
            xiaohongshu_post, xhs_prompt = generate_xiaohongshu_post(gemini_analysis, top_stocks_list, date_dir)
            if xiaohongshu_post is None:
                print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†å°çº¢ä¹¦æ–‡æ¡ˆ")
                return True
            print("âœ… å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
            
            # --- æ–°å¢æ­¥éª¤ï¼šä» AIåˆ†ææŠ¥å‘Š (result_analysis.txt) å›å¡« è¡Œä¸š/é¢˜æ ---
            # ç›®çš„ï¼šè§£è€¦å¯¹å°çº¢ä¹¦æ–‡æ¡ˆçš„ä¾èµ–ï¼Œç›´æ¥ä½¿ç”¨åˆ†æç»“æœ
            enrich_stocks_from_analysis(top_stocks_list, date_dir)
            # -------------------------------------------------------------------
        except Exception as e_ai:
             print(f"âš ï¸ AIåˆ†ææ¨¡å—å‡ºé”™: {e_ai}")
             return False

    # (Skip Image Prompt generation if no analysis, logically)
    if gemini_analysis:
        try:
            # ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
            image_prompt, img_gen_prompt = generate_image_prompt(gemini_analysis, top_stocks_list, date_dir)
            if image_prompt is not None:
                print("âœ… å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ")
                
                # ä¿å­˜ç‹¬ç«‹å›¾ç‰‡æç¤ºè¯æ–‡ä»¶
                prompt_dir = os.path.join(date_dir, "AIæç¤ºè¯")
                os.makedirs(prompt_dir, exist_ok=True)
                img_prompt_file = os.path.join(prompt_dir, "è¶‹åŠ¿B1é€‰è‚¡_Prompt.txt")
                with open(img_prompt_file, 'w', encoding='utf-8') as f:
                    f.write(image_prompt)
                print(f"ğŸ“ å›¾ç‰‡æç¤ºè¯å·²ä¿å­˜: {img_prompt_file}")
        except Exception as e_img:
            print(f"âš ï¸ å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå¤±è´¥: {e_img}")

    # 4. ä¿å­˜æŠ¥å‘Š
    save_reports(gemini_analysis, xiaohongshu_post, today)
    return True


if __name__ == "__main__":
    run()
