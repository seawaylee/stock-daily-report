import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime
import time
import os
from .fish_basin_helper import save_to_excel

# Symbol Mapping
# Format: "Name": "Code"
# Updated based on user feedback (Jan 20)
SYMBOLS = {
    # --- A-Shares ---
    "ä¸Šè¯æŒ‡æ•°": "sh000001",
    "æ·±è¯æˆæŒ‡": "sz399001",
    "åˆ›ä¸šæ¿æŒ‡": "sz399006",
    "ç§‘åˆ›50": "sh000688",
    "åŒ—è¯50": "bj899050",
    "æ²ªæ·±300": "sh000300",
    "ä¸­è¯500": "sz399905",
    "ä¸­è¯1000": "sz399852", 
    "ä¸­è¯A500": "sh000510", # Updated to sh000510
    "å›½è¯2000": "sz399303", 
    "å›½è¯å¾®ç›˜": "sz399852", 

    # --- HK ---
    "æ’ç”ŸæŒ‡æ•°": "hkHSI",
    "æ’ç”Ÿç§‘æŠ€": "hkHSTECH",
    
    # --- US ---
    "çº³æ–¯è¾¾å…‹": "us.IXIC",
    "æ ‡æ™®500": "us.INX",

    # --- Commodities / FX ---
    "COMEXé»„é‡‘": "GC", 
    "COMEXç™½é“¶": "SI",
    "ç¾å…ƒç¦»å²¸äººæ°‘å¸": "FX_USDCNH", # Added (Using CNY proxy if CNH unavailable)
}

# Cache for Spot Data
SPOT_DATA_CACHE = None

def get_a_share_spot(code):
    """Retrieve spot data for an A-share index from cache"""
    global SPOT_DATA_CACHE
    if SPOT_DATA_CACHE is None:
        try:
            # Code format in Sina Spot: sh000001
            SPOT_DATA_CACHE = ak.stock_zh_index_spot_sina()
        except Exception as e:
            print(f"Failed to fetch A-share spot data: {e}")
            SPOT_DATA_CACHE = pd.DataFrame() # prevent retry loop failure

    if SPOT_DATA_CACHE.empty:
        return None

    # Search
    # Sina Spot codes are like 'sh000001'
    row = SPOT_DATA_CACHE[SPOT_DATA_CACHE['ä»£ç '] == code]
    if not row.empty:
        return row.iloc[0]
    return None

def fetch_data(name, code):
    """
    Fetch data for a given symbol.
    Handles Commodities, US/HK Indices, and A-Share Indices.
    """
    try:
        df = None
        
        # 0. FX (USD/CNH)
        if code == "FX_USDCNH":
            try:
                df = ak.currency_boc_sina(symbol="ç¾å…ƒ", start_date="20240101", end_date="20261231")
                if df is not None:
                     df = df.rename(columns={'æ—¥æœŸ': 'date', 'ä¸­è¡ŒæŠ˜ç®—ä»·': 'close'})
                     df['close'] = pd.to_numeric(df['close'], errors='coerce') / 100.0
                     df['volume'] = 0
                     df['open'] = df['close']
                     df['high'] = df['close']
                     df['low'] = df['close']
            except: pass
            if df is not None: return df

        # 1. Commodities (COMEX Futures)
        if code in ["GC", "SI"]:
            df = ak.futures_foreign_hist(symbol=code) 
            if df is not None:
                df = df.rename(columns={'date': 'date', 'close': 'close', 'open': 'open', 'high': 'high', 'low': 'low'})
                df['date'] = pd.to_datetime(df['date'])
                df = df[df['date'] >= '2024-01-01']
                return df

        # 2. HK Indices
        if code.startswith("hk"):
             try:
                 symbol_clean = code[2:]
                 df = ak.stock_hk_index_daily_sina(symbol=symbol_clean)
                 
                 # Append Spot
                 if df is not None and not df.empty:
                     df['date'] = pd.to_datetime(df['date'])
                     last_date = df['date'].iloc[-1].date()
                     today_date = datetime.now().date()
                     
                     if last_date < today_date:
                         try:
                             spot_df = ak.stock_hk_index_spot_em()
                             target_row = spot_df[spot_df['ä»£ç '] == symbol_clean]
                             if not target_row.empty:
                                 row = target_row.iloc[0]
                                 new_data = {
                                     'date': pd.to_datetime(today_date),
                                     'open': row['ä»Šå¼€'],
                                     'high': row['æœ€é«˜'],
                                     'low': row['æœ€ä½'],
                                     'close': row['æœ€æ–°ä»·'],
                                     'volume': row['æˆäº¤é‡']
                                 }
                                 df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
                         except Exception as e_spot:
                             print(f"Failed to fetch HK spot data for {code}: {e_spot}")
             except Exception as e: 
                 print(f"Error fetching HK history: {e}")


        # 3. US Indices
        elif code.startswith("us."):
             try:
                df = ak.stock_us_index_daily_sina(symbol=code)
             except: pass
        
        # 4. THS Concepts (Micro Cap)
        elif code.startswith("ths_"):
             try:
                 symbol = code.split("_")[1]
                 df = ak.stock_board_concept_index_ths(symbol=symbol, start_date="20240101")
                 if df is not None:
                     df = df.rename(columns={
                        'æ—¥æœŸ': 'date', 'å¼€ç›˜ä»·': 'open', 'æœ€é«˜ä»·': 'high', 'æœ€ä½ä»·': 'low', 
                        'æ”¶ç›˜ä»·': 'close', 'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'turnover'
                     })
             except: pass

        # 5. Specialized A-Share (CSI A500)
        elif code == "sh000510":
             try:
                 df = ak.stock_zh_index_daily_em(symbol="sh000510")
             except:
                 try:
                     df = ak.stock_zh_index_daily(symbol="sh000510")
                 except: pass

        # 6. Generic A-Share Indices (Default)
        else:
             # Try EM Daily first
             try:
                df = ak.stock_zh_index_daily_em(symbol=code)
             except Exception as e1:
                # Fallback to Sina Daily
                try:
                    df = ak.stock_zh_index_daily(symbol=code)
                except Exception as e2: 
                    pass
        
        # --- Common Logic: Append A-Share Spot if needed ---
        # Only applicable if code starts with sh/sz/bj or is numeric (generic A-share)
        is_ashare = code.startswith(('sh', 'sz', 'bj')) or code == 'sh000510'
        
        if df is not None and not df.empty and is_ashare:
             if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values(by='date')
                
                # Check freshness
                last_date = df['date'].iloc[-1].date()
                today_date = datetime.now().date()
                
                if last_date < today_date:
                    # Try to find spot data
                    spot_row = get_a_share_spot(code)
                    if spot_row is not None:
                        try:
                            # Sina Spot columns: ä»£ç ,åç§°,æœ€æ–°ä»·,æ¶¨è·Œé¢,æ¶¨è·Œå¹…,æ˜¨æ”¶,ä»Šå¼€,æœ€é«˜,æœ€ä½,æˆäº¤é‡,æˆäº¤é¢
                            new_data = {
                                'date': pd.to_datetime(today_date),
                                'open': float(spot_row['ä»Šå¼€']),
                                'high': float(spot_row['æœ€é«˜']),
                                'low': float(spot_row['æœ€ä½']),
                                'close': float(spot_row['æœ€æ–°ä»·']),
                                'volume': float(spot_row['æˆäº¤é‡'])
                            }
                            # Check strictly if price is valid (not 0)
                            if new_data['close'] > 0:
                                df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
                                # print(f"  Append Spot: {code} {new_data['close']}")
                        except Exception as e_append:
                            print(f"Error appending spot for {code}: {e_append}")

        if df is not None and not df.empty:
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values(by='date')
            
            # Ensure columns
            if 'close' not in df.columns and 'æ”¶ç›˜ä»·' in df.columns:
                 df = df.rename(columns={'æ”¶ç›˜ä»·': 'close', 'æ—¥æœŸ': 'date', 'æˆäº¤é‡': 'volume'})
            elif 'close' not in df.columns and 'æ”¶ç›˜' in df.columns:
                 df = df.rename(columns={'æ”¶ç›˜': 'close', 'æ—¥æœŸ': 'date', 'æˆäº¤é‡': 'volume'})

            # Numeric conversion
            df['close'] = pd.to_numeric(df['close'], errors='coerce')
            if 'volume' in df.columns:
                df['volume'] = pd.to_numeric(df['volume'], errors='coerce')
                
            return df

    except Exception as e:
        print(f"Error fetching {name} ({code}): {e}")
        return None
    return None

def get_fish_basin_analysis(symbols_map):
    results = []
    failed_items = list(symbols_map.items()) # Start with all
    max_retries = 2
    
    import time
    
    print(f"Starting Fish Basin Analysis for {len(symbols_map)} symbols...")
    
    for attempt in range(max_retries + 1):
        if not failed_items:
            break
            
        current_batch = failed_items
        failed_items = []
        
        if attempt > 0:
            print(f"\nğŸ”„ Retry Cycle {attempt}/{max_retries} for {len(current_batch)} items...")
            time.sleep(2)
            
        for name, code in current_batch:
            try:
                # print(f"Processing {name} ({code})...") 
                # (Silence normal logs on retries to reduce noise, or keep it?)
                
                # 1. Fetch
                df = fetch_data(name, code)
                
                if df is None or df.empty:
                    # Logic: If fetch failed, mark as failed
                    failed_items.append((name, code))
                    continue
                    
                close = df['close']
                
                # 2. Indicators
                # å¤§å“¥é»„çº¿: (MA14 + MA28 + MA57 + MA114) / 4
                df['MA14'] = close.rolling(window=14).mean()
                df['MA28'] = close.rolling(window=28).mean()
                df['MA57'] = close.rolling(window=57).mean()
                df['MA114'] = close.rolling(window=114).mean()
                df['å¤§å“¥é»„çº¿'] = (df['MA14'] + df['MA28'] + df['MA57'] + df['MA114']) / 4
                
                # è¶‹åŠ¿ç™½çº¿: EMA(EMA(C,10),10)
                ema10 = close.ewm(span=10, adjust=False).mean()
                df['è¶‹åŠ¿ç™½çº¿'] = ema10.ewm(span=10, adjust=False).mean()
                
                # Volume Ratio (Vol / MA5_Vol)
                if 'volume' in df.columns:
                    vol_ma5 = df['volume'].rolling(window=5).mean()
                    df['vol_ratio'] = df['volume'] / vol_ma5
                else:
                    df['vol_ratio'] = np.nan

                df_valid = df.dropna(subset=['å¤§å“¥é»„çº¿']).copy()
                if df_valid.empty: 
                    # Data too short?
                    print(f"âš ï¸ Data too short for {name}")
                    continue # Not a fetch fail, just data issue. Don't retry.
                
                last_row = df_valid.iloc[-1]
                current_date = last_row['date']
                current_price = last_row['close']
                dage_yellow_current = last_row['å¤§å“¥é»„çº¿']
                white_line_current = last_row['è¶‹åŠ¿ç™½çº¿']
                vol_ratio = last_row.get('vol_ratio', 0)
                
                # Status
                status_str = "YES" if current_price >= dage_yellow_current else "NO"
                
                # Deviation
                deviation = (current_price - dage_yellow_current) / dage_yellow_current
                
                # Signal Date (Backtrack for price crossing yellow line)
                price_arr = df['close'].values
                indicator_arr = df['å¤§å“¥é»„çº¿'].values
                white_arr = df['è¶‹åŠ¿ç™½çº¿'].values
                dates_arr = df['date'].values
                
                idx = len(df) - 1
                curr_state = (price_arr[idx] >= indicator_arr[idx])
                
                signal_idx = -1
                for i in range(idx - 1, 114, -1):  # å¤§å“¥é»„çº¿éœ€è¦114å¤©æ•°æ®
                    if pd.isna(indicator_arr[i]): break
                    state_i = (price_arr[i] >= indicator_arr[i])
                    if state_i != curr_state:
                        signal_idx = i + 1
                        break
                
                interval_change = 0.0
                change_date_str = "-"
                if signal_idx != -1:
                    # Safe date conversion
                    try:
                        ts = (dates_arr[signal_idx] - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')
                        change_date_str = datetime.utcfromtimestamp(ts).strftime("%y.%m.%d")
                    except: pass
                    base_price = price_arr[signal_idx]
                    interval_change = (current_price - base_price) / base_price

                # è®¡ç®—é‡‘å‰/æ­»å‰æŒç»­å¤©æ•° (ç™½çº¿vsé»„çº¿)
                golden_cross_days = 0 
                death_cross_days = 0
                
                current_is_golden = white_arr[idx] > indicator_arr[idx]
                
                for i in range(idx, 114, -1):
                    if pd.isna(white_arr[i]) or pd.isna(indicator_arr[i]): break
                    is_golden = white_arr[i] > indicator_arr[i]
                    if is_golden == current_is_golden:
                        if current_is_golden:
                            golden_cross_days += 1
                        else:
                            death_cross_days += 1
                    else:
                        break
                
                if current_is_golden:
                    death_cross_days = 0
                else:
                    golden_cross_days = 0

                # Daily Change
                prev_close = df.iloc[-2]['close'] if len(df) >= 2 else current_price
                daily_change = (current_price - prev_close) / prev_close
                
                # ç™½çº¿åç¦»ç‡
                white_deviation = (current_price - white_line_current) / white_line_current
                
                # Vol Ratio Format
                vr_str = f"{vol_ratio:.2f}" if pd.notna(vol_ratio) else "-"
                
                results.append({
                    "ä»£ç ": code,
                    "åç§°": name,
                    "çŠ¶æ€": status_str,
                    "æ¶¨å¹…%": f"{daily_change*100:+.2f}%",
                    "ç°ä»·": int(current_price) if current_price > 5 else f"{current_price:.2f}",
                    "é»„çº¿": int(dage_yellow_current),
                    "ç™½çº¿": int(white_line_current) if white_line_current > 5 else f"{white_line_current:.2f}",
                    "é»„çº¿åç¦»ç‡": f"{deviation*100:.2f}%",
                    "ç™½çº¿åç¦»ç‡": f"{white_deviation*100:.2f}%",
                    "é‡æ¯”": vr_str,
                    "é‡‘å‰å¤©æ•°": golden_cross_days if golden_cross_days > 0 else "-",
                    "æ­»å‰å¤©æ•°": death_cross_days if death_cross_days > 0 else "-",
                    "çŠ¶æ€å˜é‡æ—¶é—´": change_date_str,
                    "åŒºé—´æ¶¨å¹…%": f"{interval_change*100:.2f}%",
                    "_deviation_raw": deviation
                })
                
                print(f"âœ… {name} Done.")
                
            except Exception as e:
                print(f"âŒ Error processing {name}: {e}")
                failed_items.append((name, code))
            
    # --- Summary Section ---
    success_count = len(results)
    total_count = len(symbols_map)
    fail_count = len(failed_items)
    
    print("\n" + "="*40)
    print(f"ğŸ“Š è¶‹åŠ¿æ¨¡å‹(æŒ‡æ•°) æ‰§è¡Œæ±‡æ€»")
    print(f"âœ… æˆåŠŸ: {success_count}/{total_count}")
    print(f"âŒ å¤±è´¥: {fail_count}/{total_count}")
    
    if fail_count > 0:
        missing_names = [n for n, c in failed_items]
        print(f"âš ï¸ æœ€ç»ˆå¤±è´¥åˆ—è¡¨: {', '.join(missing_names)}")
    print("="*40 + "\n")

    # Sort results by deviation descending
    results.sort(key=lambda x: x.get('_deviation_raw', -999), reverse=True)
    
    return pd.DataFrame(results).drop(columns=['_deviation_raw'], errors='ignore')

# Export Default Targets for external use
DEFAULT_TARGETS = {
    "ç™½é“¶ç°è´§": "SI", # COMEX Silver
    "é»„é‡‘ç°è´§": "GC", # COMEX Gold
    "ä¸­è¯500": "sz399905",
    "ç§‘åˆ›50": "sh000688",
    # "ä¸­è¯2000": "sz932000", # EM Daily 932000 might fail, let's use proxy if found
    "ä¸­è¯2000": "sz399303", # CNI 2000 proxy
    "ä¸­è¯1000": "sz399852",
    "ä¸­è¯A500": "sh000510", # Use Sina source (tested)
    "å¾®ç›˜è‚¡": "ths_å¾®ç›˜è‚¡", # Use THS Concept
    "åŒ—è¯50": "bj899050",
    "åˆ›ä¸šæ¿æŒ‡": "sz399006",
    "æ’ç”Ÿç§‘æŠ€": "hkHSTECH",
    "æ’ç”ŸæŒ‡æ•°": "hkHSI",
    "æ²ªæ·±300": "sh000300",
    "ä¸Šè¯50": "sh000016",
    "æ ‡æ™®500": "us.INX",
    "çº³æŒ‡100": "us.IXIC",
    "ä¸Šè¯æŒ‡æ•°": "sh000001" 
}

def run(date_dir=None, save_excel=True):
    """
    Main entry point for Fish Basin Index Analysis.
    Returns the DataFrame.
    """
    print("\n=== é±¼ç›†è¶‹åŠ¿æ¨¡å‹v2.0 (Fish Basin Model) ===")
    print(f"Date: {datetime.now().strftime('%Y.%m.%d')}")
    
    df = get_fish_basin_analysis(DEFAULT_TARGETS)
    
    if not df.empty:
        curr_date = datetime.now().strftime('%Y%m%d')
        output_path = None
        
        # Calculate Rank Change (Logic preserved)
        df['æ’åå˜åŒ–'] = "-"
        try:
            from datetime import timedelta
            today = datetime.now()
            for days_back in range(1, 8):
                prev_date = (today - timedelta(days=days_back)).strftime('%Y%m%d')
                
                # Check Merged first, then Individual
                merged_prev = f"results/{prev_date}/è¶‹åŠ¿æ¨¡å‹_åˆå¹¶.xlsx"
                old_prev = f"results/{prev_date}/è¶‹åŠ¿æ¨¡å‹_æŒ‡æ•°.xlsx"
                prev_df = None
                
                if os.path.exists(merged_prev):
                    try: prev_df = pd.read_excel(merged_prev, sheet_name='æŒ‡æ•°')
                    except: pass
                
                if prev_df is None and os.path.exists(old_prev):
                    prev_df = pd.read_excel(old_prev)
                
                if prev_df is not None:
                    if 'åç§°' in prev_df.columns:
                        prev_rank = {name: idx+1 for idx, name in enumerate(prev_df['åç§°'].tolist())}
                        rank_changes = []
                        for idx, row in df.iterrows():
                            name = row['åç§°']
                            today_rank = idx + 1
                            if name in prev_rank:
                                change = prev_rank[name] - today_rank
                                if change > 0: rank_changes.append(f"+{change}")
                                elif change < 0: rank_changes.append(str(change))
                                else: rank_changes.append("-")
                            else: rank_changes.append("æ–°")
                        df['æ’åå˜åŒ–'] = rank_changes
                    break
        except Exception as e:
            print(f"æ’åå˜åŒ–è®¡ç®—å¤±è´¥: {e}")
              
        # Save Excel only if requested
        if save_excel:
            if date_dir:
                 output_path = os.path.join(date_dir, "è¶‹åŠ¿æ¨¡å‹_æŒ‡æ•°.xlsx")
            else:
                 output_path = f"results/{curr_date}/è¶‹åŠ¿æ¨¡å‹_æŒ‡æ•°.xlsx"
            save_to_excel(df, output_path)

        # Console Output (Preserved)
        RED = '\033[91m'
        GREEN = '\033[92m'
        RESET = '\033[0m'
        BOLD = '\033[1m'
        headers = ["ä»£ç ", "åç§°", "çŠ¶æ€", "æ¶¨å¹…%", "ç°ä»·", "é»„çº¿", "ç™½çº¿", "é»„çº¿åç¦»ç‡", "ç™½çº¿åç¦»ç‡", "é‡‘å‰å¤©æ•°", "æ­»å‰å¤©æ•°", "æ’åå˜åŒ–"]
        header_str = "  ".join([f"{h:<10}" for h in headers])
        print(f"{BOLD}{header_str}{RESET}")
        
        for _, row in df.iterrows():
            try:
                status = row['çŠ¶æ€']
                status_color = RED if status == 'YES' else GREEN
                chg_str = row['æ¶¨å¹…%']
                chg_val = float(chg_str.strip('%'))
                chg_color = RED if chg_val > 0 else GREEN
                dev_str = row['é»„çº¿åç¦»ç‡']
                dev_val = float(dev_str.strip('%'))
                dev_color = RED if dev_val > 0 else GREEN
                white_dev_str = row['ç™½çº¿åç¦»ç‡']
                white_dev_val = float(white_dev_str.strip('%'))
                white_dev_color = RED if white_dev_val > 0 else GREEN
                rank_change = str(row.get('æ’åå˜åŒ–', '-'))
                rank_color = RED if rank_change.startswith('+') else (GREEN if rank_change.startswith('-') and rank_change != '-' else RESET)
                
                line = [
                    f"{row['ä»£ç ']:<10}",
                    f"{row['åç§°']:<10}",
                    f"{status_color}{status:<10}{RESET}",
                    f"{chg_color}{chg_str:<10}{RESET}",
                    f"{str(row['ç°ä»·']):<10}",
                    f"{str(row['é»„çº¿']):<10}",
                    f"{str(row['ç™½çº¿']):<10}",
                    f"{dev_color}{dev_str:<10}{RESET}",
                    f"{white_dev_color}{white_dev_str:<10}{RESET}",
                    f"{str(row['é‡‘å‰å¤©æ•°']):<10}",
                    f"{str(row['æ­»å‰å¤©æ•°']):<10}",
                    f"{rank_color}{rank_change:<6}{RESET}"
                ]
                print("  ".join(line))
            except: pass
            
        return df
    else:
        print("No data generated.")
        return pd.DataFrame()

if __name__ == "__main__":
    run()
