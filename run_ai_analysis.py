"""
å…¨å¸‚åœºé€‰è‚¡ + AIæ™ºèƒ½åˆ†æç”ŸæˆæŠ¥å‘Š
1. 300å¹¶å‘å…¨å¸‚åœºé€‰è‚¡ï¼ˆå¸‚å€¼100äº¿+ï¼Œæ’é™¤STï¼‰
2. æ¥å…¥Geminiåˆ†æTop10å€¼åšç‡
3. ç”Ÿæˆæ¨èåŸå› MDæ–‡æ¡£
4. ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼ˆè„±æ•å¤„ç†ï¼‰
"""
import sys
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import requests
import base64
import time
import numpy as np
# from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
# load_dotenv()

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# from data_fetcher import get_all_stock_list, get_stock_data
# from signals import check_stock_signal
# from tqdm import tqdm
# import pandas as pd

# é…ç½®
MAX_WORKERS = 400
MIN_MARKET_CAP = 100  # å¸‚å€¼100äº¿ä»¥ä¸Š


class NumpyEncoder(json.JSONEncoder):
    """å¤„ç†numpyç±»å‹çš„JSONç¼–ç å™¨"""
    def default(self, obj):
        if isinstance(obj, (np.integer, np.int64)):
            return int(obj)
        if isinstance(obj, (np.floating, np.float64)):
            return float(obj)
        if isinstance(obj, np.bool_):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)


def process_single_stock(args):
    """å¤„ç†å•åªè‚¡ç¥¨"""
    code, name, market_cap, industry = args
    try:
        df = get_stock_data(code, 300)
        if df is None or len(df) < 120:
            return None
        
        result = check_stock_signal(df, code)
        
        # è·å–æœ€åä¸€è¡ŒåŸå§‹æ•°æ®
        last_row = df.iloc[-1].to_dict()
        last_row['date'] = str(last_row['date'])[:10]
        
        return {
            'code': code,
            'name': name,
            'market_cap': float(market_cap),
            'industry': industry if str(industry).lower() != 'nan' else None,  # é¢˜æ/è¡Œä¸š
            'signal': bool(result.get('signal', False)),
            'signals': result.get('signals', []),
            'K': float(result.get('K', 0)),
            'D': float(result.get('D', 0)),
            'J': float(result.get('J', 0)),
            'RSI': float(result.get('RSI', 0)),
            'near_amplitude': float(result.get('è¿‘æœŸæŒ¯å¹…', 0)),
            'far_amplitude': float(result.get('è¿œæœŸæŒ¯å¹…', 0)),
            'raw_data': last_row
        }
    except Exception as e:
        return None


def run_full_selection():
    """å…¨å¸‚åœºé€‰è‚¡"""
    today_date = datetime.now().strftime('%Y%m%d')
    date_dir = os.path.join("results", today_date)
    os.makedirs(date_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šæ—¥ç»“æœ
    import glob
    existing_files = glob.glob(os.path.join(date_dir, f"selected_{today_date}_*.json"))
    if existing_files:
        latest_file = max(existing_files, key=os.path.getctime)
        print(f"âš¡ å‘ç°ä»Šæ—¥å·²æœ‰é€‰è‚¡ç»“æœ: {latest_file}")
        with open(latest_file, 'r', encoding='utf-8') as f:
            selected = json.load(f)
        # ä»æ–‡ä»¶åæå–å®Œæ•´æ—¶é—´æˆ³ (selected_YYYYMMDD_HHMMSS.json)
        filename = os.path.basename(latest_file)
        # filenameæ ¼å¼: selected_20260118_004725.json
        # å»æ‰å‰ç¼€ selected_ (9 chars) å’Œåç¼€ .json (5 chars)
        timestamp = filename[9:-5] 
        return selected, timestamp

    print("=" * 70)
    print("  ä¸œæ–¹è´¢å¯Œ - çŸ¥è¡ŒB1é€‰è‚¡ç­–ç•¥ (AIæ™ºèƒ½åˆ†æç‰ˆ)")
    print(f"  å¸‚å€¼ >= {MIN_MARKET_CAP}äº¿ | æ’é™¤ST | å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")
    print(f"  æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    print("\n[1/4] è·å–è‚¡ç¥¨åˆ—è¡¨...")
    stock_list = get_all_stock_list(min_market_cap=MIN_MARKET_CAP, exclude_st=True)
    
    # æ³¨é‡Šï¼šç§»é™¤500åªè‚¡ç¥¨é™åˆ¶ï¼Œåˆ†æå…¨éƒ¨è‚¡ç¥¨
    # stock_list = stock_list.head(500)
    print(f"âš ï¸ å°†åˆ†æå…¨éƒ¨ {len(stock_list)} åªè‚¡ç¥¨")
    
    if len(stock_list) == 0:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return [], ""
    
    args_list = [
        (row['code'], row['name'], row['market_cap'], row.get('industry', '')) 
        for _, row in stock_list.iterrows()
    ]
    
    print(f"\n[2/4] å¹¶å‘åˆ†æ {len(args_list)} åªè‚¡ç¥¨çš„ä¿¡å·...")
    
    selected = []
    all_results = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_stock, args): args[0] for args in args_list}
        
        for future in tqdm(as_completed(futures), total=len(futures), desc="é€‰è‚¡è¿›åº¦"):
            result = future.result()
            if result is not None:
                all_results.append(result)
                if result['signal']:
                    selected.append(result)
    
    # ä¿å­˜ç»“æœ
    today_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜æ‰€æœ‰åŸå§‹æ•°æ®
    raw_file = os.path.join(date_dir, f"all_stocks_{today_timestamp}.jsonl")
    with open(raw_file, 'w', encoding='utf-8') as f:
        for item in all_results:
            f.write(json.dumps(item, cls=NumpyEncoder, ensure_ascii=False) + '\n')
    
    print(f"\nğŸ“ åŸå§‹æ•°æ®: {raw_file} ({len(all_results)} æ¡)")
    
    # ä¿å­˜é€‰è‚¡ç»“æœ
    selected_file = os.path.join(date_dir, f"selected_{today_timestamp}.json")
    with open(selected_file, 'w', encoding='utf-8') as f:
        json.dump(selected, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
            
    print(f"ğŸ“ é€‰è‚¡ç»“æœ: {selected_file} ({len(selected)} åª)")
    
    return selected, today_timestamp


def save_stock_summary(selected_stocks, date_dir, timestamp):
    """ä¿å­˜ä¾¿äºç§ä¿¡å‘é€çš„æ–‡æœ¬æ±‡æ€»"""
    summary_file = os.path.join(date_dir, f"stock_list_summary_{timestamp}.txt")
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(f"ğŸ“… é€‰è‚¡æ±‡æ€» {datetime.now().strftime('%Y-%m-%d')}\n")
        f.write(f"ç­–ç•¥: AIå¤§æ¨¡å‹é‡åŒ–\n")
        f.write("-" * 30 + "\n\n")
        
        for idx, stock in enumerate(selected_stocks, 1):
            code = stock['code']
            name = stock['name']
            industry = stock.get('industry', 'æœªçŸ¥è¡Œä¸š')
            # å°è¯•è·å–æ”¶ç›˜ä»·ï¼Œå¦‚æœåœ¨æ•°æ®é‡Œçš„è¯
            # å‡è®¾stock dicté‡Œå¯èƒ½æœ‰'price'æˆ–è€…'close'ï¼Œå¦‚æœæ²¡æœ‰å°±ä¸æ˜¾ç¤º
            
            f.write(f"{idx}. {name} ({code})\n")
            if industry and str(industry).lower() != 'nan':
                f.write(f"   è¡Œä¸š: {industry}\n")
            # è·å–ä¿¡å·åˆ—è¡¨
            stock_signals = stock.get('signals', [])
            
            if stock_signals:
                # ç»Ÿä¸€æœ¯è¯­
                sanitized_signals = [
                    s.replace('B1', 'ä¹°ç‚¹')
                     .replace('B', 'ä¹°ç‚¹')
                     .replace('åŸå§‹', 'æ ‡å‡†')
                    for s in stock_signals
                ]
                f.write(f"   å‘½ä¸­è§„åˆ™: {'+'.join(sanitized_signals)}\n")
            
            f.write("\n")
            
        f.write("-" * 30 + "\n")
        f.write("æ³¨ï¼šæ¬¡æ—¥å…³æ³¨è¿›åœºï¼ŒéæŠ•èµ„å»ºè®®ã€‚\n")
        f.write("æ›´å¤šè¯¦æƒ…è¯·çœ‹æ–‡æ¡ˆåˆ†æã€‚\n")

    print(f"ğŸ“ ç§ä¿¡æ±‡æ€»åˆ—è¡¨: {summary_file}")
    return summary_file

# æ³¨é‡Šï¼šsave_stock_summary åŠŸèƒ½å·²ç§»è‡³ agent_outputs/result_analysis.txt
# æ­¤å‡½æ•°ä¿ç•™ä½†ä¸å†è°ƒç”¨

# ================ è„±æ•å·¥å…·å‡½æ•° ================

def desensitize_stock_name(name):
    """è‚¡ç¥¨åç§°è„±æ•ï¼šä¿ç•™å‰2å­—ï¼Œåé¢æ”¹ä¸ºæ‹¼éŸ³é¦–å­—æ¯å¤§å†™"""
    if len(name) <= 2:
        return name
    
    try:
        from pypinyin import lazy_pinyin, Style
        # è·å–åç¼€çš„æ‹¼éŸ³é¦–å­—æ¯
        suffix = name[2:]
        pinyin_initials = lazy_pinyin(suffix, style=Style.FIRST_LETTER)
        # è½¬å¤§å†™å¹¶æ‹¼æ¥
        initials = ''.join([p.upper() for p in pinyin_initials])
        return name[:2] + initials
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… pypinyinï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘
        print("Warning: pypinyin not installed. Using simplified desensitization.")
        suffix = name[2:]
        # å–åç¼€å‰ä¸¤ä¸ªå­—ç¬¦ä½œä¸ºæ ‡è¯†
        return name[:2] + (suffix[:2].upper() if len(suffix) >= 2 else suffix.upper())

def desensitize_stock_code(code):
    """è‚¡ç¥¨ä»£ç è„±æ•ï¼šå‰4ä½ä¿ç•™ï¼Œå2ä½æ”¹ä¸º**"""
    if len(code) < 6:
        return code
    return code[:4] + '**'



def call_gemini_analysis(selected_stocks, date_dir):
    """ä½¿ç”¨Agentåˆ†æTop10å€¼åšç‡"""
    # å‡†å¤‡åˆ†ææ•°æ®
    stocks_info = []
    for s in selected_stocks:
        raw = s['raw_data']
        stocks_info.append({
            'ä»£ç ': s['code'],
            'åç§°': s['name'],
            'æ€»å¸‚å€¼(äº¿å…ƒ)': round(s['market_cap'], 0),
            'ä¿¡å·ç±»å‹': ', '.join(s['signals']),
            'K': round(s['K'], 1),
            'D': round(s['D'], 1),
            'J': round(s['J'], 1),
            'RSI': round(s['RSI'], 1),
            'è¿‘æœŸæŒ¯å¹…%': round(s['near_amplitude'], 1),
            'è¿œæœŸæŒ¯å¹…%': round(s['far_amplitude'], 1),
            'æ”¶ç›˜ä»·': raw['close'],
            'æˆäº¤é‡': raw['volume']
        })
    
    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±é‡åŒ–åˆ†æå¸ˆã€‚ä»¥ä¸‹æ˜¯é€šè¿‡"AIæ¨¡å‹"ç­–ç•¥é€‰å‡ºçš„è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯¥ç­–ç•¥ä¸»è¦æ•æ‰è¶…å–åå¼¹å’Œå›è¸©æ”¯æ’‘çš„ä¹°å…¥ä¿¡å·ã€‚

é€‰å‡ºçš„è‚¡ç¥¨æ•°æ®ï¼š
{json.dumps(stocks_info, ensure_ascii=False, indent=2, cls=NumpyEncoder)}

è¯·ä»ä¸­é€‰å‡ºToday Top10å€¼å¾—å…³æ³¨çš„è‚¡ç¥¨ï¼Œè¯„ä¼°æ ‡å‡†ï¼š
1. ä¿¡å·å¼ºåº¦ï¼ˆå¤šä¿¡å·å åŠ æ›´ä½³ï¼‰
2. æŠ€æœ¯æŒ‡æ ‡ä½ç½®ï¼ˆKDJ/RSIè¶…å–ç¨‹åº¦ï¼‰
3. **ã€é€‰è‚¡åå¥½ã€‘å°½é‡ä¸é€‰688å¼€å¤´çš„ç§‘åˆ›æ¿è‚¡ç¥¨**ï¼Œé™¤éå…¶ä»–æ ‡çš„è´¨é‡æ˜æ˜¾ä¸è¶³ã€‚
4. **ã€é¢˜æåˆ†å¸ƒã€‘é¢˜æå°½é‡åˆ†æ•£ï¼Œä¸è¦æ‰å †**ï¼æ¯ç±»ç»†åˆ†é¢˜æ/è¡Œä¸šå…¥é€‰è‚¡ç¥¨ä¸è¶…è¿‡2åªã€‚
5. **ã€é‡è¦ã€‘æ‰€å±è¡Œä¸š/é¢˜æ**ï¼ˆç”±äºæ•°æ®æºç¼ºå¤±ï¼Œè¯·ä½ æ ¹æ®è‚¡ç¥¨ä»£ç å’Œåç§°ï¼Œåˆ©ç”¨ä½ çš„çŸ¥è¯†åº“è¡¥å……å…¶æ‰€å±çš„è¡Œä¸šå’Œæ ¸å¿ƒé¢˜æï¼‰

è¯·è¾“å‡ºï¼š
1. Top10è‚¡ç¥¨æ’å
   - æ ¼å¼ï¼š`[è‚¡ç¥¨åç§°] ([ä»£ç ]) | [è¡Œä¸š/é¢˜æ] | [æ¨èç†ç”±]`
   - ç†ç”±è¦æ±‚ï¼š3-5å¥è¯ï¼Œç»“åˆæŠ€æœ¯é¢ä¸åŸºæœ¬é¢é¢˜æã€‚
2. æ•´ä½“å¸‚åœºåˆ†æï¼ˆ2-3å¥è¯ï¼‰
3. é£é™©æç¤º

æ³¨æ„ï¼šè¿™æ˜¯æŠ€æœ¯åˆ†æå‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚é¢˜æä¿¡æ¯è¯·åŠ¡å¿…å‡†ç¡®ã€‚"""

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_analysis.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"\n[4/4] ä»»åŠ¡å·²ä¿å­˜ï¼Œç­‰å¾…Agentåˆ†æTop10...")
    print(f"ğŸ“ ä»»åŠ¡æ–‡ä»¶: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_analysis.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            result = f.read()
        print("âœ… Agentåˆ†æå®Œæˆ")
        
        # --- æå–å¹¶ä¿å­˜ Top 10 ---
        import re
        top_codes = re.findall(r'\((\d{6})\)', result)
        seen = set()
        unique_codes = []
        for c in top_codes:
            if c not in seen:
                unique_codes.append(c)
                seen.add(c)
        unique_codes = unique_codes[:10]
        
        stock_map = {s['code']: s for s in selected_stocks}
        top_stocks = []
        for c in unique_codes:
            if c in stock_map:
                top_stocks.append(stock_map[c])
        
        top10_file = os.path.join(date_dir, "selected_top10.json")
        with open(top10_file, 'w', encoding='utf-8') as f:
            json.dump(top_stocks, f, cls=NumpyEncoder, ensure_ascii=False, indent=2)
        print(f"ğŸ“ å·²ç”Ÿæˆä¸­é—´æ–‡ä»¶: {top10_file} ({len(top_stocks)}åª)")
        
        return result, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        print("æç¤ºï¼šè¯·è¿è¡Œ Agent å·¥ä½œæµæ¥å¤„ç†åˆ†æä»»åŠ¡")
        return None, prompt


def generate_xiaohongshu_post(gemini_analysis, selected_stocks, date_dir):
    """ä½¿ç”¨Agentç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼ˆè„±æ•å¤„ç†ï¼‰"""
    # å‡†å¤‡è„±æ•åçš„è‚¡ç¥¨åˆ—è¡¨
    masked_stocks = []
    for s in selected_stocks:
        masked_stocks.append({
            'name': s['name'],
            'name_masked': desensitize_stock_name(s['name']),
            'code': s['code'],
            'code_masked': desensitize_stock_code(s['code']),
            'industry': s.get('industry', ''),
        })
    
    # å‡†å¤‡è„±æ•è¯´æ˜
    prompt = f"""è¯·å°†ä»¥ä¸‹è‚¡ç¥¨åˆ†ææŠ¥å‘Šæ”¹å†™æˆå°çº¢ä¹¦é£æ ¼çš„æ–‡æ¡ˆã€‚

åŸå§‹åˆ†æï¼š
{gemini_analysis}

ã€è„±æ•è‚¡ç¥¨åˆ—è¡¨ã€‘ï¼ˆä½¿ç”¨æ­¤åˆ—è¡¨ä¸­çš„è„±æ•åç§°å’Œä»£ç ï¼‰ï¼š
{json.dumps(masked_stocks, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. **é£æ ¼çµé­‚**ï¼šå¿…é¡»æåº¦"å°çº¢ä¹¦åŒ–"ï¼å¤§é‡ä½¿ç”¨Emojiï¼Œæ®µè½çŸ­ä¿ƒï¼Œè¯­æ°”å…´å¥‹ã€ä¸“ä¸šä¸”ç¡¬æ ¸ã€‚
2. **Emojiä½¿ç”¨è§„èŒƒ**ï¼š
   - æ ‡é¢˜å‰åå¿…é¡»åŠ Emoji (e.g., ğŸš€/ğŸ”¥/ğŸ’°).
   - æ¯ä¸€æ®µå¼€å¤´å¿…é¡»åŠ Emoji.
   - é‡ç‚¹è¯æ±‡å‰ååŠ Emoji.
   - æ¨èä½¿ç”¨ï¼šğŸš€ (æ½œåŠ›), ğŸ’° (ä¹°ç‚¹), ğŸ“‰ (è¶…å–), ğŸ¯ (ç›®æ ‡), âš ï¸ (é£é™©), ğŸ¤– (AIåˆ†æ).
3. **ã€é‡è¦ã€‘è‚¡ç¥¨è„±æ•å¤„ç†**ï¼š
   - ç›´æ¥ä½¿ç”¨ä¸Šé¢åˆ—è¡¨ä¸­çš„ name_masked å’Œ code_masked å­—æ®µ
   - ç¤ºä¾‹æ ¼å¼ï¼šåç››LD (6883**)
4. **æ ‡é¢˜**ï¼šå¸å¼•çœ¼çƒï¼Œä¸¥æ ¼æ§åˆ¶åœ¨20ä¸ªå­—ç¬¦ä»¥å†…ã€‚
5. **ç»“æ„è¦æ±‚**ï¼š
   - **æ ‡é¢˜è¡Œ**ï¼šæ—¥æœŸ + æ ¸å¿ƒä¸»é¢˜ + Emoji
   - **å¼€å¤´**ï¼šå„ä½äº¤æ˜“å‘˜ï¼ŒAIé‡åŒ–ä»Šæ—¥æ‰«æå…¨åœºï¼ ({datetime.now().strftime('%Y-%m-%d')})
   - **ä¸­é—´ï¼ˆæ ¸å¿ƒéƒ¨åˆ†ï¼‰**ï¼šåˆ—å‡ºTop10è‚¡ç¥¨ã€‚**å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ2è¡Œæ ¼å¼**ï¼Œæ¯åªè‚¡ç¥¨å 2è¡Œï¼š
     
     1ï¸âƒ£ [è‚¡ç¥¨åè„±æ•] ([ä»£ç è„±æ•]) | ğŸ·ï¸[è¡Œä¸š]
     ğŸ‘‰ [æ ¸å¿ƒç†ç”±ç®€è¿°ï¼Œ30å­—ä»¥å†…ï¼Œé‡ç‚¹å†™æŠ€æœ¯é¢ä¼˜åŠ¿]

     2ï¸âƒ£ ... (ä»¥æ­¤ç±»æ¨)
   
   - **ç»“å°¾**ï¼šé£é™©æç¤º + äº’åŠ¨ + å…³æ³¨å¼•å¯¼ã€‚
6. **æœ¯è¯­æ›¿æ¢**ï¼šå°† "B" æˆ– "B1" æ›¿æ¢ä¸º "ä¹°ç‚¹"ã€‚
7. **å­—æ•°é™åˆ¶**ï¼šå…¨æ–‡å­—æ•°å¿…é¡»ä¸¥æ ¼æ§åˆ¶åœ¨ **1000å­—ä»¥å†…**ã€‚ç²¾ç®€æ ¸å¿ƒç†ç”±ï¼Œå»é™¤å†—ä½™ä¿®é¥°ã€‚
7. **ç¦è¯**ï¼šç»å¯¹ä¸è¦å‡ºç° "çŸ¥è¡Œ"ã€"ä¸œæ–¹è´¢å¯Œ" ç­‰å…·ä½“ç­–ç•¥æˆ–æ¥æºåç§°ã€‚
7. **äººè®¾**ï¼šAIé‡åŒ–åˆ†æå¸ˆï¼ˆæœºå™¨äººè¯­æ°”ï¼Œä½†ç”ŸåŠ¨ï¼‰ã€‚
8. **ä¸¥ç¦Markdown**ï¼šä¸è¦ç”¨ `**`, `###`, `- ` ç­‰Markdownç¬¦å·ã€‚åªç”¨Emojiå’Œç©ºè¡Œåˆ†æ®µã€‚
9. **æ–‡æœ«è¯é¢˜**ï¼š#AIé€‰è‚¡ #é‡åŒ–äº¤æ˜“ #Aè‚¡ #æ¯æ—¥å¤ç›˜
10. **å­—æ•°**ï¼š1000å­—ä»¥å†…ã€‚
11. **ç§°å‘¼**ï¼šç»Ÿç§°è¯»è€…ä¸º"å„ä½äº¤æ˜“å‘˜" (Traders)ï¼Œä¸¥ç¦ä½¿ç”¨"å®¶äººä»¬"ã€"é›†ç¾ä»¬"ç­‰å°çº¢ä¹¦å¸¸è§ç§°å‘¼ã€‚
12. **å¿…é¡»åŒ…å«**ï¼š"æ¬¡æ—¥å…³æ³¨è¿›åœº" çš„æç¤ºã€‚

è¯·ç›´æ¥è¾“å‡ºæ–‡æ¡ˆå†…å®¹ã€‚"""

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_xiaohongshu.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"ğŸ“ å°çº¢ä¹¦ä»»åŠ¡å·²ä¿å­˜: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_xiaohongshu.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            result = f.read()
        print("âœ… å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
        return result, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        return None, prompt


def generate_image_prompt(gemini_analysis, selected_stocks, date_dir):
    """ä½¿ç”¨Agentç”Ÿæˆä¿¡æ¯å›¾æç¤ºè¯"""
    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    if len(selected_stocks) > 10:
        print(f"âš ï¸ è­¦å‘Š: ä¼ å…¥å›¾ç‰‡ç”Ÿæˆçš„è‚¡ç¥¨æ•°é‡ä¸º {len(selected_stocks)}ï¼Œé¢„æœŸä¸º10ã€‚")
        # å°è¯•ä½¿ç”¨å‰10ä¸ª
        selected_stocks = selected_stocks[:10]

    # å‡†å¤‡è‚¡ç¥¨æ•°æ®æ‘˜è¦(åŒ…å«æŠ€æœ¯æŒ‡æ ‡ + è„±æ•ä¿¡æ¯)
    stock_summary = []
    for s in selected_stocks:
        stock_summary.append({
            'name': s['name'],
            'name_masked': s.get('name_masked', desensitize_stock_name(s['name'])),  # ä¼˜å…ˆä½¿ç”¨å·²æœ‰è„±æ•å
            'code': s['code'],
            'code_masked': s.get('code_masked', desensitize_stock_code(s['code'])),  # ä¼˜å…ˆä½¿ç”¨å·²æœ‰è„±æ•ä»£ç 
            'industry': s.get('industry', 'æœªçŸ¥'),
            'signals': ','.join(s.get('signals', [])).replace('B1','æ ‡å‡†ä¹°ç‚¹').replace('B','æ ‡å‡†ä¹°ç‚¹').replace('åŸå§‹ä¹°ç‚¹','æ ‡å‡†ä¹°ç‚¹'),
            'J': round(s.get('J', 0), 2),
            'RSI': round(s.get('RSI', 0), 2),
        })
    
    # ä»å°çº¢ä¹¦æ–‡æ¡ˆæå–æ¬¡æ—¥ç­–ç•¥
    # ä»åˆ†æç»“æœæå– "æ•´ä½“å¸‚åœºå¤ç›˜" å’Œ "æ¬¡æ—¥äº¤æ˜“ç­–ç•¥"
    import re
    
    # æå– æ•´ä½“å¤ç›˜
    # æ¨¡å¼: "æ•´ä½“å¸‚åœºå¤ç›˜" -> (ç›´åˆ° "æ¬¡æ—¥äº¤æ˜“ç­–ç•¥")
    market_review = "æ— å¤ç›˜å†…å®¹"
    match_review = re.search(r'æ•´ä½“å¸‚åœºå¤ç›˜\s+(.+?)(?=\n\s*æ¬¡æ—¥äº¤æ˜“ç­–ç•¥|$)', gemini_analysis, re.DOTALL)
    if match_review:
        market_review = match_review.group(1).strip()
        
    # æå– æ¬¡æ—¥äº¤æ˜“ç­–ç•¥
    # æ¨¡å¼: "æ¬¡æ—¥äº¤æ˜“ç­–ç•¥" -> (ç›´åˆ° "é£é™©æç¤º" æˆ– ç»“æŸ)
    tomorrow_strategy = ""
    match_strategy = re.search(r'æ¬¡æ—¥äº¤æ˜“ç­–ç•¥\s+(.+?)(?=\n\s*é£é™©æç¤º|$)', gemini_analysis, re.DOTALL)
    if match_strategy:
        tomorrow_strategy = match_strategy.group(1).strip()

    # --- å¯¹å¤ç›˜å’Œç­–ç•¥æ–‡æ¡ˆè¿›è¡Œè„±æ•æ›¿æ¢ ---
    # éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œå°†æ–‡æ¡ˆä¸­çš„"å…¨å"æ›¿æ¢ä¸º"è„±æ•å"
    # æŒ‰åç§°é•¿åº¦é™åºæ’åˆ—ï¼Œé¿å…çŸ­åè¯¯ä¼¤é•¿å (e.g. "ä¸­èˆª" vs "ä¸­èˆªå…‰ç”µ")
    sorted_stocks = sorted(selected_stocks, key=lambda x: len(x['name']), reverse=True)
    
    for s in sorted_stocks:
        name = s['name']
        name_masked = s.get('name_masked', desensitize_stock_name(name))
        code = s['code']
        code_masked = s.get('code_masked', desensitize_stock_code(code))
        
        # æ›¿æ¢åç§°
        if name in market_review:
            market_review = market_review.replace(name, name_masked)
        if name in tomorrow_strategy:
            tomorrow_strategy = tomorrow_strategy.replace(name, name_masked)
        
        # æ›¿æ¢ä»£ç  (å¦‚æœæœ‰çš„è¯)
        if code in market_review:
            market_review = market_review.replace(code, code_masked)
        if code in tomorrow_strategy:
            tomorrow_strategy = tomorrow_strategy.replace(code, code_masked)

    
    # æ„å»ºåŠ¨æ€ Footer å†…å®¹
    footer_content = ""
    if market_review and market_review != "æ— å¤ç›˜å†…å®¹":
        footer_content += f"ğŸ“ æ•´ä½“å¤ç›˜\n{market_review}\n\n"
    
    if tomorrow_strategy:
        footer_content += f"ğŸ’¡ æ¬¡æ—¥ç­–ç•¥\n{tomorrow_strategy}"

    prompt = f"""(masterpiece, best quality), (vertical:1.2), (aspect ratio: 10:16), (sketch style), (hand drawn), (infographic)

Create a TALL VERTICAL PORTRAIT IMAGE (Aspect Ratio 10:16) HAND-DRAWN SKETCH style stock market infographic poster.

**CRITICAL: VERTICAL PORTRAIT FORMAT (10:16)**
- The image MUST be significantly taller than it is wide (Phone wallpaper style).
- Aspect Ratio: 10:16.
- Canvas Size: 1600x2560.

**CRITICAL: HAND-DRAWN AESTHETIC**
- Use ONLY pencil sketch lines, charcoal shading, ink pen strokes
- Visible paper grain texture throughout
- Line wobbles and imperfections (authentic hand-drawn feel)
- NO digital smoothness, NO vector graphics
- Shading: crosshatching, stippling, charcoal smudges only
- Background: Hand-drawn red-gold gradient with visible pencil strokes


Left: Robot mascot wearing red scarf, holding gear + rocket, thumbs-up, hand-sketched
Right: Speech bubble: "å…ˆè¿›åˆ¶é€ +å†›å·¥+æ–°èƒ½æºä¸‰å¤§ä¸»çº¿é½å‘åŠ›ï¼KDJè¶…å–åŒºé—´ çŸ­æœŸä¿®å¤çª—å£å·²å¼€å¯ğŸ’°"
Center: "AIå¤§æ¨¡å‹é‡åŒ–ç­–ç•¥" + "{datetime.now().strftime('%Y-%m-%d')}"

10 stock cards (5 per column) in a 2-Column Grid:
Left column: Pale blue background with paper texture
Right column: Pale yellow background with paper texture

**DESENSITIZATION RULES:**
All cards must use masked names and codes.

**CONTENT TO RENDER:**
{json.dumps(stock_summary, ensure_ascii=False, indent=2, cls=NumpyEncoder)}

For each stock, create card with:
Line 1: #[index] [name_masked] | [code_masked]
Line 2: [industry_icon] [industry]
Line 3: [signal_icon] [signals] | J=[J] RSI=[RSI]

Industry icons: ğŸ”‹ batteries, âœˆï¸ aerospace, ğŸ”Œ electronics, ğŸ¤– robotics, ğŸš— automotive, ğŸ­ machinery, ğŸ“¦ logistics
Signal icons: Use ONE of ğŸš€ OR ğŸ”¥ OR ğŸ“ˆ


{footer_content}


**ENHANCED HAND-DRAWN STYLE:**
1. Paper texture visible throughout (sketch paper grain)
2. All lines with wobbles, varying thickness
3. Shading only via crosshatching/stippling - NO smooth gradients  
4. Hand-lettered text with irregularities
5. Background: Red-gold gradient with visible pencil strokes
6. Card borders: Hand-drawn rounded rectangles
7. Overall: Professional architect sketch, NOT polished digital

TECHNICAL:
- Aspect ratio: 10:16 (Vertical Phone Wallpaper)
- Resolution: 1600x2560 (2K Vertical)
- Chinese text must be clear and readable
"""

    # ä¿å­˜ä»»åŠ¡åˆ°æ–‡ä»¶ä¾›Agentå¤„ç†
    agent_task_dir = os.path.join(date_dir, "agent_tasks")
    os.makedirs(agent_task_dir, exist_ok=True)
    
    task_file = os.path.join(agent_task_dir, "task_image_prompt.txt")
    with open(task_file, 'w', encoding='utf-8') as f:
        f.write(prompt)
    
    print(f"ğŸ“ å›¾ç‰‡ç”Ÿæˆä»»åŠ¡å·²ä¿å­˜: {task_file}")
    
    # è¯»å–Agentç”Ÿæˆçš„ç»“æœ
    agent_output_dir = os.path.join(date_dir, "agent_outputs")
    output_file = os.path.join(agent_output_dir, "result_image_prompt.txt")
    
    if os.path.exists(output_file):
        with open(output_file, 'r', encoding='utf-8') as f:
            final_prompt = f.read()
        final_prompt += "\n\n(Note: This prompt is optimized for the 'Nano Banana Pro3' model. Please ensure all details are consistent with high-quality hand-drawn vector art.)"
        print("âœ… å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ")
        return final_prompt, prompt
    else:
        print(f"âš ï¸  ç­‰å¾…Agentç”Ÿæˆç»“æœ: {output_file}")
        return None, prompt


def save_reports(gemini_analysis, xiaohongshu_post, today):
    """ä¿å­˜æŠ¥å‘Šï¼ˆç®€åŒ–ç‰ˆ - ä»…ä¿å­˜åˆ°agent_outputsï¼‰"""
    # æ³¨é‡Šï¼šå¤–å±‚é‡å¤æ–‡ä»¶å·²ç§»é™¤ï¼Œæ‰€æœ‰ç»“æœé›†ä¸­åœ¨ agent_outputs/
    # æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œactual saving done in agent workflow
    date_str = today.split('_')[0]
    date_dir = os.path.join("results", date_str)
    
    print(f"ï¿½ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {date_dir}/agent_outputs/")
    print(f"   - result_analysis.txt")
    print(f"   - result_xiaohongshu.txt")
    print(f"   - result_image_prompt.txt")
    
    return None, None


def save_prompts(prompts_dict, today):
    """ä¿å­˜æç¤ºè¯è®°å½•ï¼ˆå¯é€‰ - ç”¨äºè°ƒè¯•ï¼‰"""
    # æ³¨é‡Šï¼šæ­¤åŠŸèƒ½å¯é€‰ï¼Œæç¤ºè¯å·²åœ¨ agent_tasks/ ä¸­ä¿å­˜
    # ä¿ç•™æ­¤å‡½æ•°ç”¨äºè°ƒè¯•ç›®çš„
def enrich_stocks_from_analysis(selected_stocks, date_dir):
    """ä»åˆ†ææŠ¥å‘Šå›å¡«è¡Œä¸š/é¢˜æ"""
    try:
        print("ğŸ”„ æ­£åœ¨ä»åˆ†ææŠ¥å‘Šå›å¡« [è¡Œä¸š] å’Œ [è„±æ•ä¿¡æ¯]...")
        analysis_file = os.path.join(date_dir, "agent_outputs", "result_analysis.txt")
        if os.path.exists(analysis_file):
            import re
            with open(analysis_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£ææ¨¡å¼: 1. ä¸­èˆªå…‰ç”µ (002179) | å†›å·¥ç”µå­/é«˜ç«¯è¿æ¥å™¨ | ...
            # å…¼å®¹æ ¼å¼: åºå·. åç§° (ä»£ç ) | è¡Œä¸š | ...
            pattern = re.compile(r'\d+\.\s*(.+?)\s*\((\d{6})\)\s*\|\s*(.+?)\s*\|')
            
            # æ„å»ºæ˜ å°„è¡¨ code -> industry
            industry_map = {}
            matches = pattern.findall(content)
            for name, code, ind in matches:
                industry_map[code] = ind.strip()
                # print(f"  - è¯†åˆ«åˆ°: {code} -> {ind.strip()}")

            # å›å¡«åˆ° selected_stocks
            count = 0
            for stock in selected_stocks:
                code = stock['code']
                if code in industry_map:
                    stock['industry'] = industry_map[code]
                    count += 1
            
            print(f"âœ… æˆåŠŸä»åˆ†ææŠ¥å‘Šå›å¡« {count} æ¡è¡Œä¸šæ•°æ®")
            return True
        else:
            print("âš ï¸ æœªæ‰¾åˆ° result_analysis.txtï¼Œæ— æ³•å›å¡«ä¿¡æ¯")
            return False
    except Exception as e:
        print(f"âš ï¸ å›å¡«ä¿¡æ¯å‡ºé”™: {e}") 
        return False



def main():
    # 1. å…¨å¸‚åœºé€‰è‚¡
    selected, today = run_full_selection()
    
    # ç¡®ä¿æ—¥æœŸæ–‡ä»¶å¤¹å­˜åœ¨
    date_str = today.split('_')[0]
    date_dir = os.path.join("results", date_str)
    os.makedirs(date_dir, exist_ok=True)
    
    # æ³¨é‡Šï¼šstock_list_summary å·²ç§»è‡³ agent_outputs/result_analysis.txt
    # if selected:
    #     save_stock_summary(selected, date_dir, today)
    
    # 4. è°ƒç”¨AIåˆ†æ
    if not selected:
        print("âŒ æ²¡æœ‰é€‰å‡ºè‚¡ç¥¨ï¼Œè·³è¿‡åˆ†æ")
        return

    try:
        # ä¼ å…¥æ‰€æœ‰é€‰ä¸­çš„è‚¡ç¥¨ä¾›Agentåˆ†æ
        # Agentä¼šä»ä¸­é€‰å‡ºTop10è¿›è¡Œæ·±åº¦åˆ†æ
        all_stocks = selected
        
        # è°ƒç”¨Agentåˆ†æï¼ˆä¼ å…¥å…¨éƒ¨å€™é€‰ï¼‰
        gemini_analysis, analysis_prompt = call_gemini_analysis(all_stocks, date_dir)
        
        # å¦‚æœAgentè¿˜æœªç”Ÿæˆç»“æœï¼Œç­‰å¾…ç”¨æˆ·è¿è¡Œå·¥ä½œæµ
        if gemini_analysis is None:
            print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†ä»»åŠ¡")
            print("è¯·è¿è¡Œ Agent å·¥ä½œæµå®Œæˆåˆ†æï¼Œç„¶åå†æ¬¡æ‰§è¡Œæ­¤è„šæœ¬")
            return
        
        print("\nâœ… Agentåˆ†æå®Œæˆ")
        
        # åŠ è½½ Top 10 ä¸­é—´æ–‡ä»¶
        top10_file = os.path.join(date_dir, "selected_top10.json")
        top_stocks_list = all_stocks # é»˜è®¤
        
        if os.path.exists(top10_file):
             with open(top10_file, 'r', encoding='utf-8') as f:
                top_stocks_list = json.load(f)
             print(f"âš¡ åŠ è½½ Top 10 è‚¡ç¥¨æ± : {len(top_stocks_list)} åª")
        else:
             print("âš ï¸ æœªæ‰¾åˆ° selected_top10.jsonï¼Œå°†ä½¿ç”¨å…¨éƒ¨è‚¡ç¥¨")

        # ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        xiaohongshu_post, xhs_prompt = generate_xiaohongshu_post(gemini_analysis, top_stocks_list, date_dir)
        if xiaohongshu_post is None:
            print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†å°çº¢ä¹¦æ–‡æ¡ˆ")
            return
        print("âœ… å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ")
        
        # --- æ–°å¢æ­¥éª¤ï¼šä» AIåˆ†ææŠ¥å‘Š (result_analysis.txt) å›å¡« è¡Œä¸š/é¢˜æ ---
        # ç›®çš„ï¼šè§£è€¦å¯¹å°çº¢ä¹¦æ–‡æ¡ˆçš„ä¾èµ–ï¼Œç›´æ¥ä½¿ç”¨åˆ†æç»“æœ
        # --- æ–°å¢æ­¥éª¤ï¼šä» AIåˆ†ææŠ¥å‘Š (result_analysis.txt) å›å¡« è¡Œä¸š/é¢˜æ ---
        enrich_stocks_from_analysis(top_stocks_list, date_dir)
        # -------------------------------------------------------------------


        # ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
        image_prompt, img_gen_prompt = generate_image_prompt(gemini_analysis, top_stocks_list, date_dir)
        if image_prompt is None:
            print("\nâ¸ï¸  è„šæœ¬æš‚åœï¼šç­‰å¾…Agentå·¥ä½œæµå¤„ç†å›¾ç‰‡æç¤ºè¯")
            return
        print("âœ… å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ")
        print(f"\n[Image Prompt]:\n{image_prompt}\n")
        
        # ä¿å­˜ç‹¬ç«‹å›¾ç‰‡æç¤ºè¯æ–‡ä»¶
        img_prompt_file = os.path.join(date_dir, f"image_prompt_{today}.txt")
        with open(img_prompt_file, 'w', encoding='utf-8') as f:
            f.write(image_prompt)
        print(f"ğŸ“ å›¾ç‰‡æç¤ºè¯å·²ä¿å­˜: {img_prompt_file}")
        
        # æ³¨é‡Šï¼šæç¤ºè¯å·²ä¿å­˜åœ¨ agent_tasks/ ç›®å½•ï¼Œä¸éœ€è¦é‡å¤ä¿å­˜
        # prompts_dict = {
        #     "Top10åˆ†æ Prompt": analysis_prompt,
        #     "å°çº¢ä¹¦æ–‡æ¡ˆ Prompt": xhs_prompt,
        #     "å›¾ç‰‡ç”Ÿæˆ Prompt": img_gen_prompt
        # }
        # save_prompts(prompts_dict, today)
        
        # 4. ä¿å­˜æŠ¥å‘Š
        save_reports(gemini_analysis, xiaohongshu_post, today)
        
    except Exception as e:
        print(f"\nâŒ AIåˆ†æå‡ºé”™: {e}")
        print("è¯·ç¡®ä¿å·²è®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡")


if __name__ == "__main__":
    main()
